{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b5636bb-b5cc-4bd4-958b-cec961c8c59c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "class LFSR:\n",
    "    def __init__(self, length, initial_state):\n",
    "        self.length = length\n",
    "        self.state = initial_state\n",
    "\n",
    "    def next(self):\n",
    "        feedback_bit = self.state[-1] ^ self.state[-2] ^ self.state[-3] ^ self.state[-4]\n",
    "        new_bit = feedback_bit\n",
    "        self.state = np.roll(self.state, 1)\n",
    "        self.state[0] = new_bit\n",
    "        return new_bit\n",
    "\n",
    "class Geffe3:\n",
    "    def __init__(self):\n",
    "        # Define the three LFSRs with specific lengths and initial states\n",
    "        self.R1 = LFSR(5, np.array([1, 0, 1, 0, 1]))   # Initial state: 10101\n",
    "        self.R2 = LFSR(7, np.array([1, 0, 1, 0, 1, 1, 1]))  # Initial state: 1010111\n",
    "        self.R3 = LFSR(11, np.array([1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1]))  # Initial state: 11011101011\n",
    "\n",
    "    def next(self):\n",
    "        # Generate the next bit using the three LFSRs\n",
    "        r1 = self.R1.next()\n",
    "        r2 = self.R2.next()\n",
    "        r3 = self.R3.next()\n",
    "        b1 = r1 & r2\n",
    "        b2 = (~r1) & r3\n",
    "        return b1 ^ b2\n",
    "\n",
    "    def generate_keystream_bytes(self, length):\n",
    "        keystream_bytes = []\n",
    "        for _ in range(length):\n",
    "            byte = 0\n",
    "            for _ in range(8):\n",
    "                byte = (byte << 1) | self.next()\n",
    "            keystream_bytes.append(byte)\n",
    "        return keystream_bytes\n",
    "\n",
    "def generate_keystreams(num_streams, stream_length):\n",
    "    geffe = Geffe3()\n",
    "    keystreams = []\n",
    "    for _ in range(num_streams):\n",
    "        keystream_bits = [geffe.next() for _ in range(stream_length)]\n",
    "        keystream_bytes = geffe.generate_keystream_bytes(stream_length // 8)\n",
    "        keystreams.append((keystream_bits, keystream_bytes))\n",
    "    return keystreams\n",
    "\n",
    "def save_keystreams_to_csv(keystreams, filename):\n",
    "    columns = [f'Bit_{i+1}' for i in range(64)] + [f'Byte_{i+1}' for i in range(8)]\n",
    "    data = []\n",
    "    for bits, bytes in keystreams:\n",
    "        data.append(bits + bytes)\n",
    "    df = pd.DataFrame(data, columns=columns)\n",
    "    df.to_csv(filename, index=False)\n",
    "    print(f\"Keystreams saved to CSV file: {filename}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    num_records = 100000\n",
    "    stream_length = 80\n",
    "    filename = '100000_keystreams.csv'\n",
    "\n",
    "    keystreams = generate_keystreams(num_records, stream_length)\n",
    "    save_keystreams_to_csv(keystreams, filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0ba03c56-b9ef-4381-a991-b0f1ffe2638c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv1D, BatchNormalization, Flatten, Dense\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b1193289-1b75-4dfa-acea-5de9f5e9f014",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n",
      "X_train shape: (80000, 64, 1), y_train shape: (80000, 8)\n",
      "X_test shape: (20000, 64, 1), y_test shape: (20000, 8)\n"
     ]
    }
   ],
   "source": [
    "# Load the data from CSV\n",
    "data = pd.read_csv('100000_keystreams.csv')\n",
    "# Check if TensorFlow is using the GPU\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "# Separate the input features (64-bit key) and the targets (10 bytes of keystream)\n",
    "X = data.iloc[:, :64].values  # First 64 columns are the 64-bit key\n",
    "y = data.iloc[:, 64:72].values  # Next 10 columns are the 10 bytes of the keystream\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Reshape X to be (num_samples, 64, 1) for Conv1D input\n",
    "X_train_reshaped = X_train.reshape(-1, 64, 1)\n",
    "X_test_reshaped = X_test.reshape(-1, 64, 1)\n",
    "\n",
    "# Verify shapes\n",
    "print(f\"X_train shape: {X_train_reshaped.shape}, y_train shape: {y_train.shape}\")\n",
    "print(f\"X_test shape: {X_test_reshaped.shape}, y_test shape: {y_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7edf2be2-d57e-448e-897e-0ee47bb02ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to build the model\n",
    "def build_model():\n",
    "    input_layer = Input(shape=(64, 1))\n",
    "    x = Conv1D(32, 4, activation='relu', padding='same', strides=2)(input_layer)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Conv1D(64, 4, activation='relu', padding='same', strides=2)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Conv1D(128, 4, activation='relu', padding='same', strides=2)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Conv1D(256, 4, activation='relu', padding='same', strides=2)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Flatten()(x)\n",
    "    output_layer = Dense(256, activation='softmax')(x)  # 256 units for each byte\n",
    "    model = Model(inputs=input_layer, outputs=output_layer)\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "67cf8c2b-7f4e-4e2b-bdb5-1044a7aaa0fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to train and evaluate a model for a specific byte of the keystream\n",
    "def train_and_evaluate(X_train, y_train, X_test, y_test, byte_index):\n",
    "    # Initialize the model\n",
    "    model = build_model()\n",
    "\n",
    "    # Convert the labels to categorical\n",
    "    y_train_byte = to_categorical(y_train[:, byte_index], num_classes=256)  # 256 possible byte values\n",
    "    y_test_byte = to_categorical(y_test[:, byte_index], num_classes=256)\n",
    "\n",
    "    # Early stopping callback\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "    # Train the model\n",
    "    model.fit(X_train_reshaped, y_train_byte, epochs=50, batch_size=32, validation_split=0.1, callbacks=[early_stopping], verbose=1)\n",
    "\n",
    "    # Evaluate the model\n",
    "    loss, accuracy = model.evaluate(X_test_reshaped, y_test_byte, verbose=0)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5f117dd2-a85e-450f-b3ff-08c146d6c8b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training for byte 0...\n",
      "Epoch 1/50\n",
      "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 7ms/step - accuracy: 0.0569 - loss: 5.3191 - val_accuracy: 0.1260 - val_loss: 4.2282\n",
      "Epoch 2/50\n",
      "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 7ms/step - accuracy: 0.2144 - loss: 3.5639 - val_accuracy: 0.1975 - val_loss: 3.6158\n",
      "Epoch 3/50\n",
      "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 8ms/step - accuracy: 0.3738 - loss: 2.5625 - val_accuracy: 0.2534 - val_loss: 3.3377\n",
      "Epoch 4/50\n",
      "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 8ms/step - accuracy: 0.5144 - loss: 1.8655 - val_accuracy: 0.2903 - val_loss: 3.2385\n",
      "Epoch 5/50\n",
      "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 7ms/step - accuracy: 0.6155 - loss: 1.4172 - val_accuracy: 0.3076 - val_loss: 3.3153\n",
      "Epoch 6/50\n",
      "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 7ms/step - accuracy: 0.6841 - loss: 1.1152 - val_accuracy: 0.3254 - val_loss: 3.3478\n",
      "Epoch 7/50\n",
      "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 8ms/step - accuracy: 0.7416 - loss: 0.8860 - val_accuracy: 0.3384 - val_loss: 3.5544\n",
      "Epoch 8/50\n",
      "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 7ms/step - accuracy: 0.7812 - loss: 0.7273 - val_accuracy: 0.3417 - val_loss: 3.6473\n",
      "Epoch 9/50\n",
      "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 8ms/step - accuracy: 0.8085 - loss: 0.6224 - val_accuracy: 0.3593 - val_loss: 3.7911\n",
      "Accuracy for byte 0: 28.56%\n",
      "\n",
      "Training for byte 1...\n",
      "Epoch 1/50\n",
      "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 7ms/step - accuracy: 0.0575 - loss: 5.3078 - val_accuracy: 0.1283 - val_loss: 4.2047\n",
      "Epoch 2/50\n",
      "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 7ms/step - accuracy: 0.2177 - loss: 3.5316 - val_accuracy: 0.1994 - val_loss: 3.5643\n",
      "Epoch 3/50\n",
      "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 7ms/step - accuracy: 0.3758 - loss: 2.5387 - val_accuracy: 0.2500 - val_loss: 3.3249\n",
      "Epoch 4/50\n",
      "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 7ms/step - accuracy: 0.5151 - loss: 1.8587 - val_accuracy: 0.2921 - val_loss: 3.2045\n",
      "Epoch 5/50\n",
      "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 7ms/step - accuracy: 0.6135 - loss: 1.4082 - val_accuracy: 0.3158 - val_loss: 3.2174\n",
      "Epoch 6/50\n",
      "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 7ms/step - accuracy: 0.6888 - loss: 1.1018 - val_accuracy: 0.3345 - val_loss: 3.3459\n",
      "Epoch 7/50\n",
      "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 7ms/step - accuracy: 0.7444 - loss: 0.8703 - val_accuracy: 0.3455 - val_loss: 3.4679\n",
      "Epoch 8/50\n",
      "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 7ms/step - accuracy: 0.7842 - loss: 0.7133 - val_accuracy: 0.3535 - val_loss: 3.6529\n",
      "Epoch 9/50\n",
      "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 7ms/step - accuracy: 0.8179 - loss: 0.5983 - val_accuracy: 0.3591 - val_loss: 3.8111\n",
      "Accuracy for byte 1: 28.82%\n",
      "\n",
      "Training for byte 2...\n",
      "Epoch 1/50\n",
      "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 8ms/step - accuracy: 0.0623 - loss: 5.2577 - val_accuracy: 0.1335 - val_loss: 4.1269\n",
      "Epoch 2/50\n",
      "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 7ms/step - accuracy: 0.2233 - loss: 3.4626 - val_accuracy: 0.2115 - val_loss: 3.4847\n",
      "Epoch 3/50\n",
      "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 7ms/step - accuracy: 0.3944 - loss: 2.4490 - val_accuracy: 0.2594 - val_loss: 3.2329\n",
      "Epoch 4/50\n",
      "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 7ms/step - accuracy: 0.5322 - loss: 1.7747 - val_accuracy: 0.3034 - val_loss: 3.1292\n",
      "Epoch 5/50\n",
      "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 8ms/step - accuracy: 0.6394 - loss: 1.3166 - val_accuracy: 0.3329 - val_loss: 3.1315\n",
      "Epoch 6/50\n",
      "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 8ms/step - accuracy: 0.7082 - loss: 1.0280 - val_accuracy: 0.3445 - val_loss: 3.2265\n",
      "Epoch 7/50\n",
      "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 8ms/step - accuracy: 0.7637 - loss: 0.8036 - val_accuracy: 0.3646 - val_loss: 3.3158\n",
      "Epoch 8/50\n",
      "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 8ms/step - accuracy: 0.8009 - loss: 0.6575 - val_accuracy: 0.3663 - val_loss: 3.5723\n",
      "Epoch 9/50\n",
      "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 8ms/step - accuracy: 0.8303 - loss: 0.5525 - val_accuracy: 0.3774 - val_loss: 3.6536\n",
      "Accuracy for byte 2: 30.11%\n",
      "\n",
      "Training for byte 3...\n",
      "Epoch 1/50\n",
      "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 8ms/step - accuracy: 0.0593 - loss: 5.2700 - val_accuracy: 0.1367 - val_loss: 4.1483\n",
      "Epoch 2/50\n",
      "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 7ms/step - accuracy: 0.2298 - loss: 3.4541 - val_accuracy: 0.2031 - val_loss: 3.5467\n",
      "Epoch 3/50\n",
      "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 7ms/step - accuracy: 0.3934 - loss: 2.4484 - val_accuracy: 0.2559 - val_loss: 3.3009\n",
      "Epoch 4/50\n",
      "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 7ms/step - accuracy: 0.5362 - loss: 1.7767 - val_accuracy: 0.2980 - val_loss: 3.1666\n",
      "Epoch 5/50\n",
      "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 7ms/step - accuracy: 0.6381 - loss: 1.3184 - val_accuracy: 0.3295 - val_loss: 3.1652\n",
      "Epoch 6/50\n",
      "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 7ms/step - accuracy: 0.7084 - loss: 1.0238 - val_accuracy: 0.3530 - val_loss: 3.2587\n",
      "Epoch 7/50\n",
      "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 8ms/step - accuracy: 0.7612 - loss: 0.8114 - val_accuracy: 0.3613 - val_loss: 3.3809\n",
      "Epoch 8/50\n",
      "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 7ms/step - accuracy: 0.8003 - loss: 0.6616 - val_accuracy: 0.3716 - val_loss: 3.5633\n",
      "Epoch 9/50\n",
      "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 7ms/step - accuracy: 0.8300 - loss: 0.5526 - val_accuracy: 0.3778 - val_loss: 3.7038\n",
      "Epoch 10/50\n",
      "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 7ms/step - accuracy: 0.8514 - loss: 0.4749 - val_accuracy: 0.3823 - val_loss: 3.8069\n",
      "Accuracy for byte 3: 32.70%\n",
      "\n",
      "Training for byte 4...\n",
      "Epoch 1/50\n",
      "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 8ms/step - accuracy: 0.0579 - loss: 5.2720 - val_accuracy: 0.1239 - val_loss: 4.2143\n",
      "Epoch 2/50\n",
      "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 8ms/step - accuracy: 0.2187 - loss: 3.5092 - val_accuracy: 0.1925 - val_loss: 3.5997\n",
      "Epoch 3/50\n",
      "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 8ms/step - accuracy: 0.3751 - loss: 2.5348 - val_accuracy: 0.2430 - val_loss: 3.3543\n",
      "Epoch 4/50\n",
      "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 8ms/step - accuracy: 0.5115 - loss: 1.8656 - val_accuracy: 0.2804 - val_loss: 3.2953\n",
      "Epoch 5/50\n",
      "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 8ms/step - accuracy: 0.6118 - loss: 1.4168 - val_accuracy: 0.3101 - val_loss: 3.2719\n",
      "Epoch 6/50\n",
      "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 8ms/step - accuracy: 0.6887 - loss: 1.1012 - val_accuracy: 0.3311 - val_loss: 3.3842\n",
      "Epoch 7/50\n",
      "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 8ms/step - accuracy: 0.7472 - loss: 0.8686 - val_accuracy: 0.3402 - val_loss: 3.5014\n",
      "Epoch 8/50\n",
      "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 8ms/step - accuracy: 0.7859 - loss: 0.7150 - val_accuracy: 0.3456 - val_loss: 3.7176\n",
      "Epoch 9/50\n",
      "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 8ms/step - accuracy: 0.8172 - loss: 0.5957 - val_accuracy: 0.3540 - val_loss: 3.9175\n",
      "Epoch 10/50\n",
      "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 8ms/step - accuracy: 0.8411 - loss: 0.5105 - val_accuracy: 0.3596 - val_loss: 3.9938\n",
      "Accuracy for byte 4: 31.37%\n",
      "\n",
      "Training for byte 5...\n",
      "Epoch 1/50\n",
      "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 7ms/step - accuracy: 0.0538 - loss: 5.3715 - val_accuracy: 0.1200 - val_loss: 4.2588\n",
      "Epoch 2/50\n",
      "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 7ms/step - accuracy: 0.2074 - loss: 3.6001 - val_accuracy: 0.1834 - val_loss: 3.6786\n",
      "Epoch 3/50\n",
      "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 7ms/step - accuracy: 0.3638 - loss: 2.6164 - val_accuracy: 0.2344 - val_loss: 3.3958\n",
      "Epoch 4/50\n",
      "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 8ms/step - accuracy: 0.4957 - loss: 1.9472 - val_accuracy: 0.2774 - val_loss: 3.3032\n",
      "Epoch 5/50\n",
      "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 7ms/step - accuracy: 0.5988 - loss: 1.4933 - val_accuracy: 0.2907 - val_loss: 3.3984\n",
      "Epoch 6/50\n",
      "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 8ms/step - accuracy: 0.6694 - loss: 1.1852 - val_accuracy: 0.3190 - val_loss: 3.5013\n",
      "Epoch 7/50\n",
      "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 8ms/step - accuracy: 0.7277 - loss: 0.9495 - val_accuracy: 0.3246 - val_loss: 3.6291\n",
      "Epoch 8/50\n",
      "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 8ms/step - accuracy: 0.7693 - loss: 0.7809 - val_accuracy: 0.3322 - val_loss: 3.8014\n",
      "Epoch 9/50\n",
      "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 8ms/step - accuracy: 0.8017 - loss: 0.6521 - val_accuracy: 0.3410 - val_loss: 3.9900\n",
      "Accuracy for byte 5: 27.03%\n",
      "\n",
      "Training for byte 6...\n",
      "Epoch 1/50\n",
      "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 8ms/step - accuracy: 0.0555 - loss: 5.3536 - val_accuracy: 0.1214 - val_loss: 4.2739\n",
      "Epoch 2/50\n",
      "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 7ms/step - accuracy: 0.2069 - loss: 3.6171 - val_accuracy: 0.1803 - val_loss: 3.7072\n",
      "Epoch 3/50\n",
      "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 7ms/step - accuracy: 0.3586 - loss: 2.6444 - val_accuracy: 0.2281 - val_loss: 3.4935\n",
      "Epoch 4/50\n",
      "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 7ms/step - accuracy: 0.4947 - loss: 1.9761 - val_accuracy: 0.2704 - val_loss: 3.4114\n",
      "Epoch 5/50\n",
      "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - accuracy: 0.5927 - loss: 1.5228 - val_accuracy: 0.2940 - val_loss: 3.4101\n",
      "Epoch 6/50\n",
      "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - accuracy: 0.6652 - loss: 1.2054 - val_accuracy: 0.3069 - val_loss: 3.5557\n",
      "Epoch 7/50\n",
      "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - accuracy: 0.7234 - loss: 0.9730 - val_accuracy: 0.3180 - val_loss: 3.6492\n",
      "Epoch 8/50\n",
      "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - accuracy: 0.7658 - loss: 0.7962 - val_accuracy: 0.3237 - val_loss: 3.8756\n",
      "Epoch 9/50\n",
      "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 6ms/step - accuracy: 0.7994 - loss: 0.6644 - val_accuracy: 0.3379 - val_loss: 4.0290\n",
      "Epoch 10/50\n",
      "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - accuracy: 0.8192 - loss: 0.5838 - val_accuracy: 0.3428 - val_loss: 4.2072\n",
      "Accuracy for byte 6: 29.14%\n",
      "\n",
      "Training for byte 7...\n",
      "Epoch 1/50\n",
      "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 5ms/step - accuracy: 0.0501 - loss: 5.3838 - val_accuracy: 0.1181 - val_loss: 4.3001\n",
      "Epoch 2/50\n",
      "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.2024 - loss: 3.6454 - val_accuracy: 0.1793 - val_loss: 3.7287\n",
      "Epoch 3/50\n",
      "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - accuracy: 0.3551 - loss: 2.6757 - val_accuracy: 0.2290 - val_loss: 3.4925\n",
      "Epoch 4/50\n",
      "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 6ms/step - accuracy: 0.4836 - loss: 2.0134 - val_accuracy: 0.2610 - val_loss: 3.4511\n",
      "Epoch 5/50\n",
      "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - accuracy: 0.5829 - loss: 1.5720 - val_accuracy: 0.2779 - val_loss: 3.4813\n",
      "Epoch 6/50\n",
      "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 6ms/step - accuracy: 0.6579 - loss: 1.2420 - val_accuracy: 0.2976 - val_loss: 3.6133\n",
      "Epoch 7/50\n",
      "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 7ms/step - accuracy: 0.7119 - loss: 1.0028 - val_accuracy: 0.3171 - val_loss: 3.7472\n",
      "Epoch 8/50\n",
      "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 7ms/step - accuracy: 0.7590 - loss: 0.8214 - val_accuracy: 0.3210 - val_loss: 3.9625\n",
      "Epoch 9/50\n",
      "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 7ms/step - accuracy: 0.7920 - loss: 0.7006 - val_accuracy: 0.3299 - val_loss: 4.1414\n",
      "Accuracy for byte 7: 25.94%\n",
      "Accuracies for all 8 bytes:\n",
      "Byte 0: 28.56%\n",
      "Byte 1: 28.82%\n",
      "Byte 2: 30.11%\n",
      "Byte 3: 32.70%\n",
      "Byte 4: 31.37%\n",
      "Byte 5: 27.03%\n",
      "Byte 6: 29.14%\n",
      "Byte 7: 25.94%\n"
     ]
    }
   ],
   "source": [
    "# Train and evaluate the model for each byte and print the accuracy\n",
    "accuracies = []\n",
    "for byte_index in range(8):  # 8 bytes\n",
    "    print(f'\\nTraining for byte {byte_index}...')\n",
    "    accuracy = train_and_evaluate(X_train, y_train, X_test, y_test, byte_index)\n",
    "    accuracies.append(accuracy)\n",
    "    print(f'Accuracy for byte {byte_index}: {accuracy * 100:.2f}%')\n",
    "\n",
    "# Print all accuracies\n",
    "print(\"Accuracies for all 8 bytes:\")\n",
    "for byte_index, accuracy in enumerate(accuracies):\n",
    "    print(f'Byte {byte_index}: {accuracy * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7b8448e-ab8e-4328-ada4-32529bcf0f9e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iitbhu",
   "language": "python",
   "name": "iitbhu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
