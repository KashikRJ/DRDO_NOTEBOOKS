{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4115b86b-5d0c-41a4-9589-cfc686f229ee",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# BASE Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d734179-7f14-4d8f-80d9-d4e45c9b5316",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a2266c42-4bbc-4b9c-96a1-e65d0b9ff5b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data from CSV\n",
    "data = pd.read_csv('keystream_records.csv')\n",
    "\n",
    "# Separate the input features (64-bit key) and the targets (10 bytes of keystream)\n",
    "X = data.iloc[:, :64].values  # First 64 columns are the 64-bit key\n",
    "y = data.iloc[:, 64:74].values   # Next 10 columns are the 10 bytes of the keystream\n",
    "\n",
    "# Convert the target to categorical (byte values range from 0 to 255)\n",
    "y = y.astype(np.uint8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d971a77e-dd17-4c99-aac8-8db49e4e507e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets (80-20 split)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "076b8eb2-e597-45d8-b35b-f73a136df5fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class KeystreamClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(KeystreamClassifier, self).__init__()\n",
    "        self.fc1 = nn.Linear(64, 128)\n",
    "        self.fc2 = nn.Linear(128, 256)\n",
    "        self.fc3 = nn.Linear(256, 256)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29686fb3-59bb-433c-a1a3-dac9e2135d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to train and evaluate a model for a specific byte of the keystream\n",
    "def train_and_evaluate(X_train, y_train, X_test, y_test, byte_index):\n",
    "    # Initialize the model, loss function, and optimizer\n",
    "    model = KeystreamClassifier()\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    \n",
    "    # Convert data to PyTorch tensors\n",
    "    y_train_tensor = torch.tensor(y_train[:, byte_index], dtype=torch.long)\n",
    "    y_test_tensor = torch.tensor(y_test[:, byte_index], dtype=torch.long)\n",
    "    \n",
    "    # Create data loaders\n",
    "    train_dataset = torch.utils.data.TensorDataset(torch.tensor(X_train, dtype=torch.float32), y_train_tensor)\n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "    \n",
    "    # Training the model\n",
    "    num_epochs = 50\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for inputs, labels in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "        print(f'Epoch {epoch+1}/{num_epochs}, Loss: {running_loss/len(train_loader)}')\n",
    "\n",
    "    # Evaluate the model\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        outputs = model(torch.tensor(X_test, dtype=torch.float32))\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        accuracy = accuracy_score(y_test[:, byte_index], predicted.numpy())\n",
    "        return accuracy\n",
    "\n",
    "# Train and evaluate the model for each byte and print the accuracy\n",
    "accuracies = []\n",
    "for byte_index in range(10):\n",
    "    accuracy = train_and_evaluate(X_train, y_train, X_test, y_test, byte_index)\n",
    "    accuracies.append(accuracy)\n",
    "    print(f'Accuracy for byte {byte_index}: {accuracy * 100:.2f}%')\n",
    "\n",
    "# Print all accuracies\n",
    "print(\"Accuracies for all 10 bytes:\")\n",
    "for byte_index, accuracy in enumerate(accuracies):\n",
    "    print(f'Byte {byte_index}: {accuracy * 100:.2f}%')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "884152a7-efd8-4df2-a66e-6d3ab99b95f2",
   "metadata": {},
   "source": [
    "## Base Model with train accuracy also to chk overfit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1cf55773-e0f8-4c4a-a43c-4b94d6dc4817",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50, Loss: 5.546514935302734\n",
      "Epoch 2/50, Loss: 5.543440324020386\n",
      "Epoch 3/50, Loss: 5.535131820678711\n",
      "Epoch 4/50, Loss: 5.511759674835205\n",
      "Epoch 5/50, Loss: 5.4691279647827145\n",
      "Epoch 6/50, Loss: 5.41241294631958\n",
      "Epoch 7/50, Loss: 5.347812014007569\n",
      "Epoch 8/50, Loss: 5.28043024520874\n",
      "Epoch 9/50, Loss: 5.213923597335816\n",
      "Epoch 10/50, Loss: 5.151710289001465\n",
      "Epoch 11/50, Loss: 5.094512948989868\n",
      "Epoch 12/50, Loss: 5.042583721542359\n",
      "Epoch 13/50, Loss: 4.996898053741455\n",
      "Epoch 14/50, Loss: 4.9560673038482665\n",
      "Epoch 15/50, Loss: 4.9207466732025145\n",
      "Epoch 16/50, Loss: 4.887672731399536\n",
      "Epoch 17/50, Loss: 4.85904135093689\n",
      "Epoch 18/50, Loss: 4.832201749420166\n",
      "Epoch 19/50, Loss: 4.807951002120972\n",
      "Epoch 20/50, Loss: 4.784691147994995\n",
      "Epoch 21/50, Loss: 4.765532139968872\n",
      "Epoch 22/50, Loss: 4.745943176651001\n",
      "Epoch 23/50, Loss: 4.728050874710083\n",
      "Epoch 24/50, Loss: 4.71211417427063\n",
      "Epoch 25/50, Loss: 4.697914255523681\n",
      "Epoch 26/50, Loss: 4.683232507705688\n",
      "Epoch 27/50, Loss: 4.668825652313233\n",
      "Epoch 28/50, Loss: 4.655822096633911\n",
      "Epoch 29/50, Loss: 4.644980060958862\n",
      "Epoch 30/50, Loss: 4.63249744682312\n",
      "Epoch 31/50, Loss: 4.621811581802368\n",
      "Epoch 32/50, Loss: 4.612941512107849\n",
      "Epoch 33/50, Loss: 4.601522952651978\n",
      "Epoch 34/50, Loss: 4.59127271938324\n",
      "Epoch 35/50, Loss: 4.583328870010376\n",
      "Epoch 36/50, Loss: 4.571946308517456\n",
      "Epoch 37/50, Loss: 4.564496801567078\n",
      "Epoch 38/50, Loss: 4.555219281768799\n",
      "Epoch 39/50, Loss: 4.547117358016968\n",
      "Epoch 40/50, Loss: 4.539304919624328\n",
      "Epoch 41/50, Loss: 4.531947718238831\n",
      "Epoch 42/50, Loss: 4.523974833679199\n",
      "Epoch 43/50, Loss: 4.516074178886414\n",
      "Epoch 44/50, Loss: 4.510180848121643\n",
      "Epoch 45/50, Loss: 4.503119230270386\n",
      "Epoch 46/50, Loss: 4.497262648200989\n",
      "Epoch 47/50, Loss: 4.491097583007813\n",
      "Epoch 48/50, Loss: 4.485161374092102\n",
      "Epoch 49/50, Loss: 4.479517652893066\n",
      "Epoch 50/50, Loss: 4.474695421028137\n",
      "Byte 0: Train Accuracy: 12.19%, Test Accuracy: 0.40%\n",
      "Epoch 1/50, Loss: 5.546625204849243\n",
      "Epoch 2/50, Loss: 5.543503708267212\n",
      "Epoch 3/50, Loss: 5.534992598724365\n",
      "Epoch 4/50, Loss: 5.511507513809204\n",
      "Epoch 5/50, Loss: 5.470500760650634\n",
      "Epoch 6/50, Loss: 5.415619425582886\n",
      "Epoch 7/50, Loss: 5.352065560913086\n",
      "Epoch 8/50, Loss: 5.284458224868774\n",
      "Epoch 9/50, Loss: 5.215756233215332\n",
      "Epoch 10/50, Loss: 5.150253231048584\n",
      "Epoch 11/50, Loss: 5.090225673294067\n",
      "Epoch 12/50, Loss: 5.036274122619629\n",
      "Epoch 13/50, Loss: 4.988533423614502\n",
      "Epoch 14/50, Loss: 4.945182969284057\n",
      "Epoch 15/50, Loss: 4.907761492919922\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 48\u001b[0m\n\u001b[0;32m     46\u001b[0m accuracies \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m byte_index \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m10\u001b[39m):\n\u001b[1;32m---> 48\u001b[0m     train_accuracy, test_accuracy \u001b[38;5;241m=\u001b[39m train_and_evaluate(X_train, y_train, X_test, y_test, byte_index)\n\u001b[0;32m     49\u001b[0m     accuracies\u001b[38;5;241m.\u001b[39mappend((train_accuracy, test_accuracy))\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mByte \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbyte_index\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: Train Accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_accuracy\u001b[38;5;250m \u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m100\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m%, Test Accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_accuracy\u001b[38;5;250m \u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m100\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[1;32mIn[7], line 22\u001b[0m, in \u001b[0;36mtrain_and_evaluate\u001b[1;34m(X_train, y_train, X_test, y_test, byte_index)\u001b[0m\n\u001b[0;32m     20\u001b[0m running_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m inputs, labels \u001b[38;5;129;01min\u001b[39;00m train_loader:\n\u001b[1;32m---> 22\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m     23\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m model(inputs)\n\u001b[0;32m     24\u001b[0m     loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\_compile.py:24\u001b[0m, in \u001b[0;36m_disable_dynamo.<locals>.inner\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(fn)\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m     22\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_dynamo\u001b[39;00m\n\u001b[1;32m---> 24\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mdisable(fn, recursive)(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\_dynamo\\decorators.py:47\u001b[0m, in \u001b[0;36mdisable\u001b[1;34m(fn, recursive)\u001b[0m\n\u001b[0;32m     45\u001b[0m         fn \u001b[38;5;241m=\u001b[39m innermost_fn(fn)\n\u001b[0;32m     46\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(fn)\n\u001b[1;32m---> 47\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m DisableContext()(fn)\n\u001b[0;32m     48\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m DisableContext()\n\u001b[0;32m     49\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\_dynamo\\eval_frame.py:290\u001b[0m, in \u001b[0;36m_TorchDynamoContext.__call__\u001b[1;34m(self, fn)\u001b[0m\n\u001b[0;32m    287\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(fn)\n\u001b[0;32m    289\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 290\u001b[0m     filename \u001b[38;5;241m=\u001b[39m inspect\u001b[38;5;241m.\u001b[39mgetsourcefile(fn)\n\u001b[0;32m    291\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m    292\u001b[0m     filename \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\proenv\\Lib\\inspect.py:949\u001b[0m, in \u001b[0;36mgetsourcefile\u001b[1;34m(object)\u001b[0m\n\u001b[0;32m    946\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28many\u001b[39m(filename\u001b[38;5;241m.\u001b[39mendswith(s) \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m\n\u001b[0;32m    947\u001b[0m              importlib\u001b[38;5;241m.\u001b[39mmachinery\u001b[38;5;241m.\u001b[39mEXTENSION_SUFFIXES):\n\u001b[0;32m    948\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 949\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(filename):\n\u001b[0;32m    950\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m filename\n\u001b[0;32m    951\u001b[0m \u001b[38;5;66;03m# only return a non-existent filename if the module has a PEP 302 loader\u001b[39;00m\n",
      "File \u001b[1;32m<frozen genericpath>:19\u001b[0m, in \u001b[0;36mexists\u001b[1;34m(path)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Function to train and evaluate a model for a specific byte of the keystream\n",
    "def train_and_evaluate(X_train, y_train, X_test, y_test, byte_index):\n",
    "    # Initialize the model, loss function, and optimizer\n",
    "    model = KeystreamClassifier()\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    \n",
    "    # Convert data to PyTorch tensors\n",
    "    y_train_tensor = torch.tensor(y_train[:, byte_index], dtype=torch.long)\n",
    "    y_test_tensor = torch.tensor(y_test[:, byte_index], dtype=torch.long)\n",
    "    \n",
    "    # Create data loaders\n",
    "    train_dataset = torch.utils.data.TensorDataset(torch.tensor(X_train, dtype=torch.float32), y_train_tensor)\n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "    \n",
    "    # Training the model\n",
    "    num_epochs = 50\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for inputs, labels in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "        print(f'Epoch {epoch+1}/{num_epochs}, Loss: {running_loss/len(train_loader)}')\n",
    "\n",
    "    # Evaluate the model\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        # Evaluate on training data\n",
    "        train_outputs = model(torch.tensor(X_train, dtype=torch.float32))\n",
    "        _, train_predicted = torch.max(train_outputs, 1)\n",
    "        train_accuracy = accuracy_score(y_train[:, byte_index], train_predicted.numpy())\n",
    "        \n",
    "        # Evaluate on test data\n",
    "        test_outputs = model(torch.tensor(X_test, dtype=torch.float32))\n",
    "        _, test_predicted = torch.max(test_outputs, 1)\n",
    "        test_accuracy = accuracy_score(y_test[:, byte_index], test_predicted.numpy())\n",
    "        \n",
    "        return train_accuracy, test_accuracy\n",
    "\n",
    "# Train and evaluate the model for each byte and print the accuracy\n",
    "accuracies = []\n",
    "for byte_index in range(10):\n",
    "    train_accuracy, test_accuracy = train_and_evaluate(X_train, y_train, X_test, y_test, byte_index)\n",
    "    accuracies.append((train_accuracy, test_accuracy))\n",
    "    print(f'Byte {byte_index}: Train Accuracy: {train_accuracy * 100:.2f}%, Test Accuracy: {test_accuracy * 100:.2f}%')\n",
    "\n",
    "\n",
    "# Print all accuracies\n",
    "print(\"Accuracies for all 10 bytes:\")\n",
    "for byte_index, (train_accuracy, test_accuracy) in enumerate(accuracies):\n",
    "    print(f'Byte {byte_index}: Train Accuracy: {train_accuracy * 100:.2f}%, Test Accuracy: {test_accuracy * 100:.2f}%')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46fde6d9-f14a-48d5-8fce-2ead883abec2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# BASE MODEL with val loss,val accuracy and early stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "726d372c-d32b-45fb-a565-c34f4ecb3619",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "874c0785-0fb1-47be-a725-d933e8a72bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data from CSV\n",
    "data = pd.read_csv('keystream_records_val.csv')\n",
    "\n",
    "# Separate the input features (64-bit key) and the targets (10 bytes of keystream)\n",
    "X = data.iloc[:, :64].values  # First 64 columns are the 64-bit key\n",
    "y = data.iloc[:, 64:74].values   # Next 10 columns are the 10 bytes of the keystream\n",
    "\n",
    "# Convert the target to categorical (byte values range from 0 to 255)\n",
    "y = y.astype(np.uint8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a35c41b-c162-483c-8a4e-adf649c735b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training, validation, and testing sets (70-10-20 split)\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.67, random_state=42)  # 0.67 * 0.3 ≈ 0.2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "58fe7076-bb61-414a-8d24-905fb5568351",
   "metadata": {},
   "outputs": [],
   "source": [
    "class KeystreamClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(KeystreamClassifier, self).__init__()\n",
    "        self.fc1 = nn.Linear(64, 128)\n",
    "        self.fc2 = nn.Linear(128, 256)\n",
    "        self.fc3 = nn.Linear(256, 256)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f5a1b69-1c43-4865-961c-c0858e498ded",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## LR=0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "110a6aa6-07c4-4b6b-bc81-b1bc33647498",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training for byte 0...\n",
      "Epoch 1/50, Loss: 5.5466, Accuracy: 0.0038, Val Loss: 5.5461, Val Accuracy: 0.0034\n",
      "Epoch 2/50, Loss: 5.5448, Accuracy: 0.0041, Val Loss: 5.5462, Val Accuracy: 0.0033\n",
      "Epoch 3/50, Loss: 5.5413, Accuracy: 0.0047, Val Loss: 5.5495, Val Accuracy: 0.0040\n",
      "Epoch 4/50, Loss: 5.5289, Accuracy: 0.0059, Val Loss: 5.5568, Val Accuracy: 0.0043\n",
      "Epoch 5/50, Loss: 5.5048, Accuracy: 0.0083, Val Loss: 5.5740, Val Accuracy: 0.0048\n",
      "Epoch 6/50, Loss: 5.4694, Accuracy: 0.0100, Val Loss: 5.5934, Val Accuracy: 0.0048\n",
      "Early stopping\n",
      "Accuracy for byte 0: 0.42%\n",
      "\n",
      "Training for byte 1...\n",
      "Epoch 1/50, Loss: 5.5466, Accuracy: 0.0040, Val Loss: 5.5465, Val Accuracy: 0.0036\n",
      "Epoch 2/50, Loss: 5.5447, Accuracy: 0.0041, Val Loss: 5.5469, Val Accuracy: 0.0037\n",
      "Epoch 3/50, Loss: 5.5410, Accuracy: 0.0050, Val Loss: 5.5506, Val Accuracy: 0.0030\n",
      "Epoch 4/50, Loss: 5.5281, Accuracy: 0.0062, Val Loss: 5.5618, Val Accuracy: 0.0035\n",
      "Epoch 5/50, Loss: 5.5023, Accuracy: 0.0080, Val Loss: 5.5733, Val Accuracy: 0.0037\n",
      "Epoch 6/50, Loss: 5.4652, Accuracy: 0.0105, Val Loss: 5.6141, Val Accuracy: 0.0036\n",
      "Early stopping\n",
      "Accuracy for byte 1: 0.33%\n",
      "\n",
      "Training for byte 2...\n",
      "Epoch 1/50, Loss: 5.5466, Accuracy: 0.0038, Val Loss: 5.5463, Val Accuracy: 0.0036\n",
      "Epoch 2/50, Loss: 5.5447, Accuracy: 0.0044, Val Loss: 5.5468, Val Accuracy: 0.0038\n",
      "Epoch 3/50, Loss: 5.5404, Accuracy: 0.0052, Val Loss: 5.5506, Val Accuracy: 0.0033\n",
      "Epoch 4/50, Loss: 5.5262, Accuracy: 0.0070, Val Loss: 5.5607, Val Accuracy: 0.0041\n",
      "Epoch 5/50, Loss: 5.4988, Accuracy: 0.0089, Val Loss: 5.5736, Val Accuracy: 0.0040\n",
      "Epoch 6/50, Loss: 5.4602, Accuracy: 0.0116, Val Loss: 5.6069, Val Accuracy: 0.0041\n",
      "Early stopping\n",
      "Accuracy for byte 2: 0.37%\n",
      "\n",
      "Training for byte 3...\n",
      "Epoch 1/50, Loss: 5.5465, Accuracy: 0.0038, Val Loss: 5.5469, Val Accuracy: 0.0040\n",
      "Epoch 2/50, Loss: 5.5446, Accuracy: 0.0045, Val Loss: 5.5465, Val Accuracy: 0.0038\n",
      "Epoch 3/50, Loss: 5.5412, Accuracy: 0.0053, Val Loss: 5.5506, Val Accuracy: 0.0043\n",
      "Epoch 4/50, Loss: 5.5294, Accuracy: 0.0059, Val Loss: 5.5554, Val Accuracy: 0.0039\n",
      "Epoch 5/50, Loss: 5.5048, Accuracy: 0.0082, Val Loss: 5.5725, Val Accuracy: 0.0038\n",
      "Epoch 6/50, Loss: 5.4673, Accuracy: 0.0112, Val Loss: 5.6023, Val Accuracy: 0.0032\n",
      "Epoch 7/50, Loss: 5.4211, Accuracy: 0.0137, Val Loss: 5.6354, Val Accuracy: 0.0042\n",
      "Early stopping\n",
      "Accuracy for byte 3: 0.38%\n",
      "\n",
      "Training for byte 4...\n",
      "Epoch 1/50, Loss: 5.5465, Accuracy: 0.0040, Val Loss: 5.5456, Val Accuracy: 0.0046\n",
      "Epoch 2/50, Loss: 5.5446, Accuracy: 0.0044, Val Loss: 5.5480, Val Accuracy: 0.0034\n",
      "Epoch 3/50, Loss: 5.5394, Accuracy: 0.0051, Val Loss: 5.5546, Val Accuracy: 0.0036\n",
      "Epoch 4/50, Loss: 5.5230, Accuracy: 0.0069, Val Loss: 5.5647, Val Accuracy: 0.0040\n",
      "Epoch 5/50, Loss: 5.4918, Accuracy: 0.0085, Val Loss: 5.5937, Val Accuracy: 0.0034\n",
      "Epoch 6/50, Loss: 5.4498, Accuracy: 0.0115, Val Loss: 5.6290, Val Accuracy: 0.0034\n",
      "Early stopping\n",
      "Accuracy for byte 4: 0.39%\n",
      "\n",
      "Training for byte 5...\n",
      "Epoch 1/50, Loss: 5.5465, Accuracy: 0.0041, Val Loss: 5.5458, Val Accuracy: 0.0036\n",
      "Epoch 2/50, Loss: 5.5451, Accuracy: 0.0042, Val Loss: 5.5463, Val Accuracy: 0.0034\n",
      "Epoch 3/50, Loss: 5.5428, Accuracy: 0.0048, Val Loss: 5.5472, Val Accuracy: 0.0035\n",
      "Epoch 4/50, Loss: 5.5339, Accuracy: 0.0059, Val Loss: 5.5532, Val Accuracy: 0.0045\n",
      "Epoch 5/50, Loss: 5.5133, Accuracy: 0.0068, Val Loss: 5.5725, Val Accuracy: 0.0028\n",
      "Epoch 6/50, Loss: 5.4793, Accuracy: 0.0095, Val Loss: 5.5865, Val Accuracy: 0.0044\n",
      "Early stopping\n",
      "Accuracy for byte 5: 0.39%\n",
      "\n",
      "Training for byte 6...\n",
      "Epoch 1/50, Loss: 5.5466, Accuracy: 0.0036, Val Loss: 5.5463, Val Accuracy: 0.0037\n",
      "Epoch 2/50, Loss: 5.5444, Accuracy: 0.0043, Val Loss: 5.5481, Val Accuracy: 0.0038\n",
      "Epoch 3/50, Loss: 5.5399, Accuracy: 0.0050, Val Loss: 5.5507, Val Accuracy: 0.0039\n",
      "Epoch 4/50, Loss: 5.5252, Accuracy: 0.0063, Val Loss: 5.5667, Val Accuracy: 0.0034\n",
      "Epoch 5/50, Loss: 5.4975, Accuracy: 0.0087, Val Loss: 5.5911, Val Accuracy: 0.0037\n",
      "Epoch 6/50, Loss: 5.4574, Accuracy: 0.0114, Val Loss: 5.6166, Val Accuracy: 0.0028\n",
      "Early stopping\n",
      "Accuracy for byte 6: 0.39%\n",
      "\n",
      "Training for byte 7...\n",
      "Epoch 1/50, Loss: 5.5465, Accuracy: 0.0036, Val Loss: 5.5456, Val Accuracy: 0.0039\n",
      "Epoch 2/50, Loss: 5.5445, Accuracy: 0.0041, Val Loss: 5.5468, Val Accuracy: 0.0034\n",
      "Epoch 3/50, Loss: 5.5396, Accuracy: 0.0053, Val Loss: 5.5497, Val Accuracy: 0.0038\n",
      "Epoch 4/50, Loss: 5.5250, Accuracy: 0.0062, Val Loss: 5.5584, Val Accuracy: 0.0042\n",
      "Epoch 5/50, Loss: 5.4977, Accuracy: 0.0087, Val Loss: 5.5775, Val Accuracy: 0.0045\n",
      "Epoch 6/50, Loss: 5.4601, Accuracy: 0.0113, Val Loss: 5.6018, Val Accuracy: 0.0038\n",
      "Early stopping\n",
      "Accuracy for byte 7: 0.34%\n",
      "\n",
      "Training for byte 8...\n",
      "Epoch 1/50, Loss: 5.5465, Accuracy: 0.0040, Val Loss: 5.5467, Val Accuracy: 0.0032\n",
      "Epoch 2/50, Loss: 5.5446, Accuracy: 0.0042, Val Loss: 5.5468, Val Accuracy: 0.0042\n",
      "Epoch 3/50, Loss: 5.5400, Accuracy: 0.0051, Val Loss: 5.5513, Val Accuracy: 0.0033\n",
      "Epoch 4/50, Loss: 5.5243, Accuracy: 0.0072, Val Loss: 5.5660, Val Accuracy: 0.0039\n",
      "Epoch 5/50, Loss: 5.4949, Accuracy: 0.0087, Val Loss: 5.5878, Val Accuracy: 0.0036\n",
      "Epoch 6/50, Loss: 5.4534, Accuracy: 0.0123, Val Loss: 5.6103, Val Accuracy: 0.0031\n",
      "Early stopping\n",
      "Accuracy for byte 8: 0.39%\n",
      "\n",
      "Training for byte 9...\n",
      "Epoch 1/50, Loss: 5.5465, Accuracy: 0.0040, Val Loss: 5.5457, Val Accuracy: 0.0037\n",
      "Epoch 2/50, Loss: 5.5444, Accuracy: 0.0048, Val Loss: 5.5470, Val Accuracy: 0.0046\n",
      "Epoch 3/50, Loss: 5.5398, Accuracy: 0.0050, Val Loss: 5.5513, Val Accuracy: 0.0040\n",
      "Epoch 4/50, Loss: 5.5251, Accuracy: 0.0065, Val Loss: 5.5621, Val Accuracy: 0.0032\n",
      "Epoch 5/50, Loss: 5.4964, Accuracy: 0.0085, Val Loss: 5.5855, Val Accuracy: 0.0034\n",
      "Epoch 6/50, Loss: 5.4555, Accuracy: 0.0111, Val Loss: 5.6089, Val Accuracy: 0.0034\n",
      "Early stopping\n",
      "Accuracy for byte 9: 0.39%\n",
      "\n",
      "Accuracies for all 10 bytes:\n",
      "Byte 0: 0.42%\n",
      "Byte 1: 0.33%\n",
      "Byte 2: 0.37%\n",
      "Byte 3: 0.38%\n",
      "Byte 4: 0.39%\n",
      "Byte 5: 0.39%\n",
      "Byte 6: 0.39%\n",
      "Byte 7: 0.34%\n",
      "Byte 8: 0.39%\n",
      "Byte 9: 0.39%\n"
     ]
    }
   ],
   "source": [
    "# Function to train and evaluate a model for a specific byte of the keystream\n",
    "def train_and_evaluate(X_train, y_train, X_val, y_val, X_test, y_test, byte_index):\n",
    "    # Initialize the model, loss function, and optimizer\n",
    "    model = KeystreamClassifier()\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    \n",
    "    # Convert data to PyTorch tensors\n",
    "    y_train_tensor = torch.tensor(y_train[:, byte_index], dtype=torch.long)\n",
    "    y_val_tensor = torch.tensor(y_val[:, byte_index], dtype=torch.long)\n",
    "    y_test_tensor = torch.tensor(y_test[:, byte_index], dtype=torch.long)\n",
    "    \n",
    "    # Create data loaders\n",
    "    train_dataset = torch.utils.data.TensorDataset(torch.tensor(X_train, dtype=torch.float32), y_train_tensor)\n",
    "    val_dataset = torch.utils.data.TensorDataset(torch.tensor(X_val, dtype=torch.float32), y_val_tensor)\n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "    val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=64, shuffle=False)\n",
    "    \n",
    "    # Early stopping parameters\n",
    "    patience = 5\n",
    "    best_val_loss = float('inf')\n",
    "    best_model = None\n",
    "    patience_counter = 0\n",
    "\n",
    "    # Training the model\n",
    "    num_epochs = 50\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct_train = 0\n",
    "        total_train = 0\n",
    "\n",
    "        for inputs, labels in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            correct_train += (predicted == labels).sum().item()\n",
    "            total_train += labels.size(0)\n",
    "\n",
    "        train_loss = running_loss / len(train_loader)\n",
    "        train_accuracy = correct_train / total_train\n",
    "\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        correct_val = 0\n",
    "        total_val = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                correct_val += (predicted == labels).sum().item()\n",
    "                total_val += labels.size(0)\n",
    "\n",
    "        val_loss /= len(val_loader)\n",
    "        val_accuracy = correct_val / total_val\n",
    "\n",
    "        print(f'Epoch {epoch+1}/{num_epochs}, Loss: {train_loss:.4f}, Accuracy: {train_accuracy:.4f}, Val Loss: {val_loss:.4f}, Val Accuracy: {val_accuracy:.4f}')\n",
    "\n",
    "        # Early stopping\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            best_model = model.state_dict()\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= patience:\n",
    "                print(\"Early stopping\")\n",
    "                break\n",
    "\n",
    "    # Load the best model\n",
    "    model.load_state_dict(best_model)\n",
    "\n",
    "    # Evaluate the model on the test set\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        outputs = model(torch.tensor(X_test, dtype=torch.float32))\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        test_accuracy = accuracy_score(y_test[:, byte_index], predicted.numpy())\n",
    "        return test_accuracy\n",
    "\n",
    "# Train and evaluate the model for each byte and print the accuracy\n",
    "accuracies = []\n",
    "for byte_index in range(10):\n",
    "    print(f'\\nTraining for byte {byte_index}...')\n",
    "    accuracy = train_and_evaluate(X_train, y_train, X_val, y_val, X_test, y_test, byte_index)\n",
    "    accuracies.append(accuracy)\n",
    "    print(f'Accuracy for byte {byte_index}: {accuracy * 100:.2f}%')\n",
    "\n",
    "# Print all accuracies\n",
    "print(\"\\nAccuracies for all 10 bytes:\")\n",
    "for byte_index, accuracy in enumerate(accuracies):\n",
    "    print(f'Byte {byte_index}: {accuracy * 100:.2f}%')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7440e52-551c-4e7d-8681-51082421d8de",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## LR=0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8ed8cf0b-39e8-42ba-a1d3-9ed61c6dc6f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training for byte 0...\n",
      "Epoch 1/15, Loss: 5.5503, Accuracy: 0.0040, Val Loss: 5.5500, Val Accuracy: 0.0032\n",
      "Epoch 2/15, Loss: 5.5496, Accuracy: 0.0040, Val Loss: 5.5514, Val Accuracy: 0.0037\n",
      "Epoch 3/15, Loss: 5.5500, Accuracy: 0.0038, Val Loss: 5.5513, Val Accuracy: 0.0042\n",
      "Epoch 4/15, Loss: 5.5501, Accuracy: 0.0041, Val Loss: 5.5520, Val Accuracy: 0.0041\n",
      "Epoch 5/15, Loss: 5.5501, Accuracy: 0.0040, Val Loss: 5.5482, Val Accuracy: 0.0026\n",
      "Epoch 6/15, Loss: 5.5500, Accuracy: 0.0039, Val Loss: 5.5484, Val Accuracy: 0.0036\n",
      "Epoch 7/15, Loss: 5.5501, Accuracy: 0.0038, Val Loss: 5.5522, Val Accuracy: 0.0026\n",
      "Epoch 8/15, Loss: 5.5500, Accuracy: 0.0040, Val Loss: 5.5498, Val Accuracy: 0.0033\n",
      "Epoch 9/15, Loss: 5.5499, Accuracy: 0.0040, Val Loss: 5.5514, Val Accuracy: 0.0033\n",
      "Epoch 10/15, Loss: 5.5501, Accuracy: 0.0041, Val Loss: 5.5508, Val Accuracy: 0.0034\n",
      "Early stopping\n",
      "Accuracy for byte 0: 0.46%\n",
      "\n",
      "Training for byte 1...\n",
      "Epoch 1/15, Loss: 5.5503, Accuracy: 0.0039, Val Loss: 5.5508, Val Accuracy: 0.0039\n",
      "Epoch 2/15, Loss: 5.5500, Accuracy: 0.0041, Val Loss: 5.5497, Val Accuracy: 0.0038\n",
      "Epoch 3/15, Loss: 5.5501, Accuracy: 0.0035, Val Loss: 5.5509, Val Accuracy: 0.0043\n",
      "Epoch 4/15, Loss: 5.5499, Accuracy: 0.0040, Val Loss: 5.5508, Val Accuracy: 0.0040\n",
      "Epoch 5/15, Loss: 5.5499, Accuracy: 0.0040, Val Loss: 5.5509, Val Accuracy: 0.0050\n",
      "Epoch 6/15, Loss: 5.5501, Accuracy: 0.0040, Val Loss: 5.5499, Val Accuracy: 0.0034\n",
      "Epoch 7/15, Loss: 5.5501, Accuracy: 0.0039, Val Loss: 5.5496, Val Accuracy: 0.0036\n",
      "Epoch 8/15, Loss: 5.5499, Accuracy: 0.0037, Val Loss: 5.5500, Val Accuracy: 0.0034\n",
      "Epoch 9/15, Loss: 5.5498, Accuracy: 0.0039, Val Loss: 5.5505, Val Accuracy: 0.0041\n",
      "Epoch 10/15, Loss: 5.5499, Accuracy: 0.0037, Val Loss: 5.5526, Val Accuracy: 0.0034\n",
      "Epoch 11/15, Loss: 5.5498, Accuracy: 0.0040, Val Loss: 5.5506, Val Accuracy: 0.0048\n",
      "Epoch 12/15, Loss: 5.5499, Accuracy: 0.0038, Val Loss: 5.5514, Val Accuracy: 0.0045\n",
      "Early stopping\n",
      "Accuracy for byte 1: 0.34%\n",
      "\n",
      "Training for byte 2...\n",
      "Epoch 1/15, Loss: 5.5504, Accuracy: 0.0041, Val Loss: 5.5499, Val Accuracy: 0.0039\n",
      "Epoch 2/15, Loss: 5.5500, Accuracy: 0.0040, Val Loss: 5.5485, Val Accuracy: 0.0043\n",
      "Epoch 3/15, Loss: 5.5497, Accuracy: 0.0038, Val Loss: 5.5513, Val Accuracy: 0.0030\n",
      "Epoch 4/15, Loss: 5.5500, Accuracy: 0.0040, Val Loss: 5.5503, Val Accuracy: 0.0040\n",
      "Epoch 5/15, Loss: 5.5499, Accuracy: 0.0037, Val Loss: 5.5511, Val Accuracy: 0.0043\n",
      "Epoch 6/15, Loss: 5.5500, Accuracy: 0.0039, Val Loss: 5.5501, Val Accuracy: 0.0047\n",
      "Epoch 7/15, Loss: 5.5499, Accuracy: 0.0040, Val Loss: 5.5512, Val Accuracy: 0.0048\n",
      "Early stopping\n",
      "Accuracy for byte 2: 0.40%\n",
      "\n",
      "Training for byte 3...\n",
      "Epoch 1/15, Loss: 5.5501, Accuracy: 0.0037, Val Loss: 5.5519, Val Accuracy: 0.0042\n",
      "Epoch 2/15, Loss: 5.5497, Accuracy: 0.0041, Val Loss: 5.5520, Val Accuracy: 0.0051\n",
      "Epoch 3/15, Loss: 5.5497, Accuracy: 0.0042, Val Loss: 5.5523, Val Accuracy: 0.0034\n",
      "Epoch 4/15, Loss: 5.5499, Accuracy: 0.0036, Val Loss: 5.5502, Val Accuracy: 0.0040\n",
      "Epoch 5/15, Loss: 5.5499, Accuracy: 0.0041, Val Loss: 5.5505, Val Accuracy: 0.0034\n",
      "Epoch 6/15, Loss: 5.5498, Accuracy: 0.0040, Val Loss: 5.5516, Val Accuracy: 0.0033\n",
      "Epoch 7/15, Loss: 5.5500, Accuracy: 0.0039, Val Loss: 5.5497, Val Accuracy: 0.0040\n",
      "Epoch 8/15, Loss: 5.5495, Accuracy: 0.0043, Val Loss: 5.5492, Val Accuracy: 0.0048\n",
      "Epoch 9/15, Loss: 5.5499, Accuracy: 0.0036, Val Loss: 5.5506, Val Accuracy: 0.0035\n",
      "Epoch 10/15, Loss: 5.5499, Accuracy: 0.0040, Val Loss: 5.5498, Val Accuracy: 0.0044\n",
      "Epoch 11/15, Loss: 5.5500, Accuracy: 0.0041, Val Loss: 5.5509, Val Accuracy: 0.0038\n",
      "Epoch 12/15, Loss: 5.5497, Accuracy: 0.0040, Val Loss: 5.5508, Val Accuracy: 0.0031\n",
      "Epoch 13/15, Loss: 5.5499, Accuracy: 0.0042, Val Loss: 5.5508, Val Accuracy: 0.0034\n",
      "Early stopping\n",
      "Accuracy for byte 3: 0.44%\n",
      "\n",
      "Training for byte 4...\n",
      "Epoch 1/15, Loss: 5.5504, Accuracy: 0.0037, Val Loss: 5.5503, Val Accuracy: 0.0042\n",
      "Epoch 2/15, Loss: 5.5502, Accuracy: 0.0040, Val Loss: 5.5512, Val Accuracy: 0.0033\n",
      "Epoch 3/15, Loss: 5.5500, Accuracy: 0.0038, Val Loss: 5.5507, Val Accuracy: 0.0037\n",
      "Epoch 4/15, Loss: 5.5501, Accuracy: 0.0039, Val Loss: 5.5494, Val Accuracy: 0.0035\n",
      "Epoch 5/15, Loss: 5.5500, Accuracy: 0.0038, Val Loss: 5.5508, Val Accuracy: 0.0032\n",
      "Epoch 6/15, Loss: 5.5500, Accuracy: 0.0038, Val Loss: 5.5506, Val Accuracy: 0.0040\n",
      "Epoch 7/15, Loss: 5.5502, Accuracy: 0.0043, Val Loss: 5.5493, Val Accuracy: 0.0036\n",
      "Epoch 8/15, Loss: 5.5501, Accuracy: 0.0036, Val Loss: 5.5487, Val Accuracy: 0.0036\n",
      "Epoch 9/15, Loss: 5.5501, Accuracy: 0.0040, Val Loss: 5.5519, Val Accuracy: 0.0042\n",
      "Epoch 10/15, Loss: 5.5500, Accuracy: 0.0037, Val Loss: 5.5504, Val Accuracy: 0.0038\n",
      "Epoch 11/15, Loss: 5.5502, Accuracy: 0.0041, Val Loss: 5.5507, Val Accuracy: 0.0038\n",
      "Epoch 12/15, Loss: 5.5502, Accuracy: 0.0038, Val Loss: 5.5495, Val Accuracy: 0.0036\n",
      "Epoch 13/15, Loss: 5.5502, Accuracy: 0.0042, Val Loss: 5.5487, Val Accuracy: 0.0034\n",
      "Early stopping\n",
      "Accuracy for byte 4: 0.36%\n",
      "\n",
      "Training for byte 5...\n",
      "Epoch 1/15, Loss: 5.5503, Accuracy: 0.0040, Val Loss: 5.5497, Val Accuracy: 0.0032\n",
      "Epoch 2/15, Loss: 5.5502, Accuracy: 0.0040, Val Loss: 5.5502, Val Accuracy: 0.0035\n",
      "Epoch 3/15, Loss: 5.5500, Accuracy: 0.0041, Val Loss: 5.5498, Val Accuracy: 0.0044\n",
      "Epoch 4/15, Loss: 5.5500, Accuracy: 0.0041, Val Loss: 5.5492, Val Accuracy: 0.0036\n",
      "Epoch 5/15, Loss: 5.5499, Accuracy: 0.0041, Val Loss: 5.5497, Val Accuracy: 0.0040\n",
      "Epoch 6/15, Loss: 5.5501, Accuracy: 0.0041, Val Loss: 5.5492, Val Accuracy: 0.0034\n",
      "Epoch 7/15, Loss: 5.5501, Accuracy: 0.0037, Val Loss: 5.5495, Val Accuracy: 0.0040\n",
      "Epoch 8/15, Loss: 5.5500, Accuracy: 0.0038, Val Loss: 5.5490, Val Accuracy: 0.0034\n",
      "Epoch 9/15, Loss: 5.5500, Accuracy: 0.0039, Val Loss: 5.5510, Val Accuracy: 0.0035\n",
      "Epoch 10/15, Loss: 5.5501, Accuracy: 0.0040, Val Loss: 5.5503, Val Accuracy: 0.0038\n",
      "Epoch 11/15, Loss: 5.5501, Accuracy: 0.0041, Val Loss: 5.5495, Val Accuracy: 0.0047\n",
      "Epoch 12/15, Loss: 5.5500, Accuracy: 0.0039, Val Loss: 5.5508, Val Accuracy: 0.0043\n",
      "Epoch 13/15, Loss: 5.5498, Accuracy: 0.0040, Val Loss: 5.5503, Val Accuracy: 0.0040\n",
      "Early stopping\n",
      "Accuracy for byte 5: 0.36%\n",
      "\n",
      "Training for byte 6...\n",
      "Epoch 1/15, Loss: 5.5503, Accuracy: 0.0036, Val Loss: 5.5500, Val Accuracy: 0.0040\n",
      "Epoch 2/15, Loss: 5.5498, Accuracy: 0.0042, Val Loss: 5.5510, Val Accuracy: 0.0036\n",
      "Epoch 3/15, Loss: 5.5499, Accuracy: 0.0039, Val Loss: 5.5509, Val Accuracy: 0.0037\n",
      "Epoch 4/15, Loss: 5.5498, Accuracy: 0.0040, Val Loss: 5.5512, Val Accuracy: 0.0044\n",
      "Epoch 5/15, Loss: 5.5500, Accuracy: 0.0039, Val Loss: 5.5505, Val Accuracy: 0.0037\n",
      "Epoch 6/15, Loss: 5.5498, Accuracy: 0.0040, Val Loss: 5.5486, Val Accuracy: 0.0040\n",
      "Epoch 7/15, Loss: 5.5500, Accuracy: 0.0040, Val Loss: 5.5491, Val Accuracy: 0.0041\n",
      "Epoch 8/15, Loss: 5.5500, Accuracy: 0.0037, Val Loss: 5.5508, Val Accuracy: 0.0037\n",
      "Epoch 9/15, Loss: 5.5500, Accuracy: 0.0039, Val Loss: 5.5491, Val Accuracy: 0.0036\n",
      "Epoch 10/15, Loss: 5.5500, Accuracy: 0.0039, Val Loss: 5.5509, Val Accuracy: 0.0033\n",
      "Epoch 11/15, Loss: 5.5499, Accuracy: 0.0039, Val Loss: 5.5497, Val Accuracy: 0.0042\n",
      "Early stopping\n",
      "Accuracy for byte 6: 0.42%\n",
      "\n",
      "Training for byte 7...\n",
      "Epoch 1/15, Loss: 5.5502, Accuracy: 0.0038, Val Loss: 5.5496, Val Accuracy: 0.0040\n",
      "Epoch 2/15, Loss: 5.5499, Accuracy: 0.0042, Val Loss: 5.5503, Val Accuracy: 0.0040\n",
      "Epoch 3/15, Loss: 5.5501, Accuracy: 0.0043, Val Loss: 5.5494, Val Accuracy: 0.0045\n",
      "Epoch 4/15, Loss: 5.5496, Accuracy: 0.0045, Val Loss: 5.5515, Val Accuracy: 0.0032\n",
      "Epoch 5/15, Loss: 5.5501, Accuracy: 0.0040, Val Loss: 5.5485, Val Accuracy: 0.0043\n",
      "Epoch 6/15, Loss: 5.5501, Accuracy: 0.0038, Val Loss: 5.5503, Val Accuracy: 0.0040\n",
      "Epoch 7/15, Loss: 5.5498, Accuracy: 0.0041, Val Loss: 5.5516, Val Accuracy: 0.0043\n",
      "Epoch 8/15, Loss: 5.5500, Accuracy: 0.0037, Val Loss: 5.5490, Val Accuracy: 0.0034\n",
      "Epoch 9/15, Loss: 5.5499, Accuracy: 0.0037, Val Loss: 5.5478, Val Accuracy: 0.0048\n",
      "Epoch 10/15, Loss: 5.5500, Accuracy: 0.0038, Val Loss: 5.5499, Val Accuracy: 0.0032\n",
      "Epoch 11/15, Loss: 5.5499, Accuracy: 0.0037, Val Loss: 5.5499, Val Accuracy: 0.0033\n",
      "Epoch 12/15, Loss: 5.5499, Accuracy: 0.0041, Val Loss: 5.5505, Val Accuracy: 0.0041\n",
      "Epoch 13/15, Loss: 5.5498, Accuracy: 0.0040, Val Loss: 5.5511, Val Accuracy: 0.0035\n",
      "Epoch 14/15, Loss: 5.5497, Accuracy: 0.0038, Val Loss: 5.5510, Val Accuracy: 0.0040\n",
      "Early stopping\n",
      "Accuracy for byte 7: 0.37%\n",
      "\n",
      "Training for byte 8...\n",
      "Epoch 1/15, Loss: 5.5504, Accuracy: 0.0035, Val Loss: 5.5496, Val Accuracy: 0.0044\n",
      "Epoch 2/15, Loss: 5.5500, Accuracy: 0.0039, Val Loss: 5.5489, Val Accuracy: 0.0039\n",
      "Epoch 3/15, Loss: 5.5500, Accuracy: 0.0038, Val Loss: 5.5496, Val Accuracy: 0.0040\n",
      "Epoch 4/15, Loss: 5.5499, Accuracy: 0.0038, Val Loss: 5.5497, Val Accuracy: 0.0037\n",
      "Epoch 5/15, Loss: 5.5502, Accuracy: 0.0042, Val Loss: 5.5493, Val Accuracy: 0.0039\n",
      "Epoch 6/15, Loss: 5.5501, Accuracy: 0.0039, Val Loss: 5.5488, Val Accuracy: 0.0041\n",
      "Epoch 7/15, Loss: 5.5500, Accuracy: 0.0033, Val Loss: 5.5497, Val Accuracy: 0.0040\n",
      "Epoch 8/15, Loss: 5.5500, Accuracy: 0.0036, Val Loss: 5.5496, Val Accuracy: 0.0032\n",
      "Epoch 9/15, Loss: 5.5501, Accuracy: 0.0037, Val Loss: 5.5509, Val Accuracy: 0.0034\n",
      "Epoch 10/15, Loss: 5.5500, Accuracy: 0.0041, Val Loss: 5.5503, Val Accuracy: 0.0032\n",
      "Epoch 11/15, Loss: 5.5501, Accuracy: 0.0042, Val Loss: 5.5499, Val Accuracy: 0.0039\n",
      "Early stopping\n",
      "Accuracy for byte 8: 0.47%\n",
      "\n",
      "Training for byte 9...\n",
      "Epoch 1/15, Loss: 5.5502, Accuracy: 0.0041, Val Loss: 5.5487, Val Accuracy: 0.0052\n",
      "Epoch 2/15, Loss: 5.5498, Accuracy: 0.0036, Val Loss: 5.5500, Val Accuracy: 0.0036\n",
      "Epoch 3/15, Loss: 5.5500, Accuracy: 0.0037, Val Loss: 5.5487, Val Accuracy: 0.0047\n",
      "Epoch 4/15, Loss: 5.5497, Accuracy: 0.0039, Val Loss: 5.5498, Val Accuracy: 0.0041\n",
      "Epoch 5/15, Loss: 5.5499, Accuracy: 0.0039, Val Loss: 5.5489, Val Accuracy: 0.0045\n",
      "Epoch 6/15, Loss: 5.5501, Accuracy: 0.0040, Val Loss: 5.5491, Val Accuracy: 0.0047\n",
      "Early stopping\n",
      "Accuracy for byte 9: 0.43%\n",
      "\n",
      "Accuracies for all 10 bytes:\n",
      "Byte 0: 0.46%\n",
      "Byte 1: 0.34%\n",
      "Byte 2: 0.40%\n",
      "Byte 3: 0.44%\n",
      "Byte 4: 0.36%\n",
      "Byte 5: 0.36%\n",
      "Byte 6: 0.42%\n",
      "Byte 7: 0.37%\n",
      "Byte 8: 0.47%\n",
      "Byte 9: 0.43%\n"
     ]
    }
   ],
   "source": [
    "# Function to train and evaluate a model for a specific byte of the keystream\n",
    "def train_and_evaluate(X_train, y_train, X_val, y_val, X_test, y_test, byte_index):\n",
    "    # Initialize the model, loss function, and optimizer\n",
    "    model = KeystreamClassifier()\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "    \n",
    "    # Convert data to PyTorch tensors\n",
    "    y_train_tensor = torch.tensor(y_train[:, byte_index], dtype=torch.long)\n",
    "    y_val_tensor = torch.tensor(y_val[:, byte_index], dtype=torch.long)\n",
    "    y_test_tensor = torch.tensor(y_test[:, byte_index], dtype=torch.long)\n",
    "    \n",
    "    # Create data loaders\n",
    "    train_dataset = torch.utils.data.TensorDataset(torch.tensor(X_train, dtype=torch.float32), y_train_tensor)\n",
    "    val_dataset = torch.utils.data.TensorDataset(torch.tensor(X_val, dtype=torch.float32), y_val_tensor)\n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "    val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=64, shuffle=False)\n",
    "    \n",
    "    # Early stopping parameters\n",
    "    patience = 5\n",
    "    best_val_loss = float('inf')\n",
    "    best_model = None\n",
    "    patience_counter = 0\n",
    "\n",
    "    # Training the model\n",
    "    num_epochs = 15\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct_train = 0\n",
    "        total_train = 0\n",
    "\n",
    "        for inputs, labels in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            correct_train += (predicted == labels).sum().item()\n",
    "            total_train += labels.size(0)\n",
    "\n",
    "        train_loss = running_loss / len(train_loader)\n",
    "        train_accuracy = correct_train / total_train\n",
    "\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        correct_val = 0\n",
    "        total_val = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                correct_val += (predicted == labels).sum().item()\n",
    "                total_val += labels.size(0)\n",
    "\n",
    "        val_loss /= len(val_loader)\n",
    "        val_accuracy = correct_val / total_val\n",
    "\n",
    "        print(f'Epoch {epoch+1}/{num_epochs}, Loss: {train_loss:.4f}, Accuracy: {train_accuracy:.4f}, Val Loss: {val_loss:.4f}, Val Accuracy: {val_accuracy:.4f}')\n",
    "\n",
    "        # Early stopping\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            best_model = model.state_dict()\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= patience:\n",
    "                print(\"Early stopping\")\n",
    "                break\n",
    "\n",
    "    # Load the best model\n",
    "    model.load_state_dict(best_model)\n",
    "\n",
    "    # Evaluate the model on the test set\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        outputs = model(torch.tensor(X_test, dtype=torch.float32))\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        test_accuracy = accuracy_score(y_test[:, byte_index], predicted.numpy())\n",
    "        return test_accuracy\n",
    "\n",
    "# Train and evaluate the model for each byte and print the accuracy\n",
    "accuracies = []\n",
    "for byte_index in range(10):\n",
    "    print(f'\\nTraining for byte {byte_index}...')\n",
    "    accuracy = train_and_evaluate(X_train, y_train, X_val, y_val, X_test, y_test, byte_index)\n",
    "    accuracies.append(accuracy)\n",
    "    print(f'Accuracy for byte {byte_index}: {accuracy * 100:.2f}%')\n",
    "\n",
    "# Print all accuracies\n",
    "print(\"\\nAccuracies for all 10 bytes:\")\n",
    "for byte_index, accuracy in enumerate(accuracies):\n",
    "    print(f'Byte {byte_index}: {accuracy * 100:.2f}%')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "302d17ad-21d1-4517-af7c-98b616c66844",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Adding sigmoid layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3e9a95ec-aacb-4978-bff7-acc1d9f8927d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2494b87c-27c1-43ea-bf54-e13d1b2408e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data from CSV\n",
    "data = pd.read_csv('keystream_records_val.csv')\n",
    "\n",
    "# Separate the input features (64-bit key) and the targets (10 bytes of keystream)\n",
    "X = data.iloc[:, :64].values  # First 64 columns are the 64-bit key\n",
    "y = data.iloc[:, 64:74].values   # Next 10 columns are the 10 bytes of the keystream\n",
    "\n",
    "# Convert the target to categorical (byte values range from 0 to 255)\n",
    "y = y.astype(np.uint8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "10327cdb-69d6-4dad-9f1b-f1fca5309ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training, validation, and testing sets (70-10-20 split)\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.67, random_state=42)  # 0.67 * 0.3 ≈ 0.2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "505f0f43-4aab-4da6-bbb4-eaec3fd8cb89",
   "metadata": {},
   "outputs": [],
   "source": [
    "class KeystreamClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(KeystreamClassifier, self).__init__()\n",
    "        self.fc1 = nn.Linear(64, 128)\n",
    "        self.fc2 = nn.Linear(128, 256)\n",
    "        self.fc3 = nn.Linear(256, 8)  # Output layer with 8 neurons\n",
    "        self.sigmoid = nn.Sigmoid()   # Sigmoid activation\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.sigmoid(self.fc3(x))  # Apply sigmoid to the output layer\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d2a03ffc-654b-4091-9198-f934b220c4af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training for byte 0...\n",
      "Epoch 1/50, Loss: 0.6933, Accuracy: 0.4991, Val Loss: 0.6932, Val Accuracy: 0.4988\n",
      "Epoch 2/50, Loss: 0.6931, Accuracy: 0.5036, Val Loss: 0.6932, Val Accuracy: 0.5019\n",
      "Epoch 3/50, Loss: 0.6931, Accuracy: 0.5058, Val Loss: 0.6934, Val Accuracy: 0.5001\n",
      "Epoch 4/50, Loss: 0.6929, Accuracy: 0.5086, Val Loss: 0.6936, Val Accuracy: 0.4976\n",
      "Epoch 5/50, Loss: 0.6924, Accuracy: 0.5140, Val Loss: 0.6939, Val Accuracy: 0.4983\n",
      "Epoch 6/50, Loss: 0.6917, Accuracy: 0.5197, Val Loss: 0.6947, Val Accuracy: 0.5004\n",
      "Epoch 7/50, Loss: 0.6905, Accuracy: 0.5250, Val Loss: 0.6953, Val Accuracy: 0.4999\n",
      "Early stopping\n",
      "Accuracy for byte 0: 49.75%\n",
      "\n",
      "Training for byte 1...\n",
      "Epoch 1/50, Loss: 0.6933, Accuracy: 0.5008, Val Loss: 0.6932, Val Accuracy: 0.5013\n",
      "Epoch 2/50, Loss: 0.6931, Accuracy: 0.5034, Val Loss: 0.6934, Val Accuracy: 0.4986\n",
      "Epoch 3/50, Loss: 0.6930, Accuracy: 0.5068, Val Loss: 0.6937, Val Accuracy: 0.5017\n",
      "Epoch 4/50, Loss: 0.6928, Accuracy: 0.5107, Val Loss: 0.6936, Val Accuracy: 0.4986\n",
      "Epoch 5/50, Loss: 0.6923, Accuracy: 0.5161, Val Loss: 0.6941, Val Accuracy: 0.5008\n",
      "Epoch 6/50, Loss: 0.6915, Accuracy: 0.5208, Val Loss: 0.6947, Val Accuracy: 0.5022\n",
      "Early stopping\n",
      "Accuracy for byte 1: 50.02%\n",
      "\n",
      "Training for byte 2...\n",
      "Epoch 1/50, Loss: 0.6933, Accuracy: 0.5001, Val Loss: 0.6932, Val Accuracy: 0.4998\n",
      "Epoch 2/50, Loss: 0.6932, Accuracy: 0.5019, Val Loss: 0.6934, Val Accuracy: 0.5002\n",
      "Epoch 3/50, Loss: 0.6931, Accuracy: 0.5047, Val Loss: 0.6933, Val Accuracy: 0.5036\n",
      "Epoch 4/50, Loss: 0.6929, Accuracy: 0.5089, Val Loss: 0.6935, Val Accuracy: 0.5007\n",
      "Epoch 5/50, Loss: 0.6924, Accuracy: 0.5137, Val Loss: 0.6937, Val Accuracy: 0.5007\n",
      "Epoch 6/50, Loss: 0.6918, Accuracy: 0.5178, Val Loss: 0.6944, Val Accuracy: 0.4988\n",
      "Early stopping\n",
      "Accuracy for byte 2: 49.96%\n",
      "\n",
      "Training for byte 3...\n",
      "Epoch 1/50, Loss: 0.6933, Accuracy: 0.5007, Val Loss: 0.6932, Val Accuracy: 0.4985\n",
      "Epoch 2/50, Loss: 0.6932, Accuracy: 0.5027, Val Loss: 0.6932, Val Accuracy: 0.5000\n",
      "Epoch 3/50, Loss: 0.6931, Accuracy: 0.5041, Val Loss: 0.6933, Val Accuracy: 0.5009\n",
      "Epoch 4/50, Loss: 0.6929, Accuracy: 0.5076, Val Loss: 0.6936, Val Accuracy: 0.4985\n",
      "Epoch 5/50, Loss: 0.6926, Accuracy: 0.5115, Val Loss: 0.6937, Val Accuracy: 0.4995\n",
      "Epoch 6/50, Loss: 0.6920, Accuracy: 0.5165, Val Loss: 0.6942, Val Accuracy: 0.4999\n",
      "Epoch 7/50, Loss: 0.6910, Accuracy: 0.5233, Val Loss: 0.6947, Val Accuracy: 0.5018\n",
      "Early stopping\n",
      "Accuracy for byte 3: 49.95%\n",
      "\n",
      "Training for byte 4...\n",
      "Epoch 1/50, Loss: 0.6933, Accuracy: 0.5000, Val Loss: 0.6932, Val Accuracy: 0.4993\n",
      "Epoch 2/50, Loss: 0.6932, Accuracy: 0.5026, Val Loss: 0.6933, Val Accuracy: 0.4981\n",
      "Epoch 3/50, Loss: 0.6931, Accuracy: 0.5051, Val Loss: 0.6933, Val Accuracy: 0.5010\n",
      "Epoch 4/50, Loss: 0.6929, Accuracy: 0.5085, Val Loss: 0.6935, Val Accuracy: 0.5012\n",
      "Epoch 5/50, Loss: 0.6925, Accuracy: 0.5127, Val Loss: 0.6937, Val Accuracy: 0.5006\n",
      "Epoch 6/50, Loss: 0.6918, Accuracy: 0.5186, Val Loss: 0.6944, Val Accuracy: 0.4982\n",
      "Early stopping\n",
      "Accuracy for byte 4: 49.98%\n",
      "\n",
      "Training for byte 5...\n",
      "Epoch 1/50, Loss: 0.6933, Accuracy: 0.5001, Val Loss: 0.6933, Val Accuracy: 0.4985\n",
      "Epoch 2/50, Loss: 0.6932, Accuracy: 0.5031, Val Loss: 0.6932, Val Accuracy: 0.5013\n",
      "Epoch 3/50, Loss: 0.6931, Accuracy: 0.5054, Val Loss: 0.6933, Val Accuracy: 0.5019\n",
      "Epoch 4/50, Loss: 0.6929, Accuracy: 0.5088, Val Loss: 0.6935, Val Accuracy: 0.4995\n",
      "Epoch 5/50, Loss: 0.6924, Accuracy: 0.5140, Val Loss: 0.6941, Val Accuracy: 0.5001\n",
      "Epoch 6/50, Loss: 0.6916, Accuracy: 0.5202, Val Loss: 0.6946, Val Accuracy: 0.5004\n",
      "Epoch 7/50, Loss: 0.6904, Accuracy: 0.5267, Val Loss: 0.6952, Val Accuracy: 0.5016\n",
      "Early stopping\n",
      "Accuracy for byte 5: 49.88%\n",
      "\n",
      "Training for byte 6...\n",
      "Epoch 1/50, Loss: 0.6933, Accuracy: 0.5005, Val Loss: 0.6932, Val Accuracy: 0.5002\n",
      "Epoch 2/50, Loss: 0.6932, Accuracy: 0.5028, Val Loss: 0.6932, Val Accuracy: 0.5009\n",
      "Epoch 3/50, Loss: 0.6931, Accuracy: 0.5062, Val Loss: 0.6932, Val Accuracy: 0.5026\n",
      "Epoch 4/50, Loss: 0.6929, Accuracy: 0.5092, Val Loss: 0.6935, Val Accuracy: 0.5022\n",
      "Epoch 5/50, Loss: 0.6924, Accuracy: 0.5138, Val Loss: 0.6939, Val Accuracy: 0.5003\n",
      "Epoch 6/50, Loss: 0.6917, Accuracy: 0.5183, Val Loss: 0.6944, Val Accuracy: 0.4995\n",
      "Early stopping\n",
      "Accuracy for byte 6: 50.01%\n",
      "\n",
      "Training for byte 7...\n",
      "Epoch 1/50, Loss: 0.6933, Accuracy: 0.5002, Val Loss: 0.6932, Val Accuracy: 0.4973\n",
      "Epoch 2/50, Loss: 0.6932, Accuracy: 0.5031, Val Loss: 0.6932, Val Accuracy: 0.5009\n",
      "Epoch 3/50, Loss: 0.6931, Accuracy: 0.5045, Val Loss: 0.6934, Val Accuracy: 0.4996\n",
      "Epoch 4/50, Loss: 0.6929, Accuracy: 0.5088, Val Loss: 0.6936, Val Accuracy: 0.4989\n",
      "Epoch 5/50, Loss: 0.6926, Accuracy: 0.5123, Val Loss: 0.6938, Val Accuracy: 0.4990\n",
      "Epoch 6/50, Loss: 0.6919, Accuracy: 0.5180, Val Loss: 0.6942, Val Accuracy: 0.4994\n",
      "Early stopping\n",
      "Accuracy for byte 7: 49.97%\n",
      "\n",
      "Training for byte 8...\n",
      "Epoch 1/50, Loss: 0.6933, Accuracy: 0.4998, Val Loss: 0.6932, Val Accuracy: 0.5020\n",
      "Epoch 2/50, Loss: 0.6932, Accuracy: 0.5029, Val Loss: 0.6934, Val Accuracy: 0.5009\n",
      "Epoch 3/50, Loss: 0.6931, Accuracy: 0.5050, Val Loss: 0.6933, Val Accuracy: 0.5016\n",
      "Epoch 4/50, Loss: 0.6930, Accuracy: 0.5083, Val Loss: 0.6933, Val Accuracy: 0.4993\n",
      "Epoch 5/50, Loss: 0.6926, Accuracy: 0.5122, Val Loss: 0.6938, Val Accuracy: 0.4983\n",
      "Epoch 6/50, Loss: 0.6921, Accuracy: 0.5165, Val Loss: 0.6940, Val Accuracy: 0.5005\n",
      "Early stopping\n",
      "Accuracy for byte 8: 49.92%\n",
      "\n",
      "Training for byte 9...\n",
      "Epoch 1/50, Loss: 0.6933, Accuracy: 0.4996, Val Loss: 0.6932, Val Accuracy: 0.4992\n",
      "Epoch 2/50, Loss: 0.6932, Accuracy: 0.5014, Val Loss: 0.6932, Val Accuracy: 0.4984\n",
      "Epoch 3/50, Loss: 0.6931, Accuracy: 0.5048, Val Loss: 0.6934, Val Accuracy: 0.4967\n",
      "Epoch 4/50, Loss: 0.6929, Accuracy: 0.5085, Val Loss: 0.6935, Val Accuracy: 0.4998\n",
      "Epoch 5/50, Loss: 0.6926, Accuracy: 0.5117, Val Loss: 0.6939, Val Accuracy: 0.4998\n",
      "Epoch 6/50, Loss: 0.6920, Accuracy: 0.5168, Val Loss: 0.6941, Val Accuracy: 0.4993\n",
      "Epoch 7/50, Loss: 0.6911, Accuracy: 0.5217, Val Loss: 0.6948, Val Accuracy: 0.4993\n",
      "Early stopping\n",
      "Accuracy for byte 9: 50.04%\n",
      "\n",
      "Accuracies for all 10 bytes:\n",
      "Byte 0: 49.75%\n",
      "Byte 1: 50.02%\n",
      "Byte 2: 49.96%\n",
      "Byte 3: 49.95%\n",
      "Byte 4: 49.98%\n",
      "Byte 5: 49.88%\n",
      "Byte 6: 50.01%\n",
      "Byte 7: 49.97%\n",
      "Byte 8: 49.92%\n",
      "Byte 9: 50.04%\n"
     ]
    }
   ],
   "source": [
    "# Function to convert a byte to 8-bit binary format\n",
    "def byte_to_bits(byte_array):\n",
    "    return np.unpackbits(byte_array[:, np.newaxis], axis=1)\n",
    "\n",
    "# Function to train and evaluate a model for a specific byte of the keystream\n",
    "def train_and_evaluate(X_train, y_train, X_val, y_val, X_test, y_test, byte_index):\n",
    "    # Initialize the model, loss function, and optimizer\n",
    "    model = KeystreamClassifier()\n",
    "    criterion = nn.BCELoss()  # Binary Cross Entropy Loss\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    \n",
    "    # Convert data to PyTorch tensors\n",
    "    y_train_bits = torch.tensor(byte_to_bits(y_train[:, byte_index]), dtype=torch.float32)\n",
    "    y_val_bits = torch.tensor(byte_to_bits(y_val[:, byte_index]), dtype=torch.float32)\n",
    "    y_test_bits = torch.tensor(byte_to_bits(y_test[:, byte_index]), dtype=torch.float32)\n",
    "    \n",
    "    # Create data loaders\n",
    "    train_dataset = torch.utils.data.TensorDataset(torch.tensor(X_train, dtype=torch.float32), y_train_bits)\n",
    "    val_dataset = torch.utils.data.TensorDataset(torch.tensor(X_val, dtype=torch.float32), y_val_bits)\n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "    val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=64, shuffle=False)\n",
    "    \n",
    "    # Early stopping parameters\n",
    "    patience = 5\n",
    "    best_val_loss = float('inf')\n",
    "    best_model = None\n",
    "    patience_counter = 0\n",
    "\n",
    "    # Training the model\n",
    "    num_epochs = 50\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct_train = 0\n",
    "        total_train = 0\n",
    "\n",
    "        for inputs, labels in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            predicted = (outputs > 0.5).float()\n",
    "            correct_train += (predicted == labels).sum().item()\n",
    "            total_train += labels.numel()\n",
    "\n",
    "        train_loss = running_loss / len(train_loader)\n",
    "        train_accuracy = correct_train / total_train\n",
    "\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        correct_val = 0\n",
    "        total_val = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "\n",
    "                predicted = (outputs > 0.5).float()\n",
    "                correct_val += (predicted == labels).sum().item()\n",
    "                total_val += labels.numel()\n",
    "\n",
    "        val_loss /= len(val_loader)\n",
    "        val_accuracy = correct_val / total_val\n",
    "\n",
    "        print(f'Epoch {epoch+1}/{num_epochs}, Loss: {train_loss:.4f}, Accuracy: {train_accuracy:.4f}, Val Loss: {val_loss:.4f}, Val Accuracy: {val_accuracy:.4f}')\n",
    "\n",
    "        # Early stopping\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            best_model = model.state_dict()\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= patience:\n",
    "                print(\"Early stopping\")\n",
    "                break\n",
    "\n",
    "    # Load the best model\n",
    "    model.load_state_dict(best_model)\n",
    "\n",
    "    # Evaluate the model on the test set\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        outputs = model(torch.tensor(X_test, dtype=torch.float32))\n",
    "        predicted = (outputs > 0.5).float()\n",
    "        correct_test = (predicted == y_test_bits).sum().item()\n",
    "        total_test = y_test_bits.numel()\n",
    "        test_accuracy = correct_test / total_test\n",
    "        return test_accuracy\n",
    "\n",
    "# Train and evaluate the model for each byte and print the accuracy\n",
    "accuracies = []\n",
    "for byte_index in range(10):\n",
    "    print(f'\\nTraining for byte {byte_index}...')\n",
    "    accuracy = train_and_evaluate(X_train, y_train, X_val, y_val, X_test, y_test, byte_index)\n",
    "    accuracies.append(accuracy)\n",
    "    print(f'Accuracy for byte {byte_index}: {accuracy * 100:.2f}%')\n",
    "\n",
    "# Print all accuracies\n",
    "print(\"\\nAccuracies for all 10 bytes:\")\n",
    "for byte_index, accuracy in enumerate(accuracies):\n",
    "    print(f'Byte {byte_index}: {accuracy * 100:.2f}%')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dcc27f1-1372-4b81-9df1-5f4157ab59b4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Increase the no of layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9acc8751-17b5-47bc-a94b-1a1664daa904",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eb548f86-2a89-4b7a-8a91-b038e66c32da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data from CSV\n",
    "data = pd.read_csv('keystream_records_val.csv')\n",
    "\n",
    "# Separate the input features (64-bit key) and the targets (10 bytes of keystream)\n",
    "X = data.iloc[:, :64].values  # First 64 columns are the 64-bit key\n",
    "y = data.iloc[:, 64:74].values   # Next 10 columns are the 10 bytes of the keystream\n",
    "\n",
    "# Convert the target to categorical (byte values range from 0 to 255)\n",
    "y = y.astype(np.uint8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ab2ad7b5-d44d-4802-9db5-29500c8665d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training, validation, and testing sets (70-10-20 split)\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.67, random_state=42)  # 0.67 * 0.3 ≈ 0.2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "17921229-fe20-45e4-86aa-4abaf86ab621",
   "metadata": {},
   "outputs": [],
   "source": [
    "class KeystreamClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(KeystreamClassifier, self).__init__()\n",
    "        self.fc1 = nn.Linear(64, 512)\n",
    "        self.fc2 = nn.Linear(512, 512)\n",
    "        self.fc3 = nn.Linear(512, 256)\n",
    "        self.fc4 = nn.Linear(256, 256)\n",
    "        self.fc5 = nn.Linear(256, 128)\n",
    "        self.fc6 = nn.Linear(128, 256)  # Last layer with 256 neurons for classification\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = torch.relu(self.fc3(x))\n",
    "        x = torch.relu(self.fc4(x))\n",
    "        x = torch.relu(self.fc5(x))\n",
    "        x = self.fc6(x)  # No activation in the last layer\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d9e8b7ec-a47b-4c1f-a202-b03e1bdb305a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training for byte 0...\n",
      "Epoch 1/50, Loss: 5.5462, Accuracy: 0.0038, Val Loss: 5.5459, Val Accuracy: 0.0044\n",
      "Epoch 2/50, Loss: 5.5452, Accuracy: 0.0040, Val Loss: 5.5461, Val Accuracy: 0.0034\n",
      "Epoch 3/50, Loss: 5.5449, Accuracy: 0.0040, Val Loss: 5.5463, Val Accuracy: 0.0038\n",
      "Epoch 4/50, Loss: 5.5449, Accuracy: 0.0041, Val Loss: 5.5464, Val Accuracy: 0.0038\n",
      "Epoch 5/50, Loss: 5.5449, Accuracy: 0.0040, Val Loss: 5.5466, Val Accuracy: 0.0036\n",
      "Epoch 6/50, Loss: 5.5449, Accuracy: 0.0043, Val Loss: 5.5466, Val Accuracy: 0.0034\n",
      "Early stopping\n",
      "Accuracy for byte 0: 0.46%\n",
      "\n",
      "Training for byte 1...\n",
      "Epoch 1/50, Loss: 5.5463, Accuracy: 0.0041, Val Loss: 5.5464, Val Accuracy: 0.0046\n",
      "Epoch 2/50, Loss: 5.5452, Accuracy: 0.0042, Val Loss: 5.5467, Val Accuracy: 0.0036\n",
      "Epoch 3/50, Loss: 5.5449, Accuracy: 0.0040, Val Loss: 5.5468, Val Accuracy: 0.0032\n",
      "Epoch 4/50, Loss: 5.5448, Accuracy: 0.0042, Val Loss: 5.5469, Val Accuracy: 0.0032\n",
      "Epoch 5/50, Loss: 5.5447, Accuracy: 0.0042, Val Loss: 5.5470, Val Accuracy: 0.0032\n",
      "Epoch 6/50, Loss: 5.5448, Accuracy: 0.0043, Val Loss: 5.5470, Val Accuracy: 0.0032\n",
      "Early stopping\n",
      "Accuracy for byte 1: 0.36%\n",
      "\n",
      "Training for byte 2...\n",
      "Epoch 1/50, Loss: 5.5463, Accuracy: 0.0039, Val Loss: 5.5454, Val Accuracy: 0.0043\n",
      "Epoch 2/50, Loss: 5.5452, Accuracy: 0.0043, Val Loss: 5.5458, Val Accuracy: 0.0042\n",
      "Epoch 3/50, Loss: 5.5450, Accuracy: 0.0045, Val Loss: 5.5461, Val Accuracy: 0.0042\n",
      "Epoch 4/50, Loss: 5.5449, Accuracy: 0.0044, Val Loss: 5.5463, Val Accuracy: 0.0042\n",
      "Epoch 5/50, Loss: 5.5449, Accuracy: 0.0045, Val Loss: 5.5464, Val Accuracy: 0.0042\n",
      "Epoch 6/50, Loss: 5.5449, Accuracy: 0.0045, Val Loss: 5.5465, Val Accuracy: 0.0042\n",
      "Early stopping\n",
      "Accuracy for byte 2: 0.36%\n",
      "\n",
      "Training for byte 3...\n",
      "Epoch 1/50, Loss: 5.5463, Accuracy: 0.0035, Val Loss: 5.5463, Val Accuracy: 0.0031\n",
      "Epoch 2/50, Loss: 5.5451, Accuracy: 0.0043, Val Loss: 5.5464, Val Accuracy: 0.0040\n",
      "Epoch 3/50, Loss: 5.5449, Accuracy: 0.0042, Val Loss: 5.5467, Val Accuracy: 0.0031\n",
      "Epoch 4/50, Loss: 5.5447, Accuracy: 0.0042, Val Loss: 5.5468, Val Accuracy: 0.0031\n",
      "Epoch 5/50, Loss: 5.5447, Accuracy: 0.0044, Val Loss: 5.5469, Val Accuracy: 0.0031\n",
      "Epoch 6/50, Loss: 5.5447, Accuracy: 0.0044, Val Loss: 5.5470, Val Accuracy: 0.0031\n",
      "Early stopping\n",
      "Accuracy for byte 3: 0.44%\n",
      "\n",
      "Training for byte 4...\n",
      "Epoch 1/50, Loss: 5.5463, Accuracy: 0.0039, Val Loss: 5.5456, Val Accuracy: 0.0044\n",
      "Epoch 2/50, Loss: 5.5452, Accuracy: 0.0040, Val Loss: 5.5458, Val Accuracy: 0.0037\n",
      "Epoch 3/50, Loss: 5.5449, Accuracy: 0.0042, Val Loss: 5.5460, Val Accuracy: 0.0037\n",
      "Epoch 4/50, Loss: 5.5449, Accuracy: 0.0041, Val Loss: 5.5462, Val Accuracy: 0.0037\n",
      "Epoch 5/50, Loss: 5.5449, Accuracy: 0.0040, Val Loss: 5.5463, Val Accuracy: 0.0033\n",
      "Epoch 6/50, Loss: 5.5449, Accuracy: 0.0044, Val Loss: 5.5462, Val Accuracy: 0.0037\n",
      "Early stopping\n",
      "Accuracy for byte 4: 0.37%\n",
      "\n",
      "Training for byte 5...\n",
      "Epoch 1/50, Loss: 5.5464, Accuracy: 0.0038, Val Loss: 5.5458, Val Accuracy: 0.0034\n",
      "Epoch 2/50, Loss: 5.5453, Accuracy: 0.0043, Val Loss: 5.5458, Val Accuracy: 0.0037\n",
      "Epoch 3/50, Loss: 5.5450, Accuracy: 0.0042, Val Loss: 5.5460, Val Accuracy: 0.0037\n",
      "Epoch 4/50, Loss: 5.5449, Accuracy: 0.0045, Val Loss: 5.5461, Val Accuracy: 0.0037\n",
      "Epoch 5/50, Loss: 5.5448, Accuracy: 0.0044, Val Loss: 5.5462, Val Accuracy: 0.0037\n",
      "Epoch 6/50, Loss: 5.5449, Accuracy: 0.0044, Val Loss: 5.5462, Val Accuracy: 0.0037\n",
      "Epoch 7/50, Loss: 5.5448, Accuracy: 0.0045, Val Loss: 5.5463, Val Accuracy: 0.0037\n",
      "Early stopping\n",
      "Accuracy for byte 5: 0.38%\n",
      "\n",
      "Training for byte 6...\n",
      "Epoch 1/50, Loss: 5.5464, Accuracy: 0.0039, Val Loss: 5.5464, Val Accuracy: 0.0026\n",
      "Epoch 2/50, Loss: 5.5452, Accuracy: 0.0045, Val Loss: 5.5463, Val Accuracy: 0.0040\n",
      "Epoch 3/50, Loss: 5.5449, Accuracy: 0.0043, Val Loss: 5.5464, Val Accuracy: 0.0040\n",
      "Epoch 4/50, Loss: 5.5447, Accuracy: 0.0043, Val Loss: 5.5465, Val Accuracy: 0.0040\n",
      "Epoch 5/50, Loss: 5.5447, Accuracy: 0.0043, Val Loss: 5.5467, Val Accuracy: 0.0040\n",
      "Epoch 6/50, Loss: 5.5447, Accuracy: 0.0044, Val Loss: 5.5467, Val Accuracy: 0.0040\n",
      "Epoch 7/50, Loss: 5.5447, Accuracy: 0.0043, Val Loss: 5.5467, Val Accuracy: 0.0040\n",
      "Early stopping\n",
      "Accuracy for byte 6: 0.35%\n",
      "\n",
      "Training for byte 7...\n",
      "Epoch 1/50, Loss: 5.5462, Accuracy: 0.0038, Val Loss: 5.5460, Val Accuracy: 0.0040\n",
      "Epoch 2/50, Loss: 5.5452, Accuracy: 0.0040, Val Loss: 5.5460, Val Accuracy: 0.0040\n",
      "Epoch 3/50, Loss: 5.5449, Accuracy: 0.0039, Val Loss: 5.5460, Val Accuracy: 0.0040\n",
      "Epoch 4/50, Loss: 5.5448, Accuracy: 0.0042, Val Loss: 5.5462, Val Accuracy: 0.0043\n",
      "Epoch 5/50, Loss: 5.5448, Accuracy: 0.0040, Val Loss: 5.5465, Val Accuracy: 0.0043\n",
      "Epoch 6/50, Loss: 5.5448, Accuracy: 0.0043, Val Loss: 5.5465, Val Accuracy: 0.0043\n",
      "Epoch 7/50, Loss: 5.5448, Accuracy: 0.0044, Val Loss: 5.5464, Val Accuracy: 0.0043\n",
      "Early stopping\n",
      "Accuracy for byte 7: 0.33%\n",
      "\n",
      "Training for byte 8...\n",
      "Epoch 1/50, Loss: 5.5465, Accuracy: 0.0037, Val Loss: 5.5454, Val Accuracy: 0.0045\n",
      "Epoch 2/50, Loss: 5.5454, Accuracy: 0.0043, Val Loss: 5.5455, Val Accuracy: 0.0045\n",
      "Epoch 3/50, Loss: 5.5451, Accuracy: 0.0041, Val Loss: 5.5459, Val Accuracy: 0.0039\n",
      "Epoch 4/50, Loss: 5.5450, Accuracy: 0.0042, Val Loss: 5.5460, Val Accuracy: 0.0045\n",
      "Epoch 5/50, Loss: 5.5449, Accuracy: 0.0043, Val Loss: 5.5462, Val Accuracy: 0.0039\n",
      "Epoch 6/50, Loss: 5.5449, Accuracy: 0.0043, Val Loss: 5.5463, Val Accuracy: 0.0039\n",
      "Early stopping\n",
      "Accuracy for byte 8: 0.40%\n",
      "\n",
      "Training for byte 9...\n",
      "Epoch 1/50, Loss: 5.5463, Accuracy: 0.0038, Val Loss: 5.5455, Val Accuracy: 0.0035\n",
      "Epoch 2/50, Loss: 5.5452, Accuracy: 0.0041, Val Loss: 5.5455, Val Accuracy: 0.0035\n",
      "Epoch 3/50, Loss: 5.5449, Accuracy: 0.0044, Val Loss: 5.5455, Val Accuracy: 0.0040\n",
      "Epoch 4/50, Loss: 5.5448, Accuracy: 0.0044, Val Loss: 5.5457, Val Accuracy: 0.0040\n",
      "Epoch 5/50, Loss: 5.5447, Accuracy: 0.0043, Val Loss: 5.5458, Val Accuracy: 0.0040\n",
      "Epoch 6/50, Loss: 5.5448, Accuracy: 0.0045, Val Loss: 5.5460, Val Accuracy: 0.0047\n",
      "Epoch 7/50, Loss: 5.5447, Accuracy: 0.0043, Val Loss: 5.5457, Val Accuracy: 0.0040\n",
      "Early stopping\n",
      "Accuracy for byte 9: 0.39%\n",
      "\n",
      "Accuracies for all 10 bytes:\n",
      "Byte 0: 0.46%\n",
      "Byte 1: 0.36%\n",
      "Byte 2: 0.36%\n",
      "Byte 3: 0.44%\n",
      "Byte 4: 0.37%\n",
      "Byte 5: 0.38%\n",
      "Byte 6: 0.35%\n",
      "Byte 7: 0.33%\n",
      "Byte 8: 0.40%\n",
      "Byte 9: 0.39%\n"
     ]
    }
   ],
   "source": [
    "# Function to train and evaluate a model for a specific byte of the keystream\n",
    "def train_and_evaluate(X_train, y_train, X_val, y_val, X_test, y_test, byte_index):\n",
    "    # Initialize the model, loss function, and optimizer\n",
    "    model = KeystreamClassifier()\n",
    "    criterion = nn.CrossEntropyLoss()  # Cross-Entropy Loss for classification\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    \n",
    "    # Convert data to PyTorch tensors\n",
    "    y_train_tensor = torch.tensor(y_train[:, byte_index], dtype=torch.long)\n",
    "    y_val_tensor = torch.tensor(y_val[:, byte_index], dtype=torch.long)\n",
    "    y_test_tensor = torch.tensor(y_test[:, byte_index], dtype=torch.long)\n",
    "    \n",
    "    # Create data loaders\n",
    "    train_dataset = torch.utils.data.TensorDataset(torch.tensor(X_train, dtype=torch.float32), y_train_tensor)\n",
    "    val_dataset = torch.utils.data.TensorDataset(torch.tensor(X_val, dtype=torch.float32), y_val_tensor)\n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "    val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=64, shuffle=False)\n",
    "    \n",
    "    # Early stopping parameters\n",
    "    patience = 5\n",
    "    best_val_loss = float('inf')\n",
    "    best_model = None\n",
    "    patience_counter = 0\n",
    "\n",
    "    # Training the model\n",
    "    num_epochs = 50\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct_train = 0\n",
    "        total_train = 0\n",
    "\n",
    "        for inputs, labels in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            correct_train += (predicted == labels).sum().item()\n",
    "            total_train += labels.size(0)\n",
    "\n",
    "        train_loss = running_loss / len(train_loader)\n",
    "        train_accuracy = correct_train / total_train\n",
    "\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        correct_val = 0\n",
    "        total_val = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                correct_val += (predicted == labels).sum().item()\n",
    "                total_val += labels.size(0)\n",
    "\n",
    "        val_loss /= len(val_loader)\n",
    "        val_accuracy = correct_val / total_val\n",
    "\n",
    "        print(f'Epoch {epoch+1}/{num_epochs}, Loss: {train_loss:.4f}, Accuracy: {train_accuracy:.4f}, Val Loss: {val_loss:.4f}, Val Accuracy: {val_accuracy:.4f}')\n",
    "\n",
    "        # Early stopping\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            best_model = model.state_dict()\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= patience:\n",
    "                print(\"Early stopping\")\n",
    "                break\n",
    "\n",
    "    # Load the best model\n",
    "    model.load_state_dict(best_model)\n",
    "\n",
    "    # Evaluate the model on the test set\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        outputs = model(torch.tensor(X_test, dtype=torch.float32))\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        test_accuracy = accuracy_score(y_test[:, byte_index], predicted.numpy())\n",
    "        return test_accuracy\n",
    "\n",
    "# Train and evaluate the model for each byte and print the accuracy\n",
    "accuracies = []\n",
    "for byte_index in range(10):\n",
    "    print(f'\\nTraining for byte {byte_index}...')\n",
    "    accuracy = train_and_evaluate(X_train, y_train, X_val, y_val, X_test, y_test, byte_index)\n",
    "    accuracies.append(accuracy)\n",
    "    print(f'Accuracy for byte {byte_index}: {accuracy * 100:.2f}%')\n",
    "\n",
    "# Print all accuracies\n",
    "print(\"\\nAccuracies for all 10 bytes:\")\n",
    "for byte_index, accuracy in enumerate(accuracies):\n",
    "    print(f'Byte {byte_index}: {accuracy * 100:.2f}%')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1a079aa-57a7-4814-bdf2-ffa7970f213c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Schduler "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8756899d-ad2f-4288-ad1c-77615ef4af47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "35fbcf3d-711f-4fa0-bb64-fc9d3da39896",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data from CSV\n",
    "data = pd.read_csv('keystream_records_10lakh.csv')\n",
    "\n",
    "# Separate the input features (64-bit key) and the targets (10 bytes of keystream)\n",
    "X = data.iloc[:, :64].values  # First 64 columns are the 64-bit key\n",
    "y = data.iloc[:, 64:74].values   # Next 10 columns are the 10 bytes of the keystream\n",
    "\n",
    "# Convert the target to categorical (byte values range from 0 to 255)\n",
    "y = y.astype(np.uint8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4981df01-12f9-4274-8905-8e9cc1ab10b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training, validation, and testing sets (70-10-20 split)\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.67, random_state=42)  # 0.67 * 0.3 ≈ 0.2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6c5d5321-595d-4e33-9eef-bce29a96e3d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImprovedKeystreamClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ImprovedKeystreamClassifier, self).__init__()\n",
    "        self.fc1 = nn.Linear(64, 512)\n",
    "        self.bn1 = nn.BatchNorm1d(512)\n",
    "        self.fc2 = nn.Linear(512, 512)\n",
    "        self.bn2 = nn.BatchNorm1d(512)\n",
    "        self.fc3 = nn.Linear(512, 256)\n",
    "        self.bn3 = nn.BatchNorm1d(256)\n",
    "        self.fc4 = nn.Linear(256, 256)\n",
    "        self.bn4 = nn.BatchNorm1d(256)\n",
    "        self.fc5 = nn.Linear(256, 128)\n",
    "        self.bn5 = nn.BatchNorm1d(128)\n",
    "        self.fc6 = nn.Linear(128, 256)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.bn1(self.fc1(x)))\n",
    "        x = self.dropout(x)\n",
    "        x = torch.relu(self.bn2(self.fc2(x)))\n",
    "        x = self.dropout(x)\n",
    "        x = torch.relu(self.bn3(self.fc3(x)))\n",
    "        x = self.dropout(x)\n",
    "        x = torch.relu(self.bn4(self.fc4(x)))\n",
    "        x = self.dropout(x)\n",
    "        x = torch.relu(self.bn5(self.fc5(x)))\n",
    "        x = self.fc6(x)  # No activation in the last layer\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4c40fd2-c81a-425a-be06-517020422318",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# L1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8c9c7c26-2b0f-4ff3-ba8a-2b6c33357a5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training for byte 0...\n",
      "Epoch 1/50, Loss: 5.5617, Accuracy: 0.0038, Val Loss: 5.5499, Val Accuracy: 0.0030\n",
      "Epoch 2/50, Loss: 5.5501, Accuracy: 0.0040, Val Loss: 5.5497, Val Accuracy: 0.0034\n",
      "Epoch 3/50, Loss: 5.5505, Accuracy: 0.0037, Val Loss: 5.5493, Val Accuracy: 0.0033\n",
      "Epoch 4/50, Loss: 5.5498, Accuracy: 0.0040, Val Loss: 5.5498, Val Accuracy: 0.0032\n",
      "Epoch 5/50, Loss: 5.5500, Accuracy: 0.0043, Val Loss: 5.5491, Val Accuracy: 0.0039\n",
      "Epoch 6/50, Loss: 5.5502, Accuracy: 0.0037, Val Loss: 5.5499, Val Accuracy: 0.0042\n",
      "Epoch 7/50, Loss: 5.5478, Accuracy: 0.0040, Val Loss: 5.5478, Val Accuracy: 0.0039\n",
      "Epoch 8/50, Loss: 5.5474, Accuracy: 0.0035, Val Loss: 5.5478, Val Accuracy: 0.0040\n",
      "Epoch 9/50, Loss: 5.5474, Accuracy: 0.0040, Val Loss: 5.5480, Val Accuracy: 0.0038\n",
      "Epoch 10/50, Loss: 5.5473, Accuracy: 0.0038, Val Loss: 5.5479, Val Accuracy: 0.0037\n",
      "Epoch 11/50, Loss: 5.5462, Accuracy: 0.0040, Val Loss: 5.5471, Val Accuracy: 0.0034\n",
      "Epoch 12/50, Loss: 5.5459, Accuracy: 0.0044, Val Loss: 5.5468, Val Accuracy: 0.0036\n",
      "Epoch 13/50, Loss: 5.5459, Accuracy: 0.0039, Val Loss: 5.5467, Val Accuracy: 0.0034\n",
      "Epoch 14/50, Loss: 5.5459, Accuracy: 0.0038, Val Loss: 5.5466, Val Accuracy: 0.0039\n",
      "Epoch 15/50, Loss: 5.5451, Accuracy: 0.0040, Val Loss: 5.5466, Val Accuracy: 0.0039\n",
      "Epoch 16/50, Loss: 5.5450, Accuracy: 0.0042, Val Loss: 5.5465, Val Accuracy: 0.0036\n",
      "Epoch 17/50, Loss: 5.5450, Accuracy: 0.0040, Val Loss: 5.5466, Val Accuracy: 0.0036\n",
      "Epoch 18/50, Loss: 5.5450, Accuracy: 0.0041, Val Loss: 5.5466, Val Accuracy: 0.0034\n",
      "Epoch 19/50, Loss: 5.5450, Accuracy: 0.0041, Val Loss: 5.5466, Val Accuracy: 0.0039\n",
      "Epoch 20/50, Loss: 5.5446, Accuracy: 0.0041, Val Loss: 5.5466, Val Accuracy: 0.0039\n",
      "Epoch 21/50, Loss: 5.5445, Accuracy: 0.0038, Val Loss: 5.5466, Val Accuracy: 0.0039\n",
      "Early stopping\n",
      "Accuracy for byte 0: 0.39%\n",
      "\n",
      "Training for byte 1...\n",
      "Epoch 1/50, Loss: 5.5614, Accuracy: 0.0041, Val Loss: 5.5519, Val Accuracy: 0.0039\n",
      "Epoch 2/50, Loss: 5.5498, Accuracy: 0.0040, Val Loss: 5.5515, Val Accuracy: 0.0038\n",
      "Epoch 3/50, Loss: 5.5501, Accuracy: 0.0040, Val Loss: 5.5518, Val Accuracy: 0.0039\n",
      "Epoch 4/50, Loss: 5.5501, Accuracy: 0.0036, Val Loss: 5.5522, Val Accuracy: 0.0040\n",
      "Epoch 5/50, Loss: 5.5478, Accuracy: 0.0039, Val Loss: 5.5481, Val Accuracy: 0.0040\n",
      "Epoch 6/50, Loss: 5.5474, Accuracy: 0.0040, Val Loss: 5.5485, Val Accuracy: 0.0042\n",
      "Epoch 7/50, Loss: 5.5473, Accuracy: 0.0039, Val Loss: 5.5484, Val Accuracy: 0.0032\n",
      "Epoch 8/50, Loss: 5.5473, Accuracy: 0.0042, Val Loss: 5.5478, Val Accuracy: 0.0039\n",
      "Epoch 9/50, Loss: 5.5461, Accuracy: 0.0040, Val Loss: 5.5472, Val Accuracy: 0.0043\n",
      "Epoch 10/50, Loss: 5.5458, Accuracy: 0.0040, Val Loss: 5.5472, Val Accuracy: 0.0032\n",
      "Epoch 11/50, Loss: 5.5458, Accuracy: 0.0044, Val Loss: 5.5478, Val Accuracy: 0.0032\n",
      "Epoch 12/50, Loss: 5.5458, Accuracy: 0.0038, Val Loss: 5.5472, Val Accuracy: 0.0030\n",
      "Epoch 13/50, Loss: 5.5450, Accuracy: 0.0040, Val Loss: 5.5470, Val Accuracy: 0.0032\n",
      "Epoch 14/50, Loss: 5.5450, Accuracy: 0.0042, Val Loss: 5.5470, Val Accuracy: 0.0040\n",
      "Epoch 15/50, Loss: 5.5450, Accuracy: 0.0042, Val Loss: 5.5469, Val Accuracy: 0.0032\n",
      "Epoch 16/50, Loss: 5.5445, Accuracy: 0.0042, Val Loss: 5.5469, Val Accuracy: 0.0032\n",
      "Epoch 17/50, Loss: 5.5445, Accuracy: 0.0044, Val Loss: 5.5469, Val Accuracy: 0.0040\n",
      "Epoch 18/50, Loss: 5.5445, Accuracy: 0.0042, Val Loss: 5.5469, Val Accuracy: 0.0032\n",
      "Epoch 19/50, Loss: 5.5442, Accuracy: 0.0042, Val Loss: 5.5470, Val Accuracy: 0.0032\n",
      "Epoch 20/50, Loss: 5.5442, Accuracy: 0.0042, Val Loss: 5.5470, Val Accuracy: 0.0032\n",
      "Epoch 21/50, Loss: 5.5442, Accuracy: 0.0043, Val Loss: 5.5470, Val Accuracy: 0.0032\n",
      "Early stopping\n",
      "Accuracy for byte 1: 0.36%\n",
      "\n",
      "Training for byte 2...\n",
      "Epoch 1/50, Loss: 5.5612, Accuracy: 0.0038, Val Loss: 5.5495, Val Accuracy: 0.0034\n",
      "Epoch 2/50, Loss: 5.5503, Accuracy: 0.0041, Val Loss: 5.5499, Val Accuracy: 0.0040\n",
      "Epoch 3/50, Loss: 5.5498, Accuracy: 0.0041, Val Loss: 5.5518, Val Accuracy: 0.0034\n",
      "Epoch 4/50, Loss: 5.5502, Accuracy: 0.0037, Val Loss: 5.5501, Val Accuracy: 0.0040\n",
      "Epoch 5/50, Loss: 5.5479, Accuracy: 0.0040, Val Loss: 5.5471, Val Accuracy: 0.0029\n",
      "Epoch 6/50, Loss: 5.5476, Accuracy: 0.0038, Val Loss: 5.5474, Val Accuracy: 0.0055\n",
      "Epoch 7/50, Loss: 5.5477, Accuracy: 0.0041, Val Loss: 5.5475, Val Accuracy: 0.0042\n",
      "Epoch 8/50, Loss: 5.5473, Accuracy: 0.0041, Val Loss: 5.5480, Val Accuracy: 0.0040\n",
      "Epoch 9/50, Loss: 5.5461, Accuracy: 0.0039, Val Loss: 5.5470, Val Accuracy: 0.0040\n",
      "Epoch 10/50, Loss: 5.5460, Accuracy: 0.0039, Val Loss: 5.5468, Val Accuracy: 0.0042\n",
      "Epoch 11/50, Loss: 5.5459, Accuracy: 0.0041, Val Loss: 5.5468, Val Accuracy: 0.0042\n",
      "Epoch 12/50, Loss: 5.5452, Accuracy: 0.0045, Val Loss: 5.5466, Val Accuracy: 0.0042\n",
      "Epoch 13/50, Loss: 5.5451, Accuracy: 0.0045, Val Loss: 5.5465, Val Accuracy: 0.0042\n",
      "Epoch 14/50, Loss: 5.5451, Accuracy: 0.0043, Val Loss: 5.5465, Val Accuracy: 0.0042\n",
      "Epoch 15/50, Loss: 5.5450, Accuracy: 0.0044, Val Loss: 5.5464, Val Accuracy: 0.0042\n",
      "Epoch 16/50, Loss: 5.5450, Accuracy: 0.0044, Val Loss: 5.5465, Val Accuracy: 0.0042\n",
      "Epoch 17/50, Loss: 5.5446, Accuracy: 0.0045, Val Loss: 5.5465, Val Accuracy: 0.0042\n",
      "Epoch 18/50, Loss: 5.5445, Accuracy: 0.0045, Val Loss: 5.5465, Val Accuracy: 0.0042\n",
      "Epoch 19/50, Loss: 5.5445, Accuracy: 0.0045, Val Loss: 5.5464, Val Accuracy: 0.0042\n",
      "Epoch 20/50, Loss: 5.5443, Accuracy: 0.0045, Val Loss: 5.5465, Val Accuracy: 0.0042\n",
      "Early stopping\n",
      "Accuracy for byte 2: 0.36%\n",
      "\n",
      "Training for byte 3...\n",
      "Epoch 1/50, Loss: 5.5613, Accuracy: 0.0039, Val Loss: 5.5506, Val Accuracy: 0.0040\n",
      "Epoch 2/50, Loss: 5.5497, Accuracy: 0.0038, Val Loss: 5.5715, Val Accuracy: 0.0031\n",
      "Epoch 3/50, Loss: 5.5500, Accuracy: 0.0038, Val Loss: 5.5511, Val Accuracy: 0.0040\n",
      "Epoch 4/50, Loss: 5.5495, Accuracy: 0.0040, Val Loss: 5.5508, Val Accuracy: 0.0036\n",
      "Epoch 5/50, Loss: 5.5476, Accuracy: 0.0038, Val Loss: 5.5512, Val Accuracy: 0.0044\n",
      "Epoch 6/50, Loss: 5.5473, Accuracy: 0.0039, Val Loss: 5.5473, Val Accuracy: 0.0034\n",
      "Epoch 7/50, Loss: 5.5472, Accuracy: 0.0038, Val Loss: 5.5486, Val Accuracy: 0.0033\n",
      "Epoch 8/50, Loss: 5.5471, Accuracy: 0.0043, Val Loss: 5.5478, Val Accuracy: 0.0040\n",
      "Epoch 9/50, Loss: 5.5473, Accuracy: 0.0044, Val Loss: 5.5488, Val Accuracy: 0.0032\n",
      "Epoch 10/50, Loss: 5.5460, Accuracy: 0.0040, Val Loss: 5.5477, Val Accuracy: 0.0040\n",
      "Epoch 11/50, Loss: 5.5457, Accuracy: 0.0042, Val Loss: 5.5472, Val Accuracy: 0.0040\n",
      "Epoch 12/50, Loss: 5.5457, Accuracy: 0.0044, Val Loss: 5.5470, Val Accuracy: 0.0031\n",
      "Epoch 13/50, Loss: 5.5450, Accuracy: 0.0042, Val Loss: 5.5471, Val Accuracy: 0.0031\n",
      "Epoch 14/50, Loss: 5.5449, Accuracy: 0.0043, Val Loss: 5.5472, Val Accuracy: 0.0031\n",
      "Epoch 15/50, Loss: 5.5449, Accuracy: 0.0044, Val Loss: 5.5471, Val Accuracy: 0.0031\n",
      "Epoch 16/50, Loss: 5.5444, Accuracy: 0.0044, Val Loss: 5.5471, Val Accuracy: 0.0031\n",
      "Epoch 17/50, Loss: 5.5444, Accuracy: 0.0041, Val Loss: 5.5470, Val Accuracy: 0.0031\n",
      "Early stopping\n",
      "Accuracy for byte 3: 0.44%\n",
      "\n",
      "Training for byte 4...\n",
      "Epoch 1/50, Loss: 5.5612, Accuracy: 0.0042, Val Loss: 5.5507, Val Accuracy: 0.0042\n",
      "Epoch 2/50, Loss: 5.5502, Accuracy: 0.0040, Val Loss: 5.5490, Val Accuracy: 0.0040\n",
      "Epoch 3/50, Loss: 5.5500, Accuracy: 0.0038, Val Loss: 5.5511, Val Accuracy: 0.0036\n",
      "Epoch 4/50, Loss: 5.5502, Accuracy: 0.0040, Val Loss: 5.5492, Val Accuracy: 0.0048\n",
      "Epoch 5/50, Loss: 5.5499, Accuracy: 0.0037, Val Loss: 5.5494, Val Accuracy: 0.0033\n",
      "Epoch 6/50, Loss: 5.5476, Accuracy: 0.0038, Val Loss: 5.5470, Val Accuracy: 0.0033\n",
      "Epoch 7/50, Loss: 5.5474, Accuracy: 0.0041, Val Loss: 5.5482, Val Accuracy: 0.0043\n",
      "Epoch 8/50, Loss: 5.5475, Accuracy: 0.0038, Val Loss: 5.5477, Val Accuracy: 0.0037\n",
      "Epoch 9/50, Loss: 5.5474, Accuracy: 0.0037, Val Loss: 5.5477, Val Accuracy: 0.0045\n",
      "Epoch 10/50, Loss: 5.5462, Accuracy: 0.0039, Val Loss: 5.5466, Val Accuracy: 0.0037\n",
      "Epoch 11/50, Loss: 5.5459, Accuracy: 0.0037, Val Loss: 5.5465, Val Accuracy: 0.0038\n",
      "Epoch 12/50, Loss: 5.5459, Accuracy: 0.0038, Val Loss: 5.5469, Val Accuracy: 0.0042\n",
      "Epoch 13/50, Loss: 5.5452, Accuracy: 0.0039, Val Loss: 5.5466, Val Accuracy: 0.0033\n",
      "Epoch 14/50, Loss: 5.5451, Accuracy: 0.0040, Val Loss: 5.5463, Val Accuracy: 0.0033\n",
      "Epoch 15/50, Loss: 5.5451, Accuracy: 0.0038, Val Loss: 5.5464, Val Accuracy: 0.0033\n",
      "Epoch 16/50, Loss: 5.5450, Accuracy: 0.0041, Val Loss: 5.5464, Val Accuracy: 0.0033\n",
      "Epoch 17/50, Loss: 5.5451, Accuracy: 0.0042, Val Loss: 5.5464, Val Accuracy: 0.0037\n",
      "Epoch 18/50, Loss: 5.5446, Accuracy: 0.0041, Val Loss: 5.5463, Val Accuracy: 0.0037\n",
      "Epoch 19/50, Loss: 5.5446, Accuracy: 0.0040, Val Loss: 5.5463, Val Accuracy: 0.0033\n",
      "Early stopping\n",
      "Accuracy for byte 4: 0.37%\n",
      "\n",
      "Training for byte 5...\n",
      "Epoch 1/50, Loss: 5.5605, Accuracy: 0.0039, Val Loss: 5.5495, Val Accuracy: 0.0039\n",
      "Epoch 2/50, Loss: 5.5501, Accuracy: 0.0040, Val Loss: 5.5507, Val Accuracy: 0.0042\n",
      "Epoch 3/50, Loss: 5.5500, Accuracy: 0.0041, Val Loss: 5.5496, Val Accuracy: 0.0047\n",
      "Epoch 4/50, Loss: 5.5504, Accuracy: 0.0041, Val Loss: 5.5508, Val Accuracy: 0.0037\n",
      "Epoch 5/50, Loss: 5.5480, Accuracy: 0.0038, Val Loss: 5.5474, Val Accuracy: 0.0037\n",
      "Epoch 6/50, Loss: 5.5474, Accuracy: 0.0044, Val Loss: 5.5469, Val Accuracy: 0.0034\n",
      "Epoch 7/50, Loss: 5.5475, Accuracy: 0.0040, Val Loss: 5.5473, Val Accuracy: 0.0037\n",
      "Epoch 8/50, Loss: 5.5474, Accuracy: 0.0043, Val Loss: 5.5476, Val Accuracy: 0.0044\n",
      "Epoch 9/50, Loss: 5.5461, Accuracy: 0.0042, Val Loss: 5.5467, Val Accuracy: 0.0038\n",
      "Epoch 10/50, Loss: 5.5459, Accuracy: 0.0041, Val Loss: 5.5466, Val Accuracy: 0.0038\n",
      "Epoch 11/50, Loss: 5.5459, Accuracy: 0.0043, Val Loss: 5.5467, Val Accuracy: 0.0037\n",
      "Epoch 12/50, Loss: 5.5459, Accuracy: 0.0041, Val Loss: 5.5472, Val Accuracy: 0.0037\n",
      "Epoch 13/50, Loss: 5.5451, Accuracy: 0.0042, Val Loss: 5.5465, Val Accuracy: 0.0037\n",
      "Epoch 14/50, Loss: 5.5451, Accuracy: 0.0044, Val Loss: 5.5462, Val Accuracy: 0.0037\n",
      "Epoch 15/50, Loss: 5.5450, Accuracy: 0.0044, Val Loss: 5.5462, Val Accuracy: 0.0037\n",
      "Epoch 16/50, Loss: 5.5446, Accuracy: 0.0045, Val Loss: 5.5463, Val Accuracy: 0.0037\n",
      "Epoch 17/50, Loss: 5.5446, Accuracy: 0.0045, Val Loss: 5.5462, Val Accuracy: 0.0037\n",
      "Epoch 18/50, Loss: 5.5445, Accuracy: 0.0044, Val Loss: 5.5462, Val Accuracy: 0.0037\n",
      "Epoch 19/50, Loss: 5.5443, Accuracy: 0.0045, Val Loss: 5.5462, Val Accuracy: 0.0037\n",
      "Epoch 20/50, Loss: 5.5443, Accuracy: 0.0045, Val Loss: 5.5462, Val Accuracy: 0.0037\n",
      "Epoch 21/50, Loss: 5.5443, Accuracy: 0.0045, Val Loss: 5.5462, Val Accuracy: 0.0037\n",
      "Epoch 22/50, Loss: 5.5441, Accuracy: 0.0045, Val Loss: 5.5462, Val Accuracy: 0.0037\n",
      "Epoch 23/50, Loss: 5.5441, Accuracy: 0.0045, Val Loss: 5.5462, Val Accuracy: 0.0037\n",
      "Epoch 24/50, Loss: 5.5441, Accuracy: 0.0045, Val Loss: 5.5462, Val Accuracy: 0.0037\n",
      "Early stopping\n",
      "Accuracy for byte 5: 0.38%\n",
      "\n",
      "Training for byte 6...\n",
      "Epoch 1/50, Loss: 5.5611, Accuracy: 0.0039, Val Loss: 5.5500, Val Accuracy: 0.0045\n",
      "Epoch 2/50, Loss: 5.5503, Accuracy: 0.0036, Val Loss: 5.5513, Val Accuracy: 0.0038\n",
      "Epoch 3/50, Loss: 5.5499, Accuracy: 0.0039, Val Loss: 5.5485, Val Accuracy: 0.0044\n",
      "Epoch 4/50, Loss: 5.5498, Accuracy: 0.0039, Val Loss: 5.5491, Val Accuracy: 0.0042\n",
      "Epoch 5/50, Loss: 5.5499, Accuracy: 0.0036, Val Loss: 5.5507, Val Accuracy: 0.0036\n",
      "Epoch 6/50, Loss: 5.5501, Accuracy: 0.0040, Val Loss: 5.5511, Val Accuracy: 0.0048\n",
      "Epoch 7/50, Loss: 5.5475, Accuracy: 0.0041, Val Loss: 5.5485, Val Accuracy: 0.0040\n",
      "Epoch 8/50, Loss: 5.5474, Accuracy: 0.0041, Val Loss: 5.5476, Val Accuracy: 0.0040\n",
      "Epoch 9/50, Loss: 5.5473, Accuracy: 0.0042, Val Loss: 5.5481, Val Accuracy: 0.0044\n",
      "Epoch 10/50, Loss: 5.5474, Accuracy: 0.0039, Val Loss: 5.5479, Val Accuracy: 0.0032\n",
      "Epoch 11/50, Loss: 5.5474, Accuracy: 0.0041, Val Loss: 5.5476, Val Accuracy: 0.0040\n",
      "Epoch 12/50, Loss: 5.5460, Accuracy: 0.0042, Val Loss: 5.5472, Val Accuracy: 0.0044\n",
      "Epoch 13/50, Loss: 5.5458, Accuracy: 0.0039, Val Loss: 5.5471, Val Accuracy: 0.0040\n",
      "Epoch 14/50, Loss: 5.5458, Accuracy: 0.0042, Val Loss: 5.5472, Val Accuracy: 0.0040\n",
      "Epoch 15/50, Loss: 5.5450, Accuracy: 0.0045, Val Loss: 5.5469, Val Accuracy: 0.0040\n",
      "Epoch 16/50, Loss: 5.5449, Accuracy: 0.0042, Val Loss: 5.5467, Val Accuracy: 0.0040\n",
      "Epoch 17/50, Loss: 5.5449, Accuracy: 0.0044, Val Loss: 5.5468, Val Accuracy: 0.0040\n",
      "Epoch 18/50, Loss: 5.5449, Accuracy: 0.0042, Val Loss: 5.5469, Val Accuracy: 0.0040\n",
      "Epoch 19/50, Loss: 5.5444, Accuracy: 0.0044, Val Loss: 5.5469, Val Accuracy: 0.0040\n",
      "Epoch 20/50, Loss: 5.5444, Accuracy: 0.0045, Val Loss: 5.5468, Val Accuracy: 0.0040\n",
      "Epoch 21/50, Loss: 5.5444, Accuracy: 0.0045, Val Loss: 5.5467, Val Accuracy: 0.0040\n",
      "Epoch 22/50, Loss: 5.5442, Accuracy: 0.0045, Val Loss: 5.5467, Val Accuracy: 0.0040\n",
      "Epoch 23/50, Loss: 5.5442, Accuracy: 0.0045, Val Loss: 5.5467, Val Accuracy: 0.0040\n",
      "Epoch 24/50, Loss: 5.5441, Accuracy: 0.0045, Val Loss: 5.5467, Val Accuracy: 0.0040\n",
      "Epoch 25/50, Loss: 5.5440, Accuracy: 0.0045, Val Loss: 5.5467, Val Accuracy: 0.0040\n",
      "Epoch 26/50, Loss: 5.5440, Accuracy: 0.0045, Val Loss: 5.5467, Val Accuracy: 0.0040\n",
      "Epoch 27/50, Loss: 5.5440, Accuracy: 0.0045, Val Loss: 5.5467, Val Accuracy: 0.0040\n",
      "Epoch 28/50, Loss: 5.5439, Accuracy: 0.0045, Val Loss: 5.5467, Val Accuracy: 0.0040\n",
      "Early stopping\n",
      "Accuracy for byte 6: 0.35%\n",
      "\n",
      "Training for byte 7...\n",
      "Epoch 1/50, Loss: 5.5602, Accuracy: 0.0038, Val Loss: 5.5520, Val Accuracy: 0.0032\n",
      "Epoch 2/50, Loss: 5.5502, Accuracy: 0.0039, Val Loss: 5.5490, Val Accuracy: 0.0037\n",
      "Epoch 3/50, Loss: 5.5500, Accuracy: 0.0043, Val Loss: 5.5503, Val Accuracy: 0.0031\n",
      "Epoch 4/50, Loss: 5.5500, Accuracy: 0.0037, Val Loss: 5.5495, Val Accuracy: 0.0046\n",
      "Epoch 5/50, Loss: 5.5498, Accuracy: 0.0039, Val Loss: 5.5510, Val Accuracy: 0.0040\n",
      "Epoch 6/50, Loss: 5.5480, Accuracy: 0.0044, Val Loss: 5.5469, Val Accuracy: 0.0034\n",
      "Epoch 7/50, Loss: 5.5474, Accuracy: 0.0036, Val Loss: 5.5478, Val Accuracy: 0.0043\n",
      "Epoch 8/50, Loss: 5.5473, Accuracy: 0.0041, Val Loss: 5.5481, Val Accuracy: 0.0042\n",
      "Epoch 9/50, Loss: 5.5474, Accuracy: 0.0039, Val Loss: 5.5470, Val Accuracy: 0.0042\n",
      "Epoch 10/50, Loss: 5.5460, Accuracy: 0.0039, Val Loss: 5.5466, Val Accuracy: 0.0043\n",
      "Epoch 11/50, Loss: 5.5459, Accuracy: 0.0041, Val Loss: 5.5467, Val Accuracy: 0.0038\n",
      "Epoch 12/50, Loss: 5.5458, Accuracy: 0.0036, Val Loss: 5.5467, Val Accuracy: 0.0033\n",
      "Epoch 13/50, Loss: 5.5451, Accuracy: 0.0041, Val Loss: 5.5465, Val Accuracy: 0.0040\n",
      "Epoch 14/50, Loss: 5.5450, Accuracy: 0.0040, Val Loss: 5.5463, Val Accuracy: 0.0040\n",
      "Epoch 15/50, Loss: 5.5450, Accuracy: 0.0040, Val Loss: 5.5465, Val Accuracy: 0.0043\n",
      "Epoch 16/50, Loss: 5.5450, Accuracy: 0.0042, Val Loss: 5.5464, Val Accuracy: 0.0043\n",
      "Epoch 17/50, Loss: 5.5450, Accuracy: 0.0040, Val Loss: 5.5464, Val Accuracy: 0.0043\n",
      "Epoch 18/50, Loss: 5.5445, Accuracy: 0.0043, Val Loss: 5.5464, Val Accuracy: 0.0043\n",
      "Epoch 19/50, Loss: 5.5445, Accuracy: 0.0044, Val Loss: 5.5464, Val Accuracy: 0.0043\n",
      "Early stopping\n",
      "Accuracy for byte 7: 0.33%\n",
      "\n",
      "Training for byte 8...\n",
      "Epoch 1/50, Loss: 5.5614, Accuracy: 0.0036, Val Loss: 5.5512, Val Accuracy: 0.0048\n",
      "Epoch 2/50, Loss: 5.5503, Accuracy: 0.0038, Val Loss: 5.5492, Val Accuracy: 0.0038\n",
      "Epoch 3/50, Loss: 5.5502, Accuracy: 0.0039, Val Loss: 5.5512, Val Accuracy: 0.0036\n",
      "Epoch 4/50, Loss: 5.5501, Accuracy: 0.0041, Val Loss: 5.5503, Val Accuracy: 0.0034\n",
      "Epoch 5/50, Loss: 5.5499, Accuracy: 0.0040, Val Loss: 5.5503, Val Accuracy: 0.0042\n",
      "Epoch 6/50, Loss: 5.5477, Accuracy: 0.0040, Val Loss: 5.5476, Val Accuracy: 0.0033\n",
      "Epoch 7/50, Loss: 5.5475, Accuracy: 0.0040, Val Loss: 5.5483, Val Accuracy: 0.0032\n",
      "Epoch 8/50, Loss: 5.5479, Accuracy: 0.0039, Val Loss: 5.5471, Val Accuracy: 0.0049\n",
      "Epoch 9/50, Loss: 5.5474, Accuracy: 0.0037, Val Loss: 5.5479, Val Accuracy: 0.0039\n",
      "Epoch 10/50, Loss: 5.5461, Accuracy: 0.0043, Val Loss: 5.5463, Val Accuracy: 0.0039\n",
      "Epoch 11/50, Loss: 5.5460, Accuracy: 0.0042, Val Loss: 5.5471, Val Accuracy: 0.0039\n",
      "Epoch 12/50, Loss: 5.5459, Accuracy: 0.0041, Val Loss: 5.5463, Val Accuracy: 0.0039\n",
      "Epoch 13/50, Loss: 5.5460, Accuracy: 0.0042, Val Loss: 5.5463, Val Accuracy: 0.0033\n",
      "Epoch 14/50, Loss: 5.5452, Accuracy: 0.0045, Val Loss: 5.5463, Val Accuracy: 0.0039\n",
      "Epoch 15/50, Loss: 5.5451, Accuracy: 0.0043, Val Loss: 5.5463, Val Accuracy: 0.0039\n",
      "Early stopping\n",
      "Accuracy for byte 8: 0.40%\n",
      "\n",
      "Training for byte 9...\n",
      "Epoch 1/50, Loss: 5.5609, Accuracy: 0.0037, Val Loss: 5.5504, Val Accuracy: 0.0038\n",
      "Epoch 2/50, Loss: 5.5502, Accuracy: 0.0037, Val Loss: 5.5494, Val Accuracy: 0.0040\n",
      "Epoch 3/50, Loss: 5.5498, Accuracy: 0.0040, Val Loss: 5.5481, Val Accuracy: 0.0040\n",
      "Epoch 4/50, Loss: 5.5498, Accuracy: 0.0038, Val Loss: 5.5520, Val Accuracy: 0.0040\n",
      "Epoch 5/50, Loss: 5.5501, Accuracy: 0.0038, Val Loss: 5.5501, Val Accuracy: 0.0036\n",
      "Epoch 6/50, Loss: 5.5504, Accuracy: 0.0042, Val Loss: 5.5489, Val Accuracy: 0.0040\n",
      "Epoch 7/50, Loss: 5.5474, Accuracy: 0.0042, Val Loss: 5.5481, Val Accuracy: 0.0034\n",
      "Epoch 8/50, Loss: 5.5472, Accuracy: 0.0042, Val Loss: 5.5471, Val Accuracy: 0.0040\n",
      "Epoch 9/50, Loss: 5.5473, Accuracy: 0.0039, Val Loss: 5.5464, Val Accuracy: 0.0040\n",
      "Epoch 10/50, Loss: 5.5473, Accuracy: 0.0038, Val Loss: 5.5463, Val Accuracy: 0.0047\n",
      "Epoch 11/50, Loss: 5.5473, Accuracy: 0.0040, Val Loss: 5.5470, Val Accuracy: 0.0045\n",
      "Epoch 12/50, Loss: 5.5472, Accuracy: 0.0040, Val Loss: 5.5475, Val Accuracy: 0.0047\n",
      "Epoch 13/50, Loss: 5.5461, Accuracy: 0.0046, Val Loss: 5.5458, Val Accuracy: 0.0047\n",
      "Epoch 14/50, Loss: 5.5458, Accuracy: 0.0038, Val Loss: 5.5462, Val Accuracy: 0.0040\n",
      "Epoch 15/50, Loss: 5.5458, Accuracy: 0.0041, Val Loss: 5.5465, Val Accuracy: 0.0038\n",
      "Epoch 16/50, Loss: 5.5458, Accuracy: 0.0041, Val Loss: 5.5465, Val Accuracy: 0.0047\n",
      "Epoch 17/50, Loss: 5.5450, Accuracy: 0.0045, Val Loss: 5.5461, Val Accuracy: 0.0040\n",
      "Epoch 18/50, Loss: 5.5449, Accuracy: 0.0044, Val Loss: 5.5458, Val Accuracy: 0.0047\n",
      "Epoch 19/50, Loss: 5.5450, Accuracy: 0.0044, Val Loss: 5.5459, Val Accuracy: 0.0047\n",
      "Epoch 20/50, Loss: 5.5444, Accuracy: 0.0043, Val Loss: 5.5458, Val Accuracy: 0.0047\n",
      "Epoch 21/50, Loss: 5.5444, Accuracy: 0.0044, Val Loss: 5.5458, Val Accuracy: 0.0047\n",
      "Epoch 22/50, Loss: 5.5444, Accuracy: 0.0043, Val Loss: 5.5458, Val Accuracy: 0.0047\n",
      "Epoch 23/50, Loss: 5.5442, Accuracy: 0.0045, Val Loss: 5.5458, Val Accuracy: 0.0040\n",
      "Epoch 24/50, Loss: 5.5442, Accuracy: 0.0042, Val Loss: 5.5458, Val Accuracy: 0.0040\n",
      "Epoch 25/50, Loss: 5.5442, Accuracy: 0.0045, Val Loss: 5.5458, Val Accuracy: 0.0040\n",
      "Epoch 26/50, Loss: 5.5440, Accuracy: 0.0044, Val Loss: 5.5458, Val Accuracy: 0.0040\n",
      "Early stopping\n",
      "Accuracy for byte 9: 0.39%\n",
      "\n",
      "Accuracies for all 10 bytes:\n",
      "Byte 0: 0.39%\n",
      "Byte 1: 0.36%\n",
      "Byte 2: 0.36%\n",
      "Byte 3: 0.44%\n",
      "Byte 4: 0.37%\n",
      "Byte 5: 0.38%\n",
      "Byte 6: 0.35%\n",
      "Byte 7: 0.33%\n",
      "Byte 8: 0.40%\n",
      "Byte 9: 0.39%\n"
     ]
    }
   ],
   "source": [
    "# Function to train and evaluate a model for a specific byte of the keystream\n",
    "def train_and_evaluate(X_train, y_train, X_val, y_val, X_test, y_test, byte_index):\n",
    "    # Initialize the model, loss function, and optimizer\n",
    "    model = ImprovedKeystreamClassifier()\n",
    "    criterion = nn.CrossEntropyLoss()  # Cross-Entropy Loss for classification\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=2, factor=0.5)\n",
    "\n",
    "    # Convert data to PyTorch tensors\n",
    "    y_train_tensor = torch.tensor(y_train[:, byte_index], dtype=torch.long)\n",
    "    y_val_tensor = torch.tensor(y_val[:, byte_index], dtype=torch.long)\n",
    "    y_test_tensor = torch.tensor(y_test[:, byte_index], dtype=torch.long)\n",
    "\n",
    "    # Create data loaders\n",
    "    train_dataset = torch.utils.data.TensorDataset(torch.tensor(X_train, dtype=torch.float32), y_train_tensor)\n",
    "    val_dataset = torch.utils.data.TensorDataset(torch.tensor(X_val, dtype=torch.float32), y_val_tensor)\n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "    val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "    # Early stopping parameters\n",
    "    patience = 5\n",
    "    best_val_loss = float('inf')\n",
    "    best_model = None\n",
    "    patience_counter = 0\n",
    "\n",
    "    # Training the model\n",
    "    num_epochs = 50\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct_train = 0\n",
    "        total_train = 0\n",
    "\n",
    "        for inputs, labels in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            correct_train += (predicted == labels).sum().item()\n",
    "            total_train += labels.size(0)\n",
    "\n",
    "        train_loss = running_loss / len(train_loader)\n",
    "        train_accuracy = correct_train / total_train\n",
    "\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        correct_val = 0\n",
    "        total_val = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                correct_val += (predicted == labels).sum().item()\n",
    "                total_val += labels.size(0)\n",
    "\n",
    "        val_loss /= len(val_loader)\n",
    "        val_accuracy = correct_val / total_val\n",
    "\n",
    "        print(f'Epoch {epoch+1}/{num_epochs}, Loss: {train_loss:.4f}, Accuracy: {train_accuracy:.4f}, Val Loss: {val_loss:.4f}, Val Accuracy: {val_accuracy:.4f}')\n",
    "\n",
    "        # Adjust learning rate based on validation loss\n",
    "        scheduler.step(val_loss)\n",
    "\n",
    "        # Early stopping\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            best_model = model.state_dict()\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= patience:\n",
    "                print(\"Early stopping\")\n",
    "                break\n",
    "\n",
    "    # Load the best model\n",
    "    model.load_state_dict(best_model)\n",
    "\n",
    "    # Evaluate the model on the test set\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        outputs = model(torch.tensor(X_test, dtype=torch.float32))\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        test_accuracy = accuracy_score(y_test[:, byte_index], predicted.numpy())\n",
    "        return test_accuracy\n",
    "\n",
    "# Train and evaluate the model for each byte and print the accuracy\n",
    "accuracies = []\n",
    "for byte_index in range(10):\n",
    "    print(f'\\nTraining for byte {byte_index}...')\n",
    "    accuracy = train_and_evaluate(X_train, y_train, X_val, y_val, X_test, y_test, byte_index)\n",
    "    accuracies.append(accuracy)\n",
    "    print(f'Accuracy for byte {byte_index}: {accuracy * 100:.2f}%')\n",
    "\n",
    "# Print all accuracies\n",
    "print(\"\\nAccuracies for all 10 bytes:\")\n",
    "for byte_index, accuracy in enumerate(accuracies):\n",
    "    print(f'Byte {byte_index}: {accuracy * 100:.2f}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "63146631-e3b2-4c73-8798-df8e88140384",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training for byte 0...\n",
      "Epoch 1/50, Loss: 5.5863, Accuracy: 0.0039, Val Loss: 5.5551, Val Accuracy: 0.0034\n",
      "Epoch 2/50, Loss: 5.5530, Accuracy: 0.0040, Val Loss: 5.5472, Val Accuracy: 0.0033\n",
      "Epoch 3/50, Loss: 5.5457, Accuracy: 0.0037, Val Loss: 5.5466, Val Accuracy: 0.0042\n",
      "Epoch 4/50, Loss: 5.5452, Accuracy: 0.0046, Val Loss: 5.5468, Val Accuracy: 0.0028\n",
      "Epoch 5/50, Loss: 5.5450, Accuracy: 0.0044, Val Loss: 5.5470, Val Accuracy: 0.0036\n",
      "Epoch 6/50, Loss: 5.5447, Accuracy: 0.0042, Val Loss: 5.5468, Val Accuracy: 0.0036\n",
      "Epoch 7/50, Loss: 5.5434, Accuracy: 0.0048, Val Loss: 5.5474, Val Accuracy: 0.0029\n",
      "Epoch 8/50, Loss: 5.5424, Accuracy: 0.0050, Val Loss: 5.5476, Val Accuracy: 0.0038\n",
      "Early stopping\n",
      "Accuracy for byte 0: 0.40%\n",
      "\n",
      "Training for byte 1...\n",
      "Epoch 1/50, Loss: 5.5863, Accuracy: 0.0043, Val Loss: 5.5555, Val Accuracy: 0.0038\n",
      "Epoch 2/50, Loss: 5.5508, Accuracy: 0.0043, Val Loss: 5.5464, Val Accuracy: 0.0032\n",
      "Epoch 3/50, Loss: 5.5456, Accuracy: 0.0041, Val Loss: 5.5464, Val Accuracy: 0.0030\n",
      "Epoch 4/50, Loss: 5.5450, Accuracy: 0.0044, Val Loss: 5.5457, Val Accuracy: 0.0035\n",
      "Epoch 5/50, Loss: 5.5451, Accuracy: 0.0046, Val Loss: 5.5464, Val Accuracy: 0.0042\n",
      "Epoch 6/50, Loss: 5.5448, Accuracy: 0.0044, Val Loss: 5.5468, Val Accuracy: 0.0036\n",
      "Epoch 7/50, Loss: 5.5438, Accuracy: 0.0047, Val Loss: 5.5476, Val Accuracy: 0.0034\n",
      "Epoch 8/50, Loss: 5.5418, Accuracy: 0.0047, Val Loss: 5.5478, Val Accuracy: 0.0033\n",
      "Epoch 9/50, Loss: 5.5400, Accuracy: 0.0050, Val Loss: 5.5487, Val Accuracy: 0.0032\n",
      "Early stopping\n",
      "Accuracy for byte 1: 0.35%\n",
      "\n",
      "Training for byte 2...\n",
      "Epoch 1/50, Loss: 5.5862, Accuracy: 0.0040, Val Loss: 5.5515, Val Accuracy: 0.0041\n",
      "Epoch 2/50, Loss: 5.5529, Accuracy: 0.0042, Val Loss: 5.5467, Val Accuracy: 0.0041\n",
      "Epoch 3/50, Loss: 5.5456, Accuracy: 0.0044, Val Loss: 5.5460, Val Accuracy: 0.0044\n",
      "Epoch 4/50, Loss: 5.5448, Accuracy: 0.0047, Val Loss: 5.5459, Val Accuracy: 0.0045\n",
      "Epoch 5/50, Loss: 5.5450, Accuracy: 0.0042, Val Loss: 5.5465, Val Accuracy: 0.0043\n",
      "Epoch 6/50, Loss: 5.5447, Accuracy: 0.0046, Val Loss: 5.5464, Val Accuracy: 0.0037\n",
      "Epoch 7/50, Loss: 5.5424, Accuracy: 0.0047, Val Loss: 5.5467, Val Accuracy: 0.0036\n",
      "Epoch 8/50, Loss: 5.5411, Accuracy: 0.0047, Val Loss: 5.5475, Val Accuracy: 0.0036\n",
      "Epoch 9/50, Loss: 5.5399, Accuracy: 0.0049, Val Loss: 5.5477, Val Accuracy: 0.0037\n",
      "Early stopping\n",
      "Accuracy for byte 2: 0.38%\n",
      "\n",
      "Training for byte 3...\n",
      "Epoch 1/50, Loss: 5.5867, Accuracy: 0.0039, Val Loss: 5.5568, Val Accuracy: 0.0038\n",
      "Epoch 2/50, Loss: 5.5519, Accuracy: 0.0040, Val Loss: 5.5468, Val Accuracy: 0.0044\n",
      "Epoch 3/50, Loss: 5.5455, Accuracy: 0.0041, Val Loss: 5.5470, Val Accuracy: 0.0038\n",
      "Epoch 4/50, Loss: 5.5452, Accuracy: 0.0043, Val Loss: 5.5482, Val Accuracy: 0.0044\n",
      "Epoch 5/50, Loss: 5.5451, Accuracy: 0.0040, Val Loss: 5.5472, Val Accuracy: 0.0039\n",
      "Epoch 6/50, Loss: 5.5437, Accuracy: 0.0045, Val Loss: 5.5479, Val Accuracy: 0.0036\n",
      "Epoch 7/50, Loss: 5.5429, Accuracy: 0.0046, Val Loss: 5.5479, Val Accuracy: 0.0034\n",
      "Early stopping\n",
      "Accuracy for byte 3: 0.37%\n",
      "\n",
      "Training for byte 4...\n",
      "Epoch 1/50, Loss: 5.5858, Accuracy: 0.0040, Val Loss: 5.5563, Val Accuracy: 0.0044\n",
      "Epoch 2/50, Loss: 5.5499, Accuracy: 0.0043, Val Loss: 5.5464, Val Accuracy: 0.0033\n",
      "Epoch 3/50, Loss: 5.5455, Accuracy: 0.0041, Val Loss: 5.5464, Val Accuracy: 0.0038\n",
      "Epoch 4/50, Loss: 5.5455, Accuracy: 0.0041, Val Loss: 5.5464, Val Accuracy: 0.0040\n",
      "Epoch 5/50, Loss: 5.5448, Accuracy: 0.0044, Val Loss: 5.5470, Val Accuracy: 0.0045\n",
      "Epoch 6/50, Loss: 5.5437, Accuracy: 0.0044, Val Loss: 5.5464, Val Accuracy: 0.0038\n",
      "Epoch 7/50, Loss: 5.5430, Accuracy: 0.0043, Val Loss: 5.5468, Val Accuracy: 0.0036\n",
      "Epoch 8/50, Loss: 5.5414, Accuracy: 0.0046, Val Loss: 5.5478, Val Accuracy: 0.0038\n",
      "Epoch 9/50, Loss: 5.5384, Accuracy: 0.0054, Val Loss: 5.5495, Val Accuracy: 0.0035\n",
      "Early stopping\n",
      "Accuracy for byte 4: 0.40%\n",
      "\n",
      "Training for byte 5...\n",
      "Epoch 1/50, Loss: 5.5861, Accuracy: 0.0040, Val Loss: 5.5572, Val Accuracy: 0.0037\n",
      "Epoch 2/50, Loss: 5.5507, Accuracy: 0.0040, Val Loss: 5.5465, Val Accuracy: 0.0044\n",
      "Epoch 3/50, Loss: 5.5456, Accuracy: 0.0046, Val Loss: 5.5475, Val Accuracy: 0.0038\n",
      "Epoch 4/50, Loss: 5.5456, Accuracy: 0.0044, Val Loss: 5.5466, Val Accuracy: 0.0044\n",
      "Epoch 5/50, Loss: 5.5453, Accuracy: 0.0046, Val Loss: 5.5462, Val Accuracy: 0.0042\n",
      "Epoch 6/50, Loss: 5.5440, Accuracy: 0.0047, Val Loss: 5.5463, Val Accuracy: 0.0040\n",
      "Epoch 7/50, Loss: 5.5434, Accuracy: 0.0045, Val Loss: 5.5468, Val Accuracy: 0.0040\n",
      "Epoch 8/50, Loss: 5.5424, Accuracy: 0.0048, Val Loss: 5.5466, Val Accuracy: 0.0040\n",
      "Epoch 9/50, Loss: 5.5403, Accuracy: 0.0052, Val Loss: 5.5481, Val Accuracy: 0.0045\n",
      "Epoch 10/50, Loss: 5.5392, Accuracy: 0.0051, Val Loss: 5.5490, Val Accuracy: 0.0041\n",
      "Early stopping\n",
      "Accuracy for byte 5: 0.43%\n",
      "\n",
      "Training for byte 6...\n",
      "Epoch 1/50, Loss: 5.5864, Accuracy: 0.0042, Val Loss: 5.5549, Val Accuracy: 0.0038\n",
      "Epoch 2/50, Loss: 5.5509, Accuracy: 0.0044, Val Loss: 5.5470, Val Accuracy: 0.0034\n",
      "Epoch 3/50, Loss: 5.5455, Accuracy: 0.0042, Val Loss: 5.5462, Val Accuracy: 0.0040\n",
      "Epoch 4/50, Loss: 5.5450, Accuracy: 0.0044, Val Loss: 5.5459, Val Accuracy: 0.0041\n",
      "Epoch 5/50, Loss: 5.5446, Accuracy: 0.0042, Val Loss: 5.5463, Val Accuracy: 0.0040\n",
      "Epoch 6/50, Loss: 5.5445, Accuracy: 0.0042, Val Loss: 5.5468, Val Accuracy: 0.0034\n",
      "Epoch 7/50, Loss: 5.5427, Accuracy: 0.0042, Val Loss: 5.5471, Val Accuracy: 0.0031\n",
      "Epoch 8/50, Loss: 5.5415, Accuracy: 0.0048, Val Loss: 5.5473, Val Accuracy: 0.0033\n",
      "Epoch 9/50, Loss: 5.5407, Accuracy: 0.0047, Val Loss: 5.5489, Val Accuracy: 0.0038\n",
      "Early stopping\n",
      "Accuracy for byte 6: 0.44%\n",
      "\n",
      "Training for byte 7...\n",
      "Epoch 1/50, Loss: 5.5874, Accuracy: 0.0035, Val Loss: 5.5546, Val Accuracy: 0.0046\n",
      "Epoch 2/50, Loss: 5.5535, Accuracy: 0.0042, Val Loss: 5.5474, Val Accuracy: 0.0038\n",
      "Epoch 3/50, Loss: 5.5458, Accuracy: 0.0041, Val Loss: 5.5459, Val Accuracy: 0.0045\n",
      "Epoch 4/50, Loss: 5.5452, Accuracy: 0.0042, Val Loss: 5.5465, Val Accuracy: 0.0045\n",
      "Epoch 5/50, Loss: 5.5448, Accuracy: 0.0042, Val Loss: 5.5462, Val Accuracy: 0.0036\n",
      "Epoch 6/50, Loss: 5.5447, Accuracy: 0.0043, Val Loss: 5.5459, Val Accuracy: 0.0032\n",
      "Epoch 7/50, Loss: 5.5424, Accuracy: 0.0045, Val Loss: 5.5467, Val Accuracy: 0.0042\n",
      "Epoch 8/50, Loss: 5.5412, Accuracy: 0.0047, Val Loss: 5.5471, Val Accuracy: 0.0037\n",
      "Early stopping\n",
      "Accuracy for byte 7: 0.37%\n",
      "\n",
      "Training for byte 8...\n",
      "Epoch 1/50, Loss: 5.5875, Accuracy: 0.0036, Val Loss: 5.5552, Val Accuracy: 0.0036\n",
      "Epoch 2/50, Loss: 5.5535, Accuracy: 0.0043, Val Loss: 5.5467, Val Accuracy: 0.0038\n",
      "Epoch 3/50, Loss: 5.5461, Accuracy: 0.0042, Val Loss: 5.5459, Val Accuracy: 0.0040\n",
      "Epoch 4/50, Loss: 5.5451, Accuracy: 0.0045, Val Loss: 5.5459, Val Accuracy: 0.0038\n",
      "Epoch 5/50, Loss: 5.5449, Accuracy: 0.0042, Val Loss: 5.5457, Val Accuracy: 0.0039\n",
      "Epoch 6/50, Loss: 5.5444, Accuracy: 0.0047, Val Loss: 5.5472, Val Accuracy: 0.0042\n",
      "Epoch 7/50, Loss: 5.5425, Accuracy: 0.0046, Val Loss: 5.5479, Val Accuracy: 0.0034\n",
      "Epoch 8/50, Loss: 5.5404, Accuracy: 0.0048, Val Loss: 5.5481, Val Accuracy: 0.0040\n",
      "Epoch 9/50, Loss: 5.5395, Accuracy: 0.0045, Val Loss: 5.5497, Val Accuracy: 0.0039\n",
      "Epoch 10/50, Loss: 5.5366, Accuracy: 0.0055, Val Loss: 5.5516, Val Accuracy: 0.0039\n",
      "Early stopping\n",
      "Accuracy for byte 8: 0.38%\n",
      "\n",
      "Training for byte 9...\n",
      "Epoch 1/50, Loss: 5.5862, Accuracy: 0.0041, Val Loss: 5.5526, Val Accuracy: 0.0046\n",
      "Epoch 2/50, Loss: 5.5517, Accuracy: 0.0040, Val Loss: 5.5460, Val Accuracy: 0.0035\n",
      "Epoch 3/50, Loss: 5.5456, Accuracy: 0.0043, Val Loss: 5.5461, Val Accuracy: 0.0046\n",
      "Epoch 4/50, Loss: 5.5455, Accuracy: 0.0043, Val Loss: 5.5457, Val Accuracy: 0.0047\n",
      "Epoch 5/50, Loss: 5.5448, Accuracy: 0.0042, Val Loss: 5.5458, Val Accuracy: 0.0042\n",
      "Epoch 6/50, Loss: 5.5432, Accuracy: 0.0047, Val Loss: 5.5461, Val Accuracy: 0.0048\n",
      "Epoch 7/50, Loss: 5.5423, Accuracy: 0.0049, Val Loss: 5.5469, Val Accuracy: 0.0041\n",
      "Epoch 8/50, Loss: 5.5415, Accuracy: 0.0052, Val Loss: 5.5475, Val Accuracy: 0.0041\n",
      "Epoch 9/50, Loss: 5.5386, Accuracy: 0.0053, Val Loss: 5.5496, Val Accuracy: 0.0038\n",
      "Early stopping\n",
      "Accuracy for byte 9: 0.35%\n",
      "\n",
      "Accuracies for all 10 bytes:\n",
      "Byte 0: 0.40%\n",
      "Byte 1: 0.35%\n",
      "Byte 2: 0.38%\n",
      "Byte 3: 0.37%\n",
      "Byte 4: 0.40%\n",
      "Byte 5: 0.43%\n",
      "Byte 6: 0.44%\n",
      "Byte 7: 0.37%\n",
      "Byte 8: 0.38%\n",
      "Byte 9: 0.35%\n"
     ]
    }
   ],
   "source": [
    "# Function to train and evaluate a model for a specific byte of the keystream\n",
    "def train_and_evaluate(X_train, y_train, X_val, y_val, X_test, y_test, byte_index):\n",
    "    # Initialize the model, loss function, and optimizer\n",
    "    model = ImprovedKeystreamClassifier()\n",
    "    criterion = nn.CrossEntropyLoss()  # Cross-Entropy Loss for classification\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=2, factor=0.5)\n",
    "\n",
    "    # Convert data to PyTorch tensors\n",
    "    y_train_tensor = torch.tensor(y_train[:, byte_index], dtype=torch.long)\n",
    "    y_val_tensor = torch.tensor(y_val[:, byte_index], dtype=torch.long)\n",
    "    y_test_tensor = torch.tensor(y_test[:, byte_index], dtype=torch.long)\n",
    "\n",
    "    # Create data loaders\n",
    "    train_dataset = torch.utils.data.TensorDataset(torch.tensor(X_train, dtype=torch.float32), y_train_tensor)\n",
    "    val_dataset = torch.utils.data.TensorDataset(torch.tensor(X_val, dtype=torch.float32), y_val_tensor)\n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "    val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "    # Early stopping parameters\n",
    "    patience = 5\n",
    "    best_val_loss = float('inf')\n",
    "    best_model = None\n",
    "    patience_counter = 0\n",
    "\n",
    "    # Training the model\n",
    "    num_epochs = 50\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct_train = 0\n",
    "        total_train = 0\n",
    "\n",
    "        for inputs, labels in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            correct_train += (predicted == labels).sum().item()\n",
    "            total_train += labels.size(0)\n",
    "\n",
    "        train_loss = running_loss / len(train_loader)\n",
    "        train_accuracy = correct_train / total_train\n",
    "\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        correct_val = 0\n",
    "        total_val = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                correct_val += (predicted == labels).sum().item()\n",
    "                total_val += labels.size(0)\n",
    "\n",
    "        val_loss /= len(val_loader)\n",
    "        val_accuracy = correct_val / total_val\n",
    "\n",
    "        print(f'Epoch {epoch+1}/{num_epochs}, Loss: {train_loss:.4f}, Accuracy: {train_accuracy:.4f}, Val Loss: {val_loss:.4f}, Val Accuracy: {val_accuracy:.4f}')\n",
    "\n",
    "        # Adjust learning rate based on validation loss\n",
    "        scheduler.step(val_loss)\n",
    "\n",
    "        # Early stopping\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            best_model = model.state_dict()\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= patience:\n",
    "                print(\"Early stopping\")\n",
    "                break\n",
    "\n",
    "    # Load the best model\n",
    "    model.load_state_dict(best_model)\n",
    "\n",
    "    # Evaluate the model on the test set\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        outputs = model(torch.tensor(X_test, dtype=torch.float32))\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        test_accuracy = accuracy_score(y_test[:, byte_index], predicted.numpy())\n",
    "        return test_accuracy\n",
    "\n",
    "# Train and evaluate the model for each byte and print the accuracy\n",
    "accuracies = []\n",
    "for byte_index in range(10):\n",
    "    print(f'\\nTraining for byte {byte_index}...')\n",
    "    accuracy = train_and_evaluate(X_train, y_train, X_val, y_val, X_test, y_test, byte_index)\n",
    "    accuracies.append(accuracy)\n",
    "    print(f'Accuracy for byte {byte_index}: {accuracy * 100:.2f}%')\n",
    "\n",
    "# Print all accuracies\n",
    "print(\"\\nAccuracies for all 10 bytes:\")\n",
    "for byte_index, accuracy in enumerate(accuracies):\n",
    "    print(f'Byte {byte_index}: {accuracy * 100:.2f}%')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddfba5ea-9755-4d15-993a-03ac56a6a7d3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# L2 regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "23a886ed-25be-41c7-b7c7-2128acb169c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training for byte 0...\n",
      "Epoch 1/50, Loss: 5.5866, Accuracy: 0.0041, Val Loss: 5.5546, Val Accuracy: 0.0047\n",
      "Epoch 2/50, Loss: 5.5509, Accuracy: 0.0038, Val Loss: 5.5461, Val Accuracy: 0.0039\n",
      "Epoch 3/50, Loss: 5.5460, Accuracy: 0.0042, Val Loss: 5.5459, Val Accuracy: 0.0038\n",
      "Epoch 4/50, Loss: 5.5451, Accuracy: 0.0041, Val Loss: 5.5462, Val Accuracy: 0.0036\n",
      "Epoch 5/50, Loss: 5.5452, Accuracy: 0.0042, Val Loss: 5.5479, Val Accuracy: 0.0033\n",
      "Epoch 6/50, Loss: 5.5441, Accuracy: 0.0044, Val Loss: 5.5467, Val Accuracy: 0.0034\n",
      "Epoch 7/50, Loss: 5.5434, Accuracy: 0.0043, Val Loss: 5.5474, Val Accuracy: 0.0035\n",
      "Epoch 8/50, Loss: 5.5432, Accuracy: 0.0049, Val Loss: 5.5476, Val Accuracy: 0.0035\n",
      "Early stopping\n",
      "Accuracy for byte 0: 0.38%\n",
      "\n",
      "Training for byte 1...\n",
      "Epoch 1/50, Loss: 5.5861, Accuracy: 0.0038, Val Loss: 5.5535, Val Accuracy: 0.0043\n",
      "Epoch 2/50, Loss: 5.5541, Accuracy: 0.0041, Val Loss: 5.5463, Val Accuracy: 0.0041\n",
      "Epoch 3/50, Loss: 5.5459, Accuracy: 0.0043, Val Loss: 5.5470, Val Accuracy: 0.0030\n",
      "Epoch 4/50, Loss: 5.5450, Accuracy: 0.0042, Val Loss: 5.5468, Val Accuracy: 0.0040\n",
      "Epoch 5/50, Loss: 5.5450, Accuracy: 0.0042, Val Loss: 5.5474, Val Accuracy: 0.0035\n",
      "Epoch 6/50, Loss: 5.5434, Accuracy: 0.0045, Val Loss: 5.5476, Val Accuracy: 0.0036\n",
      "Epoch 7/50, Loss: 5.5427, Accuracy: 0.0046, Val Loss: 5.5480, Val Accuracy: 0.0032\n",
      "Early stopping\n",
      "Accuracy for byte 1: 0.40%\n",
      "\n",
      "Training for byte 2...\n",
      "Epoch 1/50, Loss: 5.5871, Accuracy: 0.0040, Val Loss: 5.5543, Val Accuracy: 0.0038\n",
      "Epoch 2/50, Loss: 5.5524, Accuracy: 0.0038, Val Loss: 5.5468, Val Accuracy: 0.0044\n",
      "Epoch 3/50, Loss: 5.5457, Accuracy: 0.0043, Val Loss: 5.5469, Val Accuracy: 0.0042\n",
      "Epoch 4/50, Loss: 5.5452, Accuracy: 0.0039, Val Loss: 5.5469, Val Accuracy: 0.0034\n",
      "Epoch 5/50, Loss: 5.5450, Accuracy: 0.0044, Val Loss: 5.5471, Val Accuracy: 0.0038\n",
      "Epoch 6/50, Loss: 5.5437, Accuracy: 0.0045, Val Loss: 5.5469, Val Accuracy: 0.0037\n",
      "Epoch 7/50, Loss: 5.5426, Accuracy: 0.0047, Val Loss: 5.5475, Val Accuracy: 0.0039\n",
      "Early stopping\n",
      "Accuracy for byte 2: 0.36%\n",
      "\n",
      "Training for byte 3...\n",
      "Epoch 1/50, Loss: 5.5854, Accuracy: 0.0037, Val Loss: 5.5576, Val Accuracy: 0.0036\n",
      "Epoch 2/50, Loss: 5.5509, Accuracy: 0.0045, Val Loss: 5.5462, Val Accuracy: 0.0040\n",
      "Epoch 3/50, Loss: 5.5454, Accuracy: 0.0047, Val Loss: 5.5468, Val Accuracy: 0.0032\n",
      "Epoch 4/50, Loss: 5.5450, Accuracy: 0.0042, Val Loss: 5.5473, Val Accuracy: 0.0036\n",
      "Epoch 5/50, Loss: 5.5446, Accuracy: 0.0043, Val Loss: 5.5469, Val Accuracy: 0.0032\n",
      "Epoch 6/50, Loss: 5.5432, Accuracy: 0.0049, Val Loss: 5.5473, Val Accuracy: 0.0038\n",
      "Epoch 7/50, Loss: 5.5425, Accuracy: 0.0051, Val Loss: 5.5475, Val Accuracy: 0.0034\n",
      "Early stopping\n",
      "Accuracy for byte 3: 0.41%\n",
      "\n",
      "Training for byte 4...\n",
      "Epoch 1/50, Loss: 5.5869, Accuracy: 0.0039, Val Loss: 5.5530, Val Accuracy: 0.0040\n",
      "Epoch 2/50, Loss: 5.5514, Accuracy: 0.0042, Val Loss: 5.5463, Val Accuracy: 0.0049\n",
      "Epoch 3/50, Loss: 5.5454, Accuracy: 0.0040, Val Loss: 5.5471, Val Accuracy: 0.0035\n",
      "Epoch 4/50, Loss: 5.5456, Accuracy: 0.0045, Val Loss: 5.5476, Val Accuracy: 0.0040\n",
      "Epoch 5/50, Loss: 5.5454, Accuracy: 0.0041, Val Loss: 5.5470, Val Accuracy: 0.0034\n",
      "Epoch 6/50, Loss: 5.5435, Accuracy: 0.0045, Val Loss: 5.5471, Val Accuracy: 0.0051\n",
      "Epoch 7/50, Loss: 5.5430, Accuracy: 0.0042, Val Loss: 5.5480, Val Accuracy: 0.0038\n",
      "Early stopping\n",
      "Accuracy for byte 4: 0.44%\n",
      "\n",
      "Training for byte 5...\n",
      "Epoch 1/50, Loss: 5.5855, Accuracy: 0.0038, Val Loss: 5.5516, Val Accuracy: 0.0046\n",
      "Epoch 2/50, Loss: 5.5490, Accuracy: 0.0040, Val Loss: 5.5466, Val Accuracy: 0.0036\n",
      "Epoch 3/50, Loss: 5.5455, Accuracy: 0.0041, Val Loss: 5.5462, Val Accuracy: 0.0034\n",
      "Epoch 4/50, Loss: 5.5448, Accuracy: 0.0045, Val Loss: 5.5461, Val Accuracy: 0.0032\n",
      "Epoch 5/50, Loss: 5.5448, Accuracy: 0.0043, Val Loss: 5.5462, Val Accuracy: 0.0042\n",
      "Epoch 6/50, Loss: 5.5436, Accuracy: 0.0045, Val Loss: 5.5465, Val Accuracy: 0.0042\n",
      "Epoch 7/50, Loss: 5.5432, Accuracy: 0.0045, Val Loss: 5.5469, Val Accuracy: 0.0038\n",
      "Epoch 8/50, Loss: 5.5431, Accuracy: 0.0047, Val Loss: 5.5472, Val Accuracy: 0.0037\n",
      "Epoch 9/50, Loss: 5.5416, Accuracy: 0.0050, Val Loss: 5.5468, Val Accuracy: 0.0036\n",
      "Early stopping\n",
      "Accuracy for byte 5: 0.41%\n",
      "\n",
      "Training for byte 6...\n",
      "Epoch 1/50, Loss: 5.5868, Accuracy: 0.0040, Val Loss: 5.5560, Val Accuracy: 0.0043\n",
      "Epoch 2/50, Loss: 5.5534, Accuracy: 0.0044, Val Loss: 5.5471, Val Accuracy: 0.0040\n",
      "Epoch 3/50, Loss: 5.5458, Accuracy: 0.0042, Val Loss: 5.5466, Val Accuracy: 0.0034\n",
      "Epoch 4/50, Loss: 5.5450, Accuracy: 0.0042, Val Loss: 5.5468, Val Accuracy: 0.0037\n",
      "Epoch 5/50, Loss: 5.5448, Accuracy: 0.0047, Val Loss: 5.5474, Val Accuracy: 0.0036\n",
      "Epoch 6/50, Loss: 5.5435, Accuracy: 0.0043, Val Loss: 5.5472, Val Accuracy: 0.0039\n",
      "Epoch 7/50, Loss: 5.5422, Accuracy: 0.0049, Val Loss: 5.5482, Val Accuracy: 0.0034\n",
      "Epoch 8/50, Loss: 5.5409, Accuracy: 0.0049, Val Loss: 5.5498, Val Accuracy: 0.0040\n",
      "Early stopping\n",
      "Accuracy for byte 6: 0.37%\n",
      "\n",
      "Training for byte 7...\n",
      "Epoch 1/50, Loss: 5.5863, Accuracy: 0.0041, Val Loss: 5.5543, Val Accuracy: 0.0029\n",
      "Epoch 2/50, Loss: 5.5521, Accuracy: 0.0040, Val Loss: 5.5468, Val Accuracy: 0.0044\n",
      "Epoch 3/50, Loss: 5.5458, Accuracy: 0.0040, Val Loss: 5.5463, Val Accuracy: 0.0040\n",
      "Epoch 4/50, Loss: 5.5454, Accuracy: 0.0039, Val Loss: 5.5462, Val Accuracy: 0.0036\n",
      "Epoch 5/50, Loss: 5.5451, Accuracy: 0.0037, Val Loss: 5.5465, Val Accuracy: 0.0040\n",
      "Epoch 6/50, Loss: 5.5444, Accuracy: 0.0048, Val Loss: 5.5468, Val Accuracy: 0.0028\n",
      "Epoch 7/50, Loss: 5.5441, Accuracy: 0.0042, Val Loss: 5.5474, Val Accuracy: 0.0038\n",
      "Epoch 8/50, Loss: 5.5425, Accuracy: 0.0050, Val Loss: 5.5477, Val Accuracy: 0.0043\n",
      "Epoch 9/50, Loss: 5.5411, Accuracy: 0.0047, Val Loss: 5.5483, Val Accuracy: 0.0040\n",
      "Early stopping\n",
      "Accuracy for byte 7: 0.33%\n",
      "\n",
      "Training for byte 8...\n",
      "Epoch 1/50, Loss: 5.5861, Accuracy: 0.0042, Val Loss: 5.5563, Val Accuracy: 0.0036\n",
      "Epoch 2/50, Loss: 5.5510, Accuracy: 0.0038, Val Loss: 5.5469, Val Accuracy: 0.0032\n",
      "Epoch 3/50, Loss: 5.5456, Accuracy: 0.0043, Val Loss: 5.5465, Val Accuracy: 0.0027\n",
      "Epoch 4/50, Loss: 5.5457, Accuracy: 0.0045, Val Loss: 5.5470, Val Accuracy: 0.0042\n",
      "Epoch 5/50, Loss: 5.5452, Accuracy: 0.0044, Val Loss: 5.5467, Val Accuracy: 0.0038\n",
      "Epoch 6/50, Loss: 5.5437, Accuracy: 0.0044, Val Loss: 5.5469, Val Accuracy: 0.0040\n",
      "Epoch 7/50, Loss: 5.5429, Accuracy: 0.0044, Val Loss: 5.5470, Val Accuracy: 0.0034\n",
      "Epoch 8/50, Loss: 5.5417, Accuracy: 0.0048, Val Loss: 5.5479, Val Accuracy: 0.0042\n",
      "Early stopping\n",
      "Accuracy for byte 8: 0.43%\n",
      "\n",
      "Training for byte 9...\n",
      "Epoch 1/50, Loss: 5.5855, Accuracy: 0.0039, Val Loss: 5.5552, Val Accuracy: 0.0036\n",
      "Epoch 2/50, Loss: 5.5503, Accuracy: 0.0040, Val Loss: 5.5464, Val Accuracy: 0.0038\n",
      "Epoch 3/50, Loss: 5.5453, Accuracy: 0.0040, Val Loss: 5.5464, Val Accuracy: 0.0039\n",
      "Epoch 4/50, Loss: 5.5454, Accuracy: 0.0044, Val Loss: 5.5465, Val Accuracy: 0.0042\n",
      "Epoch 5/50, Loss: 5.5449, Accuracy: 0.0046, Val Loss: 5.5461, Val Accuracy: 0.0046\n",
      "Epoch 6/50, Loss: 5.5435, Accuracy: 0.0049, Val Loss: 5.5466, Val Accuracy: 0.0037\n",
      "Epoch 7/50, Loss: 5.5431, Accuracy: 0.0047, Val Loss: 5.5469, Val Accuracy: 0.0040\n",
      "Epoch 8/50, Loss: 5.5421, Accuracy: 0.0047, Val Loss: 5.5472, Val Accuracy: 0.0043\n",
      "Epoch 9/50, Loss: 5.5397, Accuracy: 0.0050, Val Loss: 5.5487, Val Accuracy: 0.0034\n",
      "Epoch 10/50, Loss: 5.5387, Accuracy: 0.0050, Val Loss: 5.5497, Val Accuracy: 0.0041\n",
      "Early stopping\n",
      "Accuracy for byte 9: 0.44%\n",
      "\n",
      "Accuracies for all 10 bytes:\n",
      "Byte 0: 0.38%\n",
      "Byte 1: 0.40%\n",
      "Byte 2: 0.36%\n",
      "Byte 3: 0.41%\n",
      "Byte 4: 0.44%\n",
      "Byte 5: 0.41%\n",
      "Byte 6: 0.37%\n",
      "Byte 7: 0.33%\n",
      "Byte 8: 0.43%\n",
      "Byte 9: 0.44%\n"
     ]
    }
   ],
   "source": [
    "# Function to train and evaluate a model for a specific byte of the keystream\n",
    "def train_and_evaluate(X_train, y_train, X_val, y_val, X_test, y_test, byte_index):\n",
    "    # Initialize the model, loss function, and optimizer\n",
    "    model = ImprovedKeystreamClassifier()\n",
    "    criterion = nn.CrossEntropyLoss()  # Cross-Entropy Loss for classification\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-5)\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=2, factor=0.5)\n",
    "\n",
    "    # Convert data to PyTorch tensors\n",
    "    y_train_tensor = torch.tensor(y_train[:, byte_index], dtype=torch.long)\n",
    "    y_val_tensor = torch.tensor(y_val[:, byte_index], dtype=torch.long)\n",
    "    y_test_tensor = torch.tensor(y_test[:, byte_index], dtype=torch.long)\n",
    "\n",
    "    # Create data loaders\n",
    "    train_dataset = torch.utils.data.TensorDataset(torch.tensor(X_train, dtype=torch.float32), y_train_tensor)\n",
    "    val_dataset = torch.utils.data.TensorDataset(torch.tensor(X_val, dtype=torch.float32), y_val_tensor)\n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "    val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "    # Early stopping parameters\n",
    "    patience = 5\n",
    "    best_val_loss = float('inf')\n",
    "    best_model = None\n",
    "    patience_counter = 0\n",
    "\n",
    "    # Training the model\n",
    "    num_epochs = 50\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct_train = 0\n",
    "        total_train = 0\n",
    "\n",
    "        for inputs, labels in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            correct_train += (predicted == labels).sum().item()\n",
    "            total_train += labels.size(0)\n",
    "\n",
    "        train_loss = running_loss / len(train_loader)\n",
    "        train_accuracy = correct_train / total_train\n",
    "\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        correct_val = 0\n",
    "        total_val = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                correct_val += (predicted == labels).sum().item()\n",
    "                total_val += labels.size(0)\n",
    "\n",
    "        val_loss /= len(val_loader)\n",
    "        val_accuracy = correct_val / total_val\n",
    "\n",
    "        print(f'Epoch {epoch+1}/{num_epochs}, Loss: {train_loss:.4f}, Accuracy: {train_accuracy:.4f}, Val Loss: {val_loss:.4f}, Val Accuracy: {val_accuracy:.4f}')\n",
    "\n",
    "        # Adjust learning rate based on validation loss\n",
    "        scheduler.step(val_loss)\n",
    "\n",
    "        # Early stopping\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            best_model = model.state_dict()\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= patience:\n",
    "                print(\"Early stopping\")\n",
    "                break\n",
    "\n",
    "    # Load the best model\n",
    "    model.load_state_dict(best_model)\n",
    "\n",
    "    # Evaluate the model on the test set\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        outputs = model(torch.tensor(X_test, dtype=torch.float32))\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        test_accuracy = accuracy_score(y_test[:, byte_index], predicted.numpy())\n",
    "        return test_accuracy\n",
    "\n",
    "# Train and evaluate the model for each byte and print the accuracy\n",
    "accuracies = []\n",
    "for byte_index in range(10):\n",
    "    print(f'\\nTraining for byte {byte_index}...')\n",
    "    accuracy = train_and_evaluate(X_train, y_train, X_val, y_val, X_test, y_test, byte_index)\n",
    "    accuracies.append(accuracy)\n",
    "    print(f'Accuracy for byte {byte_index}: {accuracy * 100:.2f}%')\n",
    "\n",
    "# Print all accuracies\n",
    "print(\"\\nAccuracies for all 10 bytes:\")\n",
    "for byte_index, accuracy in enumerate(accuracies):\n",
    "    print(f'Byte {byte_index}: {accuracy * 100:.2f}%')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2215a16-c36d-4799-a35b-7442f4621394",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# 15lakh samples L2 re (shared to sir) One may use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a1997bc5-0306-4ba3-8b94-a536618e9af3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Check if GPU is available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device: {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f3dc74a4-3065-40ed-99e6-73dce1efcfc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training for byte 0...\n",
      "Epoch 1/50, Loss: 5.5509, Accuracy: 0.0039, Val Loss: 5.5458, Val Accuracy: 0.0039\n",
      "Epoch 2/50, Loss: 5.5458, Accuracy: 0.0038, Val Loss: 5.5457, Val Accuracy: 0.0038\n",
      "Epoch 3/50, Loss: 5.5457, Accuracy: 0.0038, Val Loss: 5.5457, Val Accuracy: 0.0041\n",
      "Epoch 4/50, Loss: 5.5457, Accuracy: 0.0038, Val Loss: 5.5456, Val Accuracy: 0.0037\n",
      "Epoch 5/50, Loss: 5.5454, Accuracy: 0.0039, Val Loss: 5.5455, Val Accuracy: 0.0038\n",
      "Epoch 6/50, Loss: 5.5454, Accuracy: 0.0040, Val Loss: 5.5456, Val Accuracy: 0.0038\n",
      "Epoch 7/50, Loss: 5.5454, Accuracy: 0.0039, Val Loss: 5.5455, Val Accuracy: 0.0039\n",
      "Epoch 8/50, Loss: 5.5453, Accuracy: 0.0039, Val Loss: 5.5454, Val Accuracy: 0.0037\n",
      "Epoch 9/50, Loss: 5.5453, Accuracy: 0.0039, Val Loss: 5.5454, Val Accuracy: 0.0041\n",
      "Epoch 10/50, Loss: 5.5453, Accuracy: 0.0039, Val Loss: 5.5454, Val Accuracy: 0.0041\n",
      "Epoch 11/50, Loss: 5.5452, Accuracy: 0.0039, Val Loss: 5.5454, Val Accuracy: 0.0037\n",
      "Epoch 12/50, Loss: 5.5452, Accuracy: 0.0039, Val Loss: 5.5454, Val Accuracy: 0.0041\n",
      "Epoch 13/50, Loss: 5.5452, Accuracy: 0.0038, Val Loss: 5.5454, Val Accuracy: 0.0041\n",
      "Epoch 14/50, Loss: 5.5451, Accuracy: 0.0039, Val Loss: 5.5454, Val Accuracy: 0.0041\n",
      "Epoch 15/50, Loss: 5.5451, Accuracy: 0.0039, Val Loss: 5.5454, Val Accuracy: 0.0041\n",
      "Epoch 16/50, Loss: 5.5451, Accuracy: 0.0040, Val Loss: 5.5454, Val Accuracy: 0.0037\n",
      "Epoch 17/50, Loss: 5.5451, Accuracy: 0.0041, Val Loss: 5.5454, Val Accuracy: 0.0038\n",
      "Epoch 18/50, Loss: 5.5450, Accuracy: 0.0041, Val Loss: 5.5454, Val Accuracy: 0.0038\n",
      "Early stopping\n",
      "Accuracy for byte 0: 0.38%\n",
      "\n",
      "Training for byte 1...\n",
      "Epoch 1/50, Loss: 5.5511, Accuracy: 0.0040, Val Loss: 5.5459, Val Accuracy: 0.0037\n",
      "Epoch 2/50, Loss: 5.5458, Accuracy: 0.0039, Val Loss: 5.5458, Val Accuracy: 0.0037\n",
      "Epoch 3/50, Loss: 5.5457, Accuracy: 0.0040, Val Loss: 5.5457, Val Accuracy: 0.0041\n",
      "Epoch 4/50, Loss: 5.5457, Accuracy: 0.0039, Val Loss: 5.5456, Val Accuracy: 0.0041\n",
      "Epoch 5/50, Loss: 5.5454, Accuracy: 0.0041, Val Loss: 5.5455, Val Accuracy: 0.0041\n",
      "Epoch 6/50, Loss: 5.5454, Accuracy: 0.0041, Val Loss: 5.5454, Val Accuracy: 0.0041\n",
      "Epoch 7/50, Loss: 5.5454, Accuracy: 0.0040, Val Loss: 5.5454, Val Accuracy: 0.0041\n",
      "Epoch 8/50, Loss: 5.5453, Accuracy: 0.0041, Val Loss: 5.5453, Val Accuracy: 0.0041\n",
      "Epoch 9/50, Loss: 5.5453, Accuracy: 0.0040, Val Loss: 5.5453, Val Accuracy: 0.0043\n",
      "Epoch 10/50, Loss: 5.5453, Accuracy: 0.0039, Val Loss: 5.5454, Val Accuracy: 0.0041\n",
      "Epoch 11/50, Loss: 5.5453, Accuracy: 0.0040, Val Loss: 5.5454, Val Accuracy: 0.0038\n",
      "Epoch 12/50, Loss: 5.5453, Accuracy: 0.0039, Val Loss: 5.5454, Val Accuracy: 0.0041\n",
      "Epoch 13/50, Loss: 5.5452, Accuracy: 0.0041, Val Loss: 5.5453, Val Accuracy: 0.0041\n",
      "Epoch 14/50, Loss: 5.5452, Accuracy: 0.0041, Val Loss: 5.5453, Val Accuracy: 0.0041\n",
      "Early stopping\n",
      "Accuracy for byte 1: 0.40%\n",
      "\n",
      "Training for byte 2...\n",
      "Epoch 1/50, Loss: 5.5509, Accuracy: 0.0040, Val Loss: 5.5458, Val Accuracy: 0.0039\n",
      "Epoch 2/50, Loss: 5.5458, Accuracy: 0.0040, Val Loss: 5.5457, Val Accuracy: 0.0036\n",
      "Epoch 3/50, Loss: 5.5457, Accuracy: 0.0040, Val Loss: 5.5459, Val Accuracy: 0.0037\n",
      "Epoch 4/50, Loss: 5.5457, Accuracy: 0.0040, Val Loss: 5.5456, Val Accuracy: 0.0042\n",
      "Epoch 5/50, Loss: 5.5454, Accuracy: 0.0040, Val Loss: 5.5455, Val Accuracy: 0.0040\n",
      "Epoch 6/50, Loss: 5.5454, Accuracy: 0.0040, Val Loss: 5.5454, Val Accuracy: 0.0039\n",
      "Epoch 7/50, Loss: 5.5454, Accuracy: 0.0039, Val Loss: 5.5454, Val Accuracy: 0.0037\n",
      "Epoch 8/50, Loss: 5.5453, Accuracy: 0.0039, Val Loss: 5.5453, Val Accuracy: 0.0037\n",
      "Epoch 9/50, Loss: 5.5452, Accuracy: 0.0041, Val Loss: 5.5453, Val Accuracy: 0.0040\n",
      "Epoch 10/50, Loss: 5.5452, Accuracy: 0.0039, Val Loss: 5.5454, Val Accuracy: 0.0039\n",
      "Epoch 11/50, Loss: 5.5452, Accuracy: 0.0040, Val Loss: 5.5453, Val Accuracy: 0.0040\n",
      "Epoch 12/50, Loss: 5.5452, Accuracy: 0.0040, Val Loss: 5.5453, Val Accuracy: 0.0039\n",
      "Epoch 13/50, Loss: 5.5451, Accuracy: 0.0040, Val Loss: 5.5453, Val Accuracy: 0.0039\n",
      "Epoch 14/50, Loss: 5.5451, Accuracy: 0.0040, Val Loss: 5.5453, Val Accuracy: 0.0037\n",
      "Epoch 15/50, Loss: 5.5451, Accuracy: 0.0040, Val Loss: 5.5453, Val Accuracy: 0.0037\n",
      "Epoch 16/50, Loss: 5.5451, Accuracy: 0.0040, Val Loss: 5.5453, Val Accuracy: 0.0037\n",
      "Epoch 17/50, Loss: 5.5451, Accuracy: 0.0040, Val Loss: 5.5453, Val Accuracy: 0.0039\n",
      "Epoch 18/50, Loss: 5.5451, Accuracy: 0.0041, Val Loss: 5.5453, Val Accuracy: 0.0041\n",
      "Epoch 19/50, Loss: 5.5451, Accuracy: 0.0040, Val Loss: 5.5453, Val Accuracy: 0.0040\n",
      "Epoch 20/50, Loss: 5.5450, Accuracy: 0.0041, Val Loss: 5.5453, Val Accuracy: 0.0040\n",
      "Epoch 21/50, Loss: 5.5450, Accuracy: 0.0041, Val Loss: 5.5453, Val Accuracy: 0.0040\n",
      "Epoch 22/50, Loss: 5.5450, Accuracy: 0.0042, Val Loss: 5.5453, Val Accuracy: 0.0040\n",
      "Epoch 23/50, Loss: 5.5450, Accuracy: 0.0042, Val Loss: 5.5453, Val Accuracy: 0.0041\n",
      "Early stopping\n",
      "Accuracy for byte 2: 0.42%\n",
      "\n",
      "Training for byte 3...\n",
      "Epoch 1/50, Loss: 5.5512, Accuracy: 0.0039, Val Loss: 5.5457, Val Accuracy: 0.0038\n",
      "Epoch 2/50, Loss: 5.5459, Accuracy: 0.0039, Val Loss: 5.5458, Val Accuracy: 0.0039\n",
      "Epoch 3/50, Loss: 5.5457, Accuracy: 0.0040, Val Loss: 5.5458, Val Accuracy: 0.0039\n",
      "Epoch 4/50, Loss: 5.5457, Accuracy: 0.0039, Val Loss: 5.5456, Val Accuracy: 0.0037\n",
      "Epoch 5/50, Loss: 5.5454, Accuracy: 0.0040, Val Loss: 5.5455, Val Accuracy: 0.0040\n",
      "Epoch 6/50, Loss: 5.5454, Accuracy: 0.0039, Val Loss: 5.5454, Val Accuracy: 0.0036\n",
      "Epoch 7/50, Loss: 5.5454, Accuracy: 0.0040, Val Loss: 5.5454, Val Accuracy: 0.0037\n",
      "Epoch 8/50, Loss: 5.5453, Accuracy: 0.0039, Val Loss: 5.5453, Val Accuracy: 0.0039\n",
      "Epoch 9/50, Loss: 5.5453, Accuracy: 0.0039, Val Loss: 5.5454, Val Accuracy: 0.0039\n",
      "Epoch 10/50, Loss: 5.5453, Accuracy: 0.0041, Val Loss: 5.5453, Val Accuracy: 0.0038\n",
      "Epoch 11/50, Loss: 5.5452, Accuracy: 0.0040, Val Loss: 5.5453, Val Accuracy: 0.0038\n",
      "Epoch 12/50, Loss: 5.5452, Accuracy: 0.0040, Val Loss: 5.5453, Val Accuracy: 0.0038\n",
      "Epoch 13/50, Loss: 5.5452, Accuracy: 0.0040, Val Loss: 5.5453, Val Accuracy: 0.0037\n",
      "Epoch 14/50, Loss: 5.5451, Accuracy: 0.0040, Val Loss: 5.5453, Val Accuracy: 0.0038\n",
      "Epoch 15/50, Loss: 5.5451, Accuracy: 0.0040, Val Loss: 5.5453, Val Accuracy: 0.0038\n",
      "Epoch 16/50, Loss: 5.5451, Accuracy: 0.0040, Val Loss: 5.5453, Val Accuracy: 0.0038\n",
      "Epoch 17/50, Loss: 5.5451, Accuracy: 0.0040, Val Loss: 5.5453, Val Accuracy: 0.0038\n",
      "Epoch 18/50, Loss: 5.5451, Accuracy: 0.0041, Val Loss: 5.5453, Val Accuracy: 0.0038\n",
      "Early stopping\n",
      "Accuracy for byte 3: 0.39%\n",
      "\n",
      "Training for byte 4...\n",
      "Epoch 1/50, Loss: 5.5508, Accuracy: 0.0039, Val Loss: 5.5461, Val Accuracy: 0.0041\n",
      "Epoch 2/50, Loss: 5.5458, Accuracy: 0.0039, Val Loss: 5.5457, Val Accuracy: 0.0042\n",
      "Epoch 3/50, Loss: 5.5457, Accuracy: 0.0040, Val Loss: 5.5457, Val Accuracy: 0.0041\n",
      "Epoch 4/50, Loss: 5.5457, Accuracy: 0.0039, Val Loss: 5.5458, Val Accuracy: 0.0039\n",
      "Epoch 5/50, Loss: 5.5454, Accuracy: 0.0040, Val Loss: 5.5454, Val Accuracy: 0.0037\n",
      "Epoch 6/50, Loss: 5.5454, Accuracy: 0.0038, Val Loss: 5.5454, Val Accuracy: 0.0043\n",
      "Epoch 7/50, Loss: 5.5454, Accuracy: 0.0039, Val Loss: 5.5454, Val Accuracy: 0.0043\n",
      "Epoch 8/50, Loss: 5.5454, Accuracy: 0.0039, Val Loss: 5.5454, Val Accuracy: 0.0040\n",
      "Epoch 9/50, Loss: 5.5453, Accuracy: 0.0040, Val Loss: 5.5453, Val Accuracy: 0.0042\n",
      "Epoch 10/50, Loss: 5.5453, Accuracy: 0.0040, Val Loss: 5.5453, Val Accuracy: 0.0043\n",
      "Epoch 11/50, Loss: 5.5453, Accuracy: 0.0041, Val Loss: 5.5454, Val Accuracy: 0.0040\n",
      "Epoch 12/50, Loss: 5.5452, Accuracy: 0.0040, Val Loss: 5.5453, Val Accuracy: 0.0043\n",
      "Epoch 13/50, Loss: 5.5452, Accuracy: 0.0041, Val Loss: 5.5453, Val Accuracy: 0.0043\n",
      "Epoch 14/50, Loss: 5.5452, Accuracy: 0.0040, Val Loss: 5.5453, Val Accuracy: 0.0043\n",
      "Epoch 15/50, Loss: 5.5451, Accuracy: 0.0041, Val Loss: 5.5453, Val Accuracy: 0.0043\n",
      "Epoch 16/50, Loss: 5.5451, Accuracy: 0.0041, Val Loss: 5.5453, Val Accuracy: 0.0043\n",
      "Epoch 17/50, Loss: 5.5451, Accuracy: 0.0041, Val Loss: 5.5453, Val Accuracy: 0.0043\n",
      "Epoch 18/50, Loss: 5.5451, Accuracy: 0.0041, Val Loss: 5.5453, Val Accuracy: 0.0043\n",
      "Epoch 19/50, Loss: 5.5451, Accuracy: 0.0041, Val Loss: 5.5453, Val Accuracy: 0.0043\n",
      "Epoch 20/50, Loss: 5.5451, Accuracy: 0.0041, Val Loss: 5.5453, Val Accuracy: 0.0043\n",
      "Epoch 21/50, Loss: 5.5451, Accuracy: 0.0041, Val Loss: 5.5453, Val Accuracy: 0.0043\n",
      "Early stopping\n",
      "Accuracy for byte 4: 0.40%\n",
      "\n",
      "Training for byte 5...\n",
      "Epoch 1/50, Loss: 5.5509, Accuracy: 0.0040, Val Loss: 5.5456, Val Accuracy: 0.0040\n",
      "Epoch 2/50, Loss: 5.5458, Accuracy: 0.0039, Val Loss: 5.5458, Val Accuracy: 0.0039\n",
      "Epoch 3/50, Loss: 5.5457, Accuracy: 0.0039, Val Loss: 5.5456, Val Accuracy: 0.0037\n",
      "Epoch 4/50, Loss: 5.5457, Accuracy: 0.0039, Val Loss: 5.5456, Val Accuracy: 0.0040\n",
      "Epoch 5/50, Loss: 5.5454, Accuracy: 0.0040, Val Loss: 5.5454, Val Accuracy: 0.0040\n",
      "Epoch 6/50, Loss: 5.5454, Accuracy: 0.0039, Val Loss: 5.5454, Val Accuracy: 0.0040\n",
      "Epoch 7/50, Loss: 5.5454, Accuracy: 0.0039, Val Loss: 5.5454, Val Accuracy: 0.0042\n",
      "Epoch 8/50, Loss: 5.5453, Accuracy: 0.0040, Val Loss: 5.5453, Val Accuracy: 0.0038\n",
      "Epoch 9/50, Loss: 5.5453, Accuracy: 0.0039, Val Loss: 5.5453, Val Accuracy: 0.0041\n",
      "Epoch 10/50, Loss: 5.5453, Accuracy: 0.0039, Val Loss: 5.5453, Val Accuracy: 0.0041\n",
      "Epoch 11/50, Loss: 5.5452, Accuracy: 0.0040, Val Loss: 5.5453, Val Accuracy: 0.0038\n",
      "Epoch 12/50, Loss: 5.5452, Accuracy: 0.0040, Val Loss: 5.5453, Val Accuracy: 0.0041\n",
      "Epoch 13/50, Loss: 5.5452, Accuracy: 0.0039, Val Loss: 5.5453, Val Accuracy: 0.0041\n",
      "Epoch 14/50, Loss: 5.5451, Accuracy: 0.0040, Val Loss: 5.5453, Val Accuracy: 0.0041\n",
      "Epoch 15/50, Loss: 5.5451, Accuracy: 0.0040, Val Loss: 5.5453, Val Accuracy: 0.0038\n",
      "Epoch 16/50, Loss: 5.5451, Accuracy: 0.0040, Val Loss: 5.5453, Val Accuracy: 0.0038\n",
      "Epoch 17/50, Loss: 5.5451, Accuracy: 0.0040, Val Loss: 5.5453, Val Accuracy: 0.0038\n",
      "Epoch 18/50, Loss: 5.5451, Accuracy: 0.0041, Val Loss: 5.5453, Val Accuracy: 0.0038\n",
      "Epoch 19/50, Loss: 5.5451, Accuracy: 0.0041, Val Loss: 5.5453, Val Accuracy: 0.0038\n",
      "Epoch 20/50, Loss: 5.5451, Accuracy: 0.0041, Val Loss: 5.5453, Val Accuracy: 0.0038\n",
      "Epoch 21/50, Loss: 5.5451, Accuracy: 0.0041, Val Loss: 5.5453, Val Accuracy: 0.0038\n",
      "Early stopping\n",
      "Accuracy for byte 5: 0.40%\n",
      "\n",
      "Training for byte 6...\n",
      "Epoch 1/50, Loss: 5.5510, Accuracy: 0.0039, Val Loss: 5.5459, Val Accuracy: 0.0038\n",
      "Epoch 2/50, Loss: 5.5459, Accuracy: 0.0039, Val Loss: 5.5456, Val Accuracy: 0.0039\n",
      "Epoch 3/50, Loss: 5.5457, Accuracy: 0.0039, Val Loss: 5.5459, Val Accuracy: 0.0039\n",
      "Epoch 4/50, Loss: 5.5457, Accuracy: 0.0039, Val Loss: 5.5457, Val Accuracy: 0.0040\n",
      "Epoch 5/50, Loss: 5.5455, Accuracy: 0.0039, Val Loss: 5.5455, Val Accuracy: 0.0040\n",
      "Epoch 6/50, Loss: 5.5454, Accuracy: 0.0039, Val Loss: 5.5454, Val Accuracy: 0.0040\n",
      "Epoch 7/50, Loss: 5.5454, Accuracy: 0.0040, Val Loss: 5.5454, Val Accuracy: 0.0039\n",
      "Epoch 8/50, Loss: 5.5453, Accuracy: 0.0039, Val Loss: 5.5453, Val Accuracy: 0.0039\n",
      "Epoch 9/50, Loss: 5.5453, Accuracy: 0.0039, Val Loss: 5.5453, Val Accuracy: 0.0037\n",
      "Epoch 10/50, Loss: 5.5453, Accuracy: 0.0038, Val Loss: 5.5453, Val Accuracy: 0.0037\n",
      "Epoch 11/50, Loss: 5.5452, Accuracy: 0.0040, Val Loss: 5.5453, Val Accuracy: 0.0038\n",
      "Epoch 12/50, Loss: 5.5452, Accuracy: 0.0039, Val Loss: 5.5453, Val Accuracy: 0.0039\n",
      "Epoch 13/50, Loss: 5.5452, Accuracy: 0.0039, Val Loss: 5.5453, Val Accuracy: 0.0039\n",
      "Epoch 14/50, Loss: 5.5451, Accuracy: 0.0040, Val Loss: 5.5453, Val Accuracy: 0.0039\n",
      "Early stopping\n",
      "Accuracy for byte 6: 0.40%\n",
      "\n",
      "Training for byte 7...\n",
      "Epoch 1/50, Loss: 5.5508, Accuracy: 0.0039, Val Loss: 5.5458, Val Accuracy: 0.0039\n",
      "Epoch 2/50, Loss: 5.5458, Accuracy: 0.0038, Val Loss: 5.5456, Val Accuracy: 0.0038\n",
      "Epoch 3/50, Loss: 5.5457, Accuracy: 0.0039, Val Loss: 5.5458, Val Accuracy: 0.0037\n",
      "Epoch 4/50, Loss: 5.5457, Accuracy: 0.0038, Val Loss: 5.5456, Val Accuracy: 0.0037\n",
      "Epoch 5/50, Loss: 5.5454, Accuracy: 0.0038, Val Loss: 5.5454, Val Accuracy: 0.0041\n",
      "Epoch 6/50, Loss: 5.5454, Accuracy: 0.0039, Val Loss: 5.5454, Val Accuracy: 0.0041\n",
      "Epoch 7/50, Loss: 5.5454, Accuracy: 0.0039, Val Loss: 5.5453, Val Accuracy: 0.0040\n",
      "Epoch 8/50, Loss: 5.5453, Accuracy: 0.0039, Val Loss: 5.5453, Val Accuracy: 0.0038\n",
      "Epoch 9/50, Loss: 5.5453, Accuracy: 0.0040, Val Loss: 5.5453, Val Accuracy: 0.0041\n",
      "Epoch 10/50, Loss: 5.5453, Accuracy: 0.0040, Val Loss: 5.5453, Val Accuracy: 0.0041\n",
      "Epoch 11/50, Loss: 5.5452, Accuracy: 0.0039, Val Loss: 5.5453, Val Accuracy: 0.0041\n",
      "Epoch 12/50, Loss: 5.5453, Accuracy: 0.0040, Val Loss: 5.5453, Val Accuracy: 0.0041\n",
      "Epoch 13/50, Loss: 5.5452, Accuracy: 0.0038, Val Loss: 5.5453, Val Accuracy: 0.0041\n",
      "Epoch 14/50, Loss: 5.5452, Accuracy: 0.0040, Val Loss: 5.5453, Val Accuracy: 0.0041\n",
      "Epoch 15/50, Loss: 5.5452, Accuracy: 0.0040, Val Loss: 5.5452, Val Accuracy: 0.0041\n",
      "Epoch 16/50, Loss: 5.5452, Accuracy: 0.0040, Val Loss: 5.5452, Val Accuracy: 0.0041\n",
      "Epoch 17/50, Loss: 5.5451, Accuracy: 0.0040, Val Loss: 5.5452, Val Accuracy: 0.0041\n",
      "Epoch 18/50, Loss: 5.5451, Accuracy: 0.0040, Val Loss: 5.5453, Val Accuracy: 0.0041\n",
      "Epoch 19/50, Loss: 5.5451, Accuracy: 0.0040, Val Loss: 5.5452, Val Accuracy: 0.0041\n",
      "Epoch 20/50, Loss: 5.5451, Accuracy: 0.0040, Val Loss: 5.5452, Val Accuracy: 0.0041\n",
      "Early stopping\n",
      "Accuracy for byte 7: 0.39%\n",
      "\n",
      "Training for byte 8...\n",
      "Epoch 1/50, Loss: 5.5511, Accuracy: 0.0040, Val Loss: 5.5457, Val Accuracy: 0.0036\n",
      "Epoch 2/50, Loss: 5.5459, Accuracy: 0.0040, Val Loss: 5.5457, Val Accuracy: 0.0040\n",
      "Epoch 3/50, Loss: 5.5457, Accuracy: 0.0040, Val Loss: 5.5457, Val Accuracy: 0.0038\n",
      "Epoch 4/50, Loss: 5.5457, Accuracy: 0.0039, Val Loss: 5.5456, Val Accuracy: 0.0036\n",
      "Epoch 5/50, Loss: 5.5455, Accuracy: 0.0038, Val Loss: 5.5454, Val Accuracy: 0.0038\n",
      "Epoch 6/50, Loss: 5.5454, Accuracy: 0.0040, Val Loss: 5.5454, Val Accuracy: 0.0038\n",
      "Epoch 7/50, Loss: 5.5454, Accuracy: 0.0039, Val Loss: 5.5453, Val Accuracy: 0.0040\n",
      "Epoch 8/50, Loss: 5.5453, Accuracy: 0.0040, Val Loss: 5.5453, Val Accuracy: 0.0041\n",
      "Epoch 9/50, Loss: 5.5453, Accuracy: 0.0040, Val Loss: 5.5453, Val Accuracy: 0.0041\n",
      "Epoch 10/50, Loss: 5.5453, Accuracy: 0.0040, Val Loss: 5.5452, Val Accuracy: 0.0041\n",
      "Epoch 11/50, Loss: 5.5452, Accuracy: 0.0040, Val Loss: 5.5452, Val Accuracy: 0.0041\n",
      "Epoch 12/50, Loss: 5.5452, Accuracy: 0.0041, Val Loss: 5.5452, Val Accuracy: 0.0041\n",
      "Epoch 13/50, Loss: 5.5452, Accuracy: 0.0040, Val Loss: 5.5452, Val Accuracy: 0.0041\n",
      "Epoch 14/50, Loss: 5.5451, Accuracy: 0.0041, Val Loss: 5.5452, Val Accuracy: 0.0041\n",
      "Epoch 15/50, Loss: 5.5451, Accuracy: 0.0041, Val Loss: 5.5452, Val Accuracy: 0.0041\n",
      "Epoch 16/50, Loss: 5.5451, Accuracy: 0.0041, Val Loss: 5.5452, Val Accuracy: 0.0041\n",
      "Epoch 17/50, Loss: 5.5451, Accuracy: 0.0041, Val Loss: 5.5452, Val Accuracy: 0.0041\n",
      "Epoch 18/50, Loss: 5.5451, Accuracy: 0.0041, Val Loss: 5.5452, Val Accuracy: 0.0041\n",
      "Early stopping\n",
      "Accuracy for byte 8: 0.41%\n",
      "\n",
      "Training for byte 9...\n",
      "Epoch 1/50, Loss: 5.5508, Accuracy: 0.0038, Val Loss: 5.5457, Val Accuracy: 0.0039\n",
      "Epoch 2/50, Loss: 5.5458, Accuracy: 0.0039, Val Loss: 5.5457, Val Accuracy: 0.0040\n",
      "Epoch 3/50, Loss: 5.5457, Accuracy: 0.0039, Val Loss: 5.5455, Val Accuracy: 0.0039\n",
      "Epoch 4/50, Loss: 5.5457, Accuracy: 0.0040, Val Loss: 5.5458, Val Accuracy: 0.0035\n",
      "Epoch 5/50, Loss: 5.5454, Accuracy: 0.0039, Val Loss: 5.5455, Val Accuracy: 0.0040\n",
      "Epoch 6/50, Loss: 5.5454, Accuracy: 0.0039, Val Loss: 5.5454, Val Accuracy: 0.0039\n",
      "Epoch 7/50, Loss: 5.5454, Accuracy: 0.0040, Val Loss: 5.5455, Val Accuracy: 0.0038\n",
      "Epoch 8/50, Loss: 5.5453, Accuracy: 0.0040, Val Loss: 5.5453, Val Accuracy: 0.0040\n",
      "Epoch 9/50, Loss: 5.5452, Accuracy: 0.0041, Val Loss: 5.5453, Val Accuracy: 0.0035\n",
      "Epoch 10/50, Loss: 5.5453, Accuracy: 0.0039, Val Loss: 5.5454, Val Accuracy: 0.0040\n",
      "Epoch 11/50, Loss: 5.5452, Accuracy: 0.0040, Val Loss: 5.5453, Val Accuracy: 0.0041\n",
      "Epoch 12/50, Loss: 5.5452, Accuracy: 0.0040, Val Loss: 5.5453, Val Accuracy: 0.0039\n",
      "Epoch 13/50, Loss: 5.5452, Accuracy: 0.0040, Val Loss: 5.5453, Val Accuracy: 0.0038\n",
      "Epoch 14/50, Loss: 5.5451, Accuracy: 0.0040, Val Loss: 5.5453, Val Accuracy: 0.0038\n",
      "Early stopping\n",
      "Accuracy for byte 9: 0.39%\n",
      "\n",
      "Accuracies for all 10 bytes:\n",
      "Byte 0: 0.38%\n",
      "Byte 1: 0.40%\n",
      "Byte 2: 0.42%\n",
      "Byte 3: 0.39%\n",
      "Byte 4: 0.40%\n",
      "Byte 5: 0.40%\n",
      "Byte 6: 0.40%\n",
      "Byte 7: 0.39%\n",
      "Byte 8: 0.41%\n",
      "Byte 9: 0.39%\n"
     ]
    }
   ],
   "source": [
    "# Function to train and evaluate a model for a specific byte of the keystream\n",
    "def train_and_evaluate(X_train, y_train, X_val, y_val, X_test, y_test, byte_index):\n",
    "    # Initialize the model, loss function, and optimizer\n",
    "    model = ImprovedKeystreamClassifier().to(device)\n",
    "    criterion = nn.CrossEntropyLoss()  # Cross-Entropy Loss for classification\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-5)\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=2, factor=0.5)\n",
    "\n",
    "    # Convert data to PyTorch tensors and move to GPU if available\n",
    "    X_train_tensor = torch.tensor(X_train, dtype=torch.float32).to(device)\n",
    "    y_train_tensor = torch.tensor(y_train[:, byte_index], dtype=torch.long).to(device)\n",
    "    X_val_tensor = torch.tensor(X_val, dtype=torch.float32).to(device)\n",
    "    y_val_tensor = torch.tensor(y_val[:, byte_index], dtype=torch.long).to(device)\n",
    "    X_test_tensor = torch.tensor(X_test, dtype=torch.float32).to(device)\n",
    "    y_test_tensor = torch.tensor(y_test[:, byte_index], dtype=torch.long).to(device)\n",
    "\n",
    "    # Create data loaders\n",
    "    train_dataset = torch.utils.data.TensorDataset(X_train_tensor, y_train_tensor)\n",
    "    val_dataset = torch.utils.data.TensorDataset(X_val_tensor, y_val_tensor)\n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "    val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "    # Early stopping parameters\n",
    "    patience = 5\n",
    "    best_val_loss = float('inf')\n",
    "    best_model = None\n",
    "    patience_counter = 0\n",
    "\n",
    "    # Training the model\n",
    "    num_epochs = 50\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct_train = 0\n",
    "        total_train = 0\n",
    "\n",
    "        for inputs, labels in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            correct_train += (predicted == labels).sum().item()\n",
    "            total_train += labels.size(0)\n",
    "\n",
    "        train_loss = running_loss / len(train_loader)\n",
    "        train_accuracy = correct_train / total_train\n",
    "\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        correct_val = 0\n",
    "        total_val = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                correct_val += (predicted == labels).sum().item()\n",
    "                total_val += labels.size(0)\n",
    "\n",
    "        val_loss /= len(val_loader)\n",
    "        val_accuracy = correct_val / total_val\n",
    "\n",
    "        print(f'Epoch {epoch+1}/{num_epochs}, Loss: {train_loss:.4f}, Accuracy: {train_accuracy:.4f}, Val Loss: {val_loss:.4f}, Val Accuracy: {val_accuracy:.4f}')\n",
    "\n",
    "        # Adjust learning rate based on validation loss\n",
    "        scheduler.step(val_loss)\n",
    "\n",
    "        # Early stopping\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            best_model = model.state_dict()\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= patience:\n",
    "                print(\"Early stopping\")\n",
    "                break\n",
    "\n",
    "    # Load the best model\n",
    "    model.load_state_dict(best_model)\n",
    "\n",
    "    # Evaluate the model on the test set\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        outputs = model(X_test_tensor)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        test_accuracy = accuracy_score(y_test_tensor.cpu(), predicted.cpu())\n",
    "        return test_accuracy\n",
    "\n",
    "# Train and evaluate the model for each byte and print the accuracy\n",
    "accuracies = []\n",
    "for byte_index in range(10):\n",
    "    print(f'\\nTraining for byte {byte_index}...')\n",
    "    accuracy = train_and_evaluate(X_train, y_train, X_val, y_val, X_test, y_test, byte_index)\n",
    "    accuracies.append(accuracy)\n",
    "    print(f'Accuracy for byte {byte_index}: {accuracy * 100:.2f}%')\n",
    "\n",
    "# Print all accuracies\n",
    "print(\"\\nAccuracies for all 10 bytes:\")\n",
    "for byte_index, accuracy in enumerate(accuracies):\n",
    "    print(f'Byte {byte_index}: {accuracy * 100:.2f}%')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97795dfa-fbe5-4daa-ad25-2757ad9955b7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Other models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5deb43b8-de48-4cdd-8c51-1f9b8d164072",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load the data from CSV\n",
    "data = pd.read_csv('keystream_records_val.csv')\n",
    "\n",
    "# Separate the input features (64-bit key) and the targets (10 bytes of keystream)\n",
    "X = data.iloc[:, :64].values  # First 64 columns are the 64-bit key\n",
    "y = data.iloc[:, 64:74].values   # Next 10 columns are the 10 bytes of the keystream\n",
    "\n",
    "# Convert the target to categorical (byte values range from 0 to 255)\n",
    "y = y.astype(np.uint8)\n",
    "\n",
    "# Split the data into training, validation, and testing sets (70-10-20 split)\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.67, random_state=42)  # 0.67 * 0.3 ≈ 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ce1632c-ef92-420c-97b7-e7e1ac395218",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to train and evaluate a Random Forest for a specific byte of the keystream\n",
    "def train_and_evaluate_rf(X_train, y_train, X_test, y_test, byte_index):\n",
    "    model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    model.fit(X_train, y_train[:, byte_index])\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test[:, byte_index], y_pred)\n",
    "    return accuracy\n",
    "\n",
    "# Train and evaluate the model for each byte and print the accuracy\n",
    "accuracies = []\n",
    "for byte_index in range(10):\n",
    "    accuracy = train_and_evaluate_rf(X_train, y_train, X_test, y_test, byte_index)\n",
    "    accuracies.append(accuracy)\n",
    "    print(f'Accuracy for byte {byte_index} with Random Forest: {accuracy * 100:.2f}%')\n",
    "\n",
    "# Print all accuracies\n",
    "print(\"\\nAccuracies for all 10 bytes with Random Forest:\")\n",
    "for byte_index, accuracy in enumerate(accuracies):\n",
    "    print(f'Byte {byte_index}: {accuracy * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e480ce1-048e-44b8-8fa0-81adf44b7ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# Function to train and evaluate a Gradient Boosting Machine for a specific byte of the keystream\n",
    "def train_and_evaluate_gbm(X_train, y_train, X_test, y_test, byte_index):\n",
    "    model = GradientBoostingClassifier(n_estimators=100, random_state=42)\n",
    "    model.fit(X_train, y_train[:, byte_index])\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test[:, byte_index], y_pred)\n",
    "    return accuracy\n",
    "\n",
    "# Train and evaluate the model for each byte and print the accuracy\n",
    "accuracies = []\n",
    "for byte_index in range(10):\n",
    "    accuracy = train_and_evaluate_gbm(X_train, y_train, X_test, y_test, byte_index)\n",
    "    accuracies.append(accuracy)\n",
    "    print(f'Accuracy for byte {byte_index} with GBM: {accuracy * 100:.2f}%')\n",
    "\n",
    "# Print all accuracies\n",
    "print(\"\\nAccuracies for all 10 bytes with GBM:\")\n",
    "for byte_index, accuracy in enumerate(accuracies):\n",
    "    print(f'Byte {byte_index}: {accuracy * 100:.2f}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "576062e8-83df-469b-a7d3-6fdee4ef8158",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for byte 0 with SVM: 0.42%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "# Function to train and evaluate an SVM for a specific byte of the keystream\n",
    "def train_and_evaluate_svm(X_train, y_train, X_test, y_test, byte_index):\n",
    "    model = SVC(kernel='linear', random_state=42)\n",
    "    model.fit(X_train, y_train[:, byte_index])\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test[:, byte_index], y_pred)\n",
    "    return accuracy\n",
    "\n",
    "# Train and evaluate the model for each byte and print the accuracy\n",
    "accuracies = []\n",
    "for byte_index in range(10):\n",
    "    accuracy = train_and_evaluate_svm(X_train, y_train, X_test, y_test, byte_index)\n",
    "    accuracies.append(accuracy)\n",
    "    print(f'Accuracy for byte {byte_index} with SVM: {accuracy * 100:.2f}%')\n",
    "\n",
    "# Print all accuracies\n",
    "print(\"\\nAccuracies for all 10 bytes with SVM:\")\n",
    "for byte_index, accuracy in enumerate(accuracies):\n",
    "    print(f'Byte {byte_index}: {accuracy * 100:.2f}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e11ad181-8331-4a1d-b784-40508c84754a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Function to train and evaluate a k-NN for a specific byte of the keystream\n",
    "def train_and_evaluate_knn(X_train, y_train, X_test, y_test, byte_index):\n",
    "    model = KNeighborsClassifier(n_neighbors=5)\n",
    "    model.fit(X_train, y_train[:, byte_index])\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test[:, byte_index], y_pred)\n",
    "    return accuracy\n",
    "\n",
    "# Train and evaluate the model for each byte and print the accuracy\n",
    "accuracies = []\n",
    "for byte_index in range(10):\n",
    "    accuracy = train_and_evaluate_knn(X_train, y_train, X_test, y_test, byte_index)\n",
    "    accuracies.append(accuracy)\n",
    "    print(f'Accuracy for byte {byte_index} with k-NN: {accuracy * 100:.2f}%')\n",
    "\n",
    "# Print all accuracies\n",
    "print(\"\\nAccuracies for all 10 bytes with k-NN:\")\n",
    "for byte_index, accuracy in enumerate(accuracies):\n",
    "    print(f'Byte {byte_index}: {accuracy * 100:.2f}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a4e1e9-a718-4ddd-b507-6d8233ba6994",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Function to train and evaluate a Logistic Regression model for a specific byte of the keystream\n",
    "def train_and_evaluate_logreg(X_train, y_train, X_test, y_test, byte_index):\n",
    "    model = LogisticRegression(max_iter=1000, random_state=42)\n",
    "    model.fit(X_train, y_train[:, byte_index])\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test[:, byte_index], y_pred)\n",
    "    return accuracy\n",
    "\n",
    "# Train and evaluate the model for each byte and print the accuracy\n",
    "accuracies = []\n",
    "for byte_index in range(10):\n",
    "    accuracy = train_and_evaluate_logreg(X_train, y_train, X_test, y_test, byte_index)\n",
    "    accuracies.append(accuracy)\n",
    "    print(f'Accuracy for byte {byte_index} with Logistic Regression: {accuracy * 100:.2f}%')\n",
    "\n",
    "# Print all accuracies\n",
    "print(\"\\nAccuracies for all 10 bytes with Logistic Regression:\")\n",
    "for byte_index, accuracy in enumerate(accuracies):\n",
    "    print(f'Byte {byte_index}: {accuracy * 100:.2f}%')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e56eff34-ac56-4d9c-8893-11e5cf0d8ced",
   "metadata": {},
   "source": [
    "## Trans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "91d10cae-ba4c-4046-abee-f395854e5262",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "201a7d56-e661-4852-85e0-88aae924cbbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data from CSV\n",
    "data = pd.read_csv('keystream_records_val.csv')\n",
    "\n",
    "# Separate the input features (64-bit key) and the targets (10 bytes of keystream)\n",
    "X = data.iloc[:, :64].values  # First 64 columns are the 64-bit key\n",
    "y = data.iloc[:, 64:74].values   # Next 10 columns are the 10 bytes of the keystream\n",
    "\n",
    "# Convert the target to categorical (byte values range from 0 to 255)\n",
    "y = y.astype(np.uint8)\n",
    "\n",
    "# Split the data into training, validation, and testing sets (70-10-20 split)\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.67, random_state=42)  # 0.67 * 0.3 ≈ 0.2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "efdc6f17-9660-4986-a811-e94356aec906",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kashi\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\transformer.py:282: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
     ]
    }
   ],
   "source": [
    "class SimpleTransformer(nn.Module):\n",
    "    def __init__(self, input_dim, model_dim, num_heads, num_layers, output_dim):\n",
    "        super(SimpleTransformer, self).__init__()\n",
    "        self.embedding = nn.Linear(input_dim, model_dim)\n",
    "        encoder_layer = nn.TransformerEncoderLayer(d_model=model_dim, nhead=num_heads)\n",
    "        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "        self.fc = nn.Linear(model_dim, output_dim)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        x = self.transformer_encoder(x)\n",
    "        x = x.mean(dim=1)  # Global average pooling\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "input_dim = 64\n",
    "model_dim = 128\n",
    "num_heads = 4\n",
    "num_layers = 2\n",
    "output_dim = 256  # For classification into 256 classes (byte values)\n",
    "\n",
    "model = SimpleTransformer(input_dim, model_dim, num_heads, num_layers, output_dim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7907ba3a-e10d-429e-967e-14af931239ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training for byte 0...\n",
      "Epoch 1/50, Loss: 5.5772, Accuracy: 0.0039, Val Loss: 5.5585, Val Accuracy: 0.0035\n",
      "Epoch 2/50, Loss: 5.5524, Accuracy: 0.0041, Val Loss: 5.5490, Val Accuracy: 0.0055\n",
      "Epoch 3/50, Loss: 5.5486, Accuracy: 0.0040, Val Loss: 5.5504, Val Accuracy: 0.0033\n",
      "Epoch 4/50, Loss: 5.5473, Accuracy: 0.0039, Val Loss: 5.5475, Val Accuracy: 0.0032\n",
      "Epoch 5/50, Loss: 5.5471, Accuracy: 0.0039, Val Loss: 5.5475, Val Accuracy: 0.0036\n",
      "Epoch 6/50, Loss: 5.5466, Accuracy: 0.0042, Val Loss: 5.5475, Val Accuracy: 0.0038\n",
      "Epoch 7/50, Loss: 5.5464, Accuracy: 0.0040, Val Loss: 5.5476, Val Accuracy: 0.0034\n",
      "Epoch 8/50, Loss: 5.5455, Accuracy: 0.0041, Val Loss: 5.5466, Val Accuracy: 0.0036\n",
      "Epoch 9/50, Loss: 5.5452, Accuracy: 0.0042, Val Loss: 5.5470, Val Accuracy: 0.0036\n",
      "Epoch 10/50, Loss: 5.5453, Accuracy: 0.0040, Val Loss: 5.5471, Val Accuracy: 0.0040\n",
      "Epoch 11/50, Loss: 5.5452, Accuracy: 0.0040, Val Loss: 5.5468, Val Accuracy: 0.0034\n",
      "Epoch 12/50, Loss: 5.5449, Accuracy: 0.0040, Val Loss: 5.5466, Val Accuracy: 0.0038\n",
      "Epoch 13/50, Loss: 5.5448, Accuracy: 0.0041, Val Loss: 5.5467, Val Accuracy: 0.0036\n",
      "Early stopping\n",
      "Accuracy for byte 0 with Transformer: 0.46%\n",
      "\n",
      "Training for byte 1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kashi\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\transformer.py:282: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50, Loss: 5.5780, Accuracy: 0.0039, Val Loss: 5.5545, Val Accuracy: 0.0036\n",
      "Epoch 2/50, Loss: 5.5522, Accuracy: 0.0039, Val Loss: 5.5486, Val Accuracy: 0.0041\n",
      "Epoch 3/50, Loss: 5.5485, Accuracy: 0.0041, Val Loss: 5.5480, Val Accuracy: 0.0045\n",
      "Epoch 4/50, Loss: 5.5473, Accuracy: 0.0041, Val Loss: 5.5473, Val Accuracy: 0.0039\n",
      "Epoch 5/50, Loss: 5.5468, Accuracy: 0.0043, Val Loss: 5.5475, Val Accuracy: 0.0038\n",
      "Epoch 6/50, Loss: 5.5464, Accuracy: 0.0044, Val Loss: 5.5480, Val Accuracy: 0.0040\n",
      "Epoch 7/50, Loss: 5.5462, Accuracy: 0.0041, Val Loss: 5.5471, Val Accuracy: 0.0040\n",
      "Epoch 8/50, Loss: 5.5453, Accuracy: 0.0045, Val Loss: 5.5473, Val Accuracy: 0.0040\n",
      "Epoch 9/50, Loss: 5.5452, Accuracy: 0.0043, Val Loss: 5.5473, Val Accuracy: 0.0039\n",
      "Epoch 10/50, Loss: 5.5450, Accuracy: 0.0044, Val Loss: 5.5472, Val Accuracy: 0.0040\n",
      "Epoch 11/50, Loss: 5.5447, Accuracy: 0.0045, Val Loss: 5.5474, Val Accuracy: 0.0040\n",
      "Epoch 12/50, Loss: 5.5447, Accuracy: 0.0044, Val Loss: 5.5470, Val Accuracy: 0.0032\n",
      "Epoch 13/50, Loss: 5.5446, Accuracy: 0.0044, Val Loss: 5.5470, Val Accuracy: 0.0039\n",
      "Epoch 14/50, Loss: 5.5444, Accuracy: 0.0044, Val Loss: 5.5469, Val Accuracy: 0.0032\n",
      "Epoch 15/50, Loss: 5.5443, Accuracy: 0.0041, Val Loss: 5.5469, Val Accuracy: 0.0032\n",
      "Epoch 16/50, Loss: 5.5443, Accuracy: 0.0041, Val Loss: 5.5470, Val Accuracy: 0.0032\n",
      "Epoch 17/50, Loss: 5.5443, Accuracy: 0.0044, Val Loss: 5.5469, Val Accuracy: 0.0032\n",
      "Epoch 18/50, Loss: 5.5442, Accuracy: 0.0041, Val Loss: 5.5470, Val Accuracy: 0.0032\n",
      "Epoch 19/50, Loss: 5.5442, Accuracy: 0.0042, Val Loss: 5.5470, Val Accuracy: 0.0032\n",
      "Epoch 20/50, Loss: 5.5440, Accuracy: 0.0044, Val Loss: 5.5470, Val Accuracy: 0.0032\n",
      "Early stopping\n",
      "Accuracy for byte 1 with Transformer: 0.36%\n",
      "\n",
      "Training for byte 2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kashi\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\transformer.py:282: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50, Loss: 5.5800, Accuracy: 0.0036, Val Loss: 5.5582, Val Accuracy: 0.0032\n",
      "Epoch 2/50, Loss: 5.5525, Accuracy: 0.0041, Val Loss: 5.5494, Val Accuracy: 0.0040\n",
      "Epoch 3/50, Loss: 5.5487, Accuracy: 0.0038, Val Loss: 5.5474, Val Accuracy: 0.0039\n",
      "Epoch 4/50, Loss: 5.5475, Accuracy: 0.0040, Val Loss: 5.5463, Val Accuracy: 0.0036\n",
      "Epoch 5/50, Loss: 5.5469, Accuracy: 0.0042, Val Loss: 5.5471, Val Accuracy: 0.0047\n",
      "Epoch 6/50, Loss: 5.5464, Accuracy: 0.0039, Val Loss: 5.5477, Val Accuracy: 0.0048\n",
      "Epoch 7/50, Loss: 5.5465, Accuracy: 0.0042, Val Loss: 5.5468, Val Accuracy: 0.0040\n",
      "Epoch 8/50, Loss: 5.5453, Accuracy: 0.0042, Val Loss: 5.5465, Val Accuracy: 0.0038\n",
      "Epoch 9/50, Loss: 5.5453, Accuracy: 0.0045, Val Loss: 5.5464, Val Accuracy: 0.0042\n",
      "Early stopping\n",
      "Accuracy for byte 2 with Transformer: 0.36%\n",
      "\n",
      "Training for byte 3...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kashi\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\transformer.py:282: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50, Loss: 5.5794, Accuracy: 0.0039, Val Loss: 5.5564, Val Accuracy: 0.0037\n",
      "Epoch 2/50, Loss: 5.5522, Accuracy: 0.0039, Val Loss: 5.5516, Val Accuracy: 0.0039\n",
      "Epoch 3/50, Loss: 5.5482, Accuracy: 0.0042, Val Loss: 5.5494, Val Accuracy: 0.0029\n",
      "Epoch 4/50, Loss: 5.5473, Accuracy: 0.0040, Val Loss: 5.5472, Val Accuracy: 0.0031\n",
      "Epoch 5/50, Loss: 5.5466, Accuracy: 0.0039, Val Loss: 5.5492, Val Accuracy: 0.0030\n",
      "Epoch 6/50, Loss: 5.5463, Accuracy: 0.0043, Val Loss: 5.5480, Val Accuracy: 0.0042\n",
      "Epoch 7/50, Loss: 5.5461, Accuracy: 0.0041, Val Loss: 5.5488, Val Accuracy: 0.0028\n",
      "Epoch 8/50, Loss: 5.5452, Accuracy: 0.0043, Val Loss: 5.5469, Val Accuracy: 0.0040\n",
      "Epoch 9/50, Loss: 5.5450, Accuracy: 0.0046, Val Loss: 5.5471, Val Accuracy: 0.0034\n",
      "Epoch 10/50, Loss: 5.5450, Accuracy: 0.0042, Val Loss: 5.5469, Val Accuracy: 0.0040\n",
      "Epoch 11/50, Loss: 5.5446, Accuracy: 0.0039, Val Loss: 5.5470, Val Accuracy: 0.0040\n",
      "Epoch 12/50, Loss: 5.5445, Accuracy: 0.0043, Val Loss: 5.5476, Val Accuracy: 0.0031\n",
      "Epoch 13/50, Loss: 5.5445, Accuracy: 0.0042, Val Loss: 5.5472, Val Accuracy: 0.0031\n",
      "Epoch 14/50, Loss: 5.5444, Accuracy: 0.0045, Val Loss: 5.5471, Val Accuracy: 0.0040\n",
      "Epoch 15/50, Loss: 5.5443, Accuracy: 0.0044, Val Loss: 5.5470, Val Accuracy: 0.0040\n",
      "Early stopping\n",
      "Accuracy for byte 3 with Transformer: 0.39%\n",
      "\n",
      "Training for byte 4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kashi\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\transformer.py:282: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50, Loss: 5.5774, Accuracy: 0.0041, Val Loss: 5.5549, Val Accuracy: 0.0042\n",
      "Epoch 2/50, Loss: 5.5517, Accuracy: 0.0040, Val Loss: 5.5485, Val Accuracy: 0.0034\n",
      "Epoch 3/50, Loss: 5.5485, Accuracy: 0.0042, Val Loss: 5.5482, Val Accuracy: 0.0042\n",
      "Epoch 4/50, Loss: 5.5476, Accuracy: 0.0043, Val Loss: 5.5480, Val Accuracy: 0.0040\n",
      "Epoch 5/50, Loss: 5.5471, Accuracy: 0.0040, Val Loss: 5.5470, Val Accuracy: 0.0040\n",
      "Epoch 6/50, Loss: 5.5467, Accuracy: 0.0038, Val Loss: 5.5466, Val Accuracy: 0.0041\n",
      "Epoch 7/50, Loss: 5.5461, Accuracy: 0.0039, Val Loss: 5.5477, Val Accuracy: 0.0042\n",
      "Epoch 8/50, Loss: 5.5460, Accuracy: 0.0042, Val Loss: 5.5468, Val Accuracy: 0.0033\n",
      "Epoch 9/50, Loss: 5.5453, Accuracy: 0.0041, Val Loss: 5.5461, Val Accuracy: 0.0037\n",
      "Epoch 10/50, Loss: 5.5452, Accuracy: 0.0044, Val Loss: 5.5469, Val Accuracy: 0.0033\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 87\u001b[0m\n\u001b[0;32m     85\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m byte_index \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m10\u001b[39m):\n\u001b[0;32m     86\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mTraining for byte \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbyte_index\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m...\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 87\u001b[0m     accuracy \u001b[38;5;241m=\u001b[39m train_and_evaluate_transformer(X_train, y_train, X_test, y_test, byte_index)\n\u001b[0;32m     88\u001b[0m     accuracies\u001b[38;5;241m.\u001b[39mappend(accuracy)\n\u001b[0;32m     89\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAccuracy for byte \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbyte_index\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m with Transformer: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maccuracy\u001b[38;5;250m \u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m100\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[1;32mIn[4], line 32\u001b[0m, in \u001b[0;36mtrain_and_evaluate_transformer\u001b[1;34m(X_train, y_train, X_test, y_test, byte_index)\u001b[0m\n\u001b[0;32m     30\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(inputs\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m))  \u001b[38;5;66;03m# Add a dummy dimension for sequence\u001b[39;00m\n\u001b[0;32m     31\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels)\n\u001b[1;32m---> 32\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m     33\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m     34\u001b[0m running_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\_tensor.py:492\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    482\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    483\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    484\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    485\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    490\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    491\u001b[0m     )\n\u001b[1;32m--> 492\u001b[0m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mbackward(\n\u001b[0;32m    493\u001b[0m     \u001b[38;5;28mself\u001b[39m, gradient, retain_graph, create_graph, inputs\u001b[38;5;241m=\u001b[39minputs\n\u001b[0;32m    494\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\autograd\\__init__.py:251\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    246\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    248\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    250\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 251\u001b[0m Variable\u001b[38;5;241m.\u001b[39m_execution_engine\u001b[38;5;241m.\u001b[39mrun_backward(  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    252\u001b[0m     tensors,\n\u001b[0;32m    253\u001b[0m     grad_tensors_,\n\u001b[0;32m    254\u001b[0m     retain_graph,\n\u001b[0;32m    255\u001b[0m     create_graph,\n\u001b[0;32m    256\u001b[0m     inputs,\n\u001b[0;32m    257\u001b[0m     allow_unreachable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    258\u001b[0m     accumulate_grad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    259\u001b[0m )\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Function to train and evaluate the Transformer model for a specific byte of the keystream\n",
    "def train_and_evaluate_transformer(X_train, y_train, X_test, y_test, byte_index):\n",
    "    model = SimpleTransformer(input_dim, model_dim, num_heads, num_layers, output_dim)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=2, factor=0.5)\n",
    "    \n",
    "    y_train_tensor = torch.tensor(y_train[:, byte_index], dtype=torch.long)\n",
    "    y_test_tensor = torch.tensor(y_test[:, byte_index], dtype=torch.long)\n",
    "    \n",
    "    train_dataset = torch.utils.data.TensorDataset(torch.tensor(X_train, dtype=torch.float32), y_train_tensor)\n",
    "    val_dataset = torch.utils.data.TensorDataset(torch.tensor(X_val, dtype=torch.float32), torch.tensor(y_val[:, byte_index], dtype=torch.long))\n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "    val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=64, shuffle=False)\n",
    "    \n",
    "    patience = 5\n",
    "    best_val_loss = float('inf')\n",
    "    best_model = None\n",
    "    patience_counter = 0\n",
    "\n",
    "    num_epochs = 50\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct_train = 0\n",
    "        total_train = 0\n",
    "\n",
    "        for inputs, labels in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs.unsqueeze(1))  # Add a dummy dimension for sequence\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            correct_train += (predicted == labels).sum().item()\n",
    "            total_train += labels.size(0)\n",
    "\n",
    "        train_loss = running_loss / len(train_loader)\n",
    "        train_accuracy = correct_train / total_train\n",
    "\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        correct_val = 0\n",
    "        total_val = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                outputs = model(inputs.unsqueeze(1))  # Add a dummy dimension for sequence\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                correct_val += (predicted == labels).sum().item()\n",
    "                total_val += labels.size(0)\n",
    "\n",
    "        val_loss /= len(val_loader)\n",
    "        val_accuracy = correct_val / total_val\n",
    "\n",
    "        print(f'Epoch {epoch+1}/{num_epochs}, Loss: {train_loss:.4f}, Accuracy: {train_accuracy:.4f}, Val Loss: {val_loss:.4f}, Val Accuracy: {val_accuracy:.4f}')\n",
    "\n",
    "        scheduler.step(val_loss)\n",
    "\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            best_model = model.state_dict()\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= patience:\n",
    "                print(\"Early stopping\")\n",
    "                break\n",
    "\n",
    "    model.load_state_dict(best_model)\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        outputs = model(torch.tensor(X_test, dtype=torch.float32).unsqueeze(1))  # Add a dummy dimension for sequence\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        test_accuracy = accuracy_score(y_test[:, byte_index], predicted.numpy())\n",
    "        return test_accuracy\n",
    "\n",
    "accuracies = []\n",
    "for byte_index in range(10):\n",
    "    print(f'\\nTraining for byte {byte_index}...')\n",
    "    accuracy = train_and_evaluate_transformer(X_train, y_train, X_test, y_test, byte_index)\n",
    "    accuracies.append(accuracy)\n",
    "    print(f'Accuracy for byte {byte_index} with Transformer: {accuracy * 100:.2f}%')\n",
    "\n",
    "print(\"\\nAccuracies for all 10 bytes with Transformer:\")\n",
    "for byte_index, accuracy in enumerate(accuracies):\n",
    "    print(f'Byte {byte_index}: {accuracy * 100:.2f}%')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "proenv",
   "language": "python",
   "name": "proenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
