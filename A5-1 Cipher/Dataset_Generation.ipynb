{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# C-code to Python code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "key: 0x 1223456789ABCDEF\n",
      "frame number: 0x000134\n",
      "known good output:\n",
      " A->B: 0x 534EAA582FE8151AB6E1855A728C00\n",
      "  B->A: 0x 24FD35A35D5FB6526D32F906DF1AC0\n",
      "observed output:\n",
      " A->B: 0x 534EAA582FE8151AB6E1855A728C00\n",
      "  B->A: 0x 24FD35A35D5FB6526D32F906DF1AC0\n",
      "Self-check succeeded: everything looks ok.\n"
     ]
    }
   ],
   "source": [
    "class A5_1:\n",
    "    R1MASK = 0x07FFFF  # 19 bits, numbered 0..18\n",
    "    R2MASK = 0x3FFFFF  # 22 bits, numbered 0..21\n",
    "    R3MASK = 0x7FFFFF  # 23 bits, numbered 0..22\n",
    "\n",
    "    R1MID = 0x000100  # bit 8\n",
    "    R2MID = 0x000400  # bit 10\n",
    "    R3MID = 0x000400  # bit 10\n",
    "\n",
    "    R1TAPS = 0x072000  # bits 18,17,16,13\n",
    "    R2TAPS = 0x300000  # bits 21,20\n",
    "    R3TAPS = 0x700080  # bits 22,21,20,7\n",
    "\n",
    "    R1OUT = 0x040000  # bit 18 (the high bit)\n",
    "    R2OUT = 0x200000  # bit 21 (the high bit)\n",
    "    R3OUT = 0x400000  # bit 22 (the high bit)\n",
    "\n",
    "    def __init__(self):\n",
    "        self.R1 = 0\n",
    "        self.R2 = 0\n",
    "        self.R3 = 0\n",
    "\n",
    "    def parity(self, x):\n",
    "        x ^= x >> 16\n",
    "        x ^= x >> 8\n",
    "        x ^= x >> 4\n",
    "        x ^= x >> 2\n",
    "        x ^= x >> 1\n",
    "        return x & 1\n",
    "\n",
    "    def clockone(self, reg, mask, taps):\n",
    "        t = reg & taps\n",
    "        reg = (reg << 1) & mask\n",
    "        reg |= self.parity(t)\n",
    "        return reg\n",
    "\n",
    "    def majority(self):\n",
    "        sum = self.parity(self.R1 & self.R1MID) + self.parity(self.R2 & self.R2MID) + self.parity(self.R3 & self.R3MID)\n",
    "        return 1 if sum >= 2 else 0\n",
    "\n",
    "    def clock(self):\n",
    "        maj = self.majority()\n",
    "        if ((self.R1 & self.R1MID) != 0) == maj:\n",
    "            self.R1 = self.clockone(self.R1, self.R1MASK, self.R1TAPS)\n",
    "        if ((self.R2 & self.R2MID) != 0) == maj:\n",
    "            self.R2 = self.clockone(self.R2, self.R2MASK, self.R2TAPS)\n",
    "        if ((self.R3 & self.R3MID) != 0) == maj:\n",
    "            self.R3 = self.clockone(self.R3, self.R3MASK, self.R3TAPS)\n",
    "\n",
    "    def clockallthree(self):\n",
    "        self.R1 = self.clockone(self.R1, self.R1MASK, self.R1TAPS)\n",
    "        self.R2 = self.clockone(self.R2, self.R2MASK, self.R2TAPS)\n",
    "        self.R3 = self.clockone(self.R3, self.R3MASK, self.R3TAPS)\n",
    "\n",
    "    def getbit(self):\n",
    "        return self.parity(self.R1 & self.R1OUT) ^ self.parity(self.R2 & self.R2OUT) ^ self.parity(self.R3 & self.R3OUT)\n",
    "\n",
    "    def keysetup(self, key, frame):\n",
    "        self.R1 = self.R2 = self.R3 = 0\n",
    "\n",
    "        for i in range(64):\n",
    "            self.clockallthree()\n",
    "            keybit = (key[i // 8] >> (i & 7)) & 1\n",
    "            self.R1 ^= keybit\n",
    "            self.R2 ^= keybit\n",
    "            self.R3 ^= keybit\n",
    "\n",
    "        for i in range(22):\n",
    "            self.clockallthree()\n",
    "            framebit = (frame >> i) & 1\n",
    "            self.R1 ^= framebit\n",
    "            self.R2 ^= framebit\n",
    "            self.R3 ^= framebit\n",
    "\n",
    "        for _ in range(100):\n",
    "            self.clock()\n",
    "\n",
    "    def run(self):\n",
    "        AtoBkeystream = [0] * 15\n",
    "        BtoAkeystream = [0] * 15\n",
    "\n",
    "        for i in range(114):\n",
    "            self.clock()\n",
    "            AtoBkeystream[i // 8] |= self.getbit() << (7 - (i & 7))\n",
    "\n",
    "        for i in range(114):\n",
    "            self.clock()\n",
    "            BtoAkeystream[i // 8] |= self.getbit() << (7 - (i & 7))\n",
    "\n",
    "        return AtoBkeystream, BtoAkeystream\n",
    "\n",
    "def test():\n",
    "    key = [0x12, 0x23, 0x45, 0x67, 0x89, 0xAB, 0xCD, 0xEF]\n",
    "    frame = 0x134\n",
    "    goodAtoB = [0x53, 0x4E, 0xAA, 0x58, 0x2F, 0xE8, 0x15, 0x1A, 0xB6, 0xE1, 0x85, 0x5A, 0x72, 0x8C, 0x00]\n",
    "    goodBtoA = [0x24, 0xFD, 0x35, 0xA3, 0x5D, 0x5F, 0xB6, 0x52, 0x6D, 0x32, 0xF9, 0x06, 0xDF, 0x1A, 0xC0]\n",
    "\n",
    "    a5_1 = A5_1()\n",
    "    a5_1.keysetup(key, frame)\n",
    "    AtoB, BtoA = a5_1.run()\n",
    "\n",
    "    print(\"key: 0x\", ''.join(f\"{b:02X}\" for b in key))\n",
    "    print(\"frame number: 0x%06X\" % frame)\n",
    "    print(\"known good output:\")\n",
    "    print(\" A->B: 0x\", ''.join(f\"{b:02X}\" for b in goodAtoB))\n",
    "    print(\"  B->A: 0x\", ''.join(f\"{b:02X}\" for b in goodBtoA))\n",
    "    print(\"observed output:\")\n",
    "    print(\" A->B: 0x\", ''.join(f\"{b:02X}\" for b in AtoB))\n",
    "    print(\"  B->A: 0x\", ''.join(f\"{b:02X}\" for b in BtoA))\n",
    "\n",
    "    if AtoB == goodAtoB and BtoA == goodBtoA:\n",
    "        print(\"Self-check succeeded: everything looks ok.\")\n",
    "    else:\n",
    "        print(\"Self-check failed: output does not match the known-good test vector.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    test()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Modified Code for generating 10 byte Keystream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "key: 0x 1223456789ABCDEF\n",
      "frame number: 0x000134\n",
      "known good output:\n",
      " keystream: 0x 534EAA582FE8151AB6E1\n",
      "observed output:\n",
      " keystream: 0x 534EAA582FE8151AB6E1\n",
      "Self-check succeeded: everything looks ok.\n"
     ]
    }
   ],
   "source": [
    "class A5_1:\n",
    "    R1MASK = 0x07FFFF  # 19 bits, numbered 0..18\n",
    "    R2MASK = 0x3FFFFF  # 22 bits, numbered 0..21\n",
    "    R3MASK = 0x7FFFFF  # 23 bits, numbered 0..22\n",
    "\n",
    "    R1MID = 0x000100  # bit 8\n",
    "    R2MID = 0x000400  # bit 10\n",
    "    R3MID = 0x000400  # bit 10\n",
    "\n",
    "    R1TAPS = 0x072000  # bits 18,17,16,13\n",
    "    R2TAPS = 0x300000  # bits 21,20\n",
    "    R3TAPS = 0x700080  # bits 22,21,20,7\n",
    "\n",
    "    R1OUT = 0x040000  # bit 18 (the high bit)\n",
    "    R2OUT = 0x200000  # bit 21 (the high bit)\n",
    "    R3OUT = 0x400000  # bit 22 (the high bit)\n",
    "\n",
    "    def __init__(self):\n",
    "        self.R1 = 0\n",
    "        self.R2 = 0\n",
    "        self.R3 = 0\n",
    "\n",
    "    def parity(self, x):\n",
    "        x ^= x >> 16\n",
    "        x ^= x >> 8\n",
    "        x ^= x >> 4\n",
    "        x ^= x >> 2\n",
    "        x ^= x >> 1\n",
    "        return x & 1\n",
    "\n",
    "    def clockone(self, reg, mask, taps):\n",
    "        t = reg & taps\n",
    "        reg = (reg << 1) & mask\n",
    "        reg |= self.parity(t)\n",
    "        return reg\n",
    "\n",
    "    def majority(self):\n",
    "        sum = self.parity(self.R1 & self.R1MID) + self.parity(self.R2 & self.R2MID) + self.parity(self.R3 & self.R3MID)\n",
    "        return 1 if sum >= 2 else 0\n",
    "\n",
    "    def clock(self):\n",
    "        maj = self.majority()\n",
    "        if ((self.R1 & self.R1MID) != 0) == maj:\n",
    "            self.R1 = self.clockone(self.R1, self.R1MASK, self.R1TAPS)\n",
    "        if ((self.R2 & self.R2MID) != 0) == maj:\n",
    "            self.R2 = self.clockone(self.R2, self.R2MASK, self.R2TAPS)\n",
    "        if ((self.R3 & self.R3MID) != 0) == maj:\n",
    "            self.R3 = self.clockone(self.R3, self.R3MASK, self.R3TAPS)\n",
    "\n",
    "    def clockallthree(self):\n",
    "        self.R1 = self.clockone(self.R1, self.R1MASK, self.R1TAPS)\n",
    "        self.R2 = self.clockone(self.R2, self.R2MASK, self.R2TAPS)\n",
    "        self.R3 = self.clockone(self.R3, self.R3MASK, self.R3TAPS)\n",
    "\n",
    "    def getbit(self):\n",
    "        return self.parity(self.R1 & self.R1OUT) ^ self.parity(self.R2 & self.R2OUT) ^ self.parity(self.R3 & self.R3OUT)\n",
    "\n",
    "    def keysetup(self, key, frame):\n",
    "        self.R1 = self.R2 = self.R3 = 0\n",
    "\n",
    "        for i in range(64):\n",
    "            self.clockallthree()\n",
    "            keybit = (key[i // 8] >> (i & 7)) & 1\n",
    "            self.R1 ^= keybit\n",
    "            self.R2 ^= keybit\n",
    "            self.R3 ^= keybit\n",
    "\n",
    "        for i in range(22):\n",
    "            self.clockallthree()\n",
    "            framebit = (frame >> i) & 1\n",
    "            self.R1 ^= framebit\n",
    "            self.R2 ^= framebit\n",
    "            self.R3 ^= framebit\n",
    "\n",
    "        for _ in range(100):\n",
    "            self.clock()\n",
    "\n",
    "    def generate_keystream(self, length):\n",
    "        keystream = [0] * length\n",
    "\n",
    "        for i in range(length * 8):\n",
    "            self.clock()\n",
    "            keystream[i // 8] |= self.getbit() << (7 - (i & 7))\n",
    "\n",
    "        return keystream\n",
    "\n",
    "def test():\n",
    "    key = [0x12, 0x23, 0x45, 0x67, 0x89, 0xAB, 0xCD, 0xEF]\n",
    "    frame = 0x134\n",
    "    good_keystream = [0x53, 0x4E, 0xAA, 0x58, 0x2F, 0xE8, 0x15, 0x1A, 0xB6, 0xE1]  # First 10 bytes of A->B keystream\n",
    "\n",
    "    a5_1 = A5_1()\n",
    "    a5_1.keysetup(key, frame)\n",
    "    keystream = a5_1.generate_keystream(10)\n",
    "\n",
    "    print(\"key: 0x\", ''.join(f\"{b:02X}\" for b in key))\n",
    "    print(\"frame number: 0x%06X\" % frame)\n",
    "    print(\"known good output:\")\n",
    "    print(\" keystream: 0x\", ''.join(f\"{b:02X}\" for b in good_keystream))\n",
    "    print(\"observed output:\")\n",
    "    print(\" keystream: 0x\", ''.join(f\"{b:02X}\" for b in keystream))\n",
    "\n",
    "    if keystream == good_keystream:\n",
    "        print(\"Self-check succeeded: everything looks ok.\")\n",
    "    else:\n",
    "        print(\"Self-check failed: output does not match the known-good test vector.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    test()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code for generating CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import random\n",
    "\n",
    "class A5_1:\n",
    "    R1MASK = 0x07FFFF  # 19 bits, numbered 0..18\n",
    "    R2MASK = 0x3FFFFF  # 22 bits, numbered 0..21\n",
    "    R3MASK = 0x7FFFFF  # 23 bits, numbered 0..22\n",
    "\n",
    "    R1MID = 0x000100  # bit 8\n",
    "    R2MID = 0x000400  # bit 10\n",
    "    R3MID = 0x000400  # bit 10\n",
    "\n",
    "    R1TAPS = 0x072000  # bits 18,17,16,13\n",
    "    R2TAPS = 0x300000  # bits 21,20\n",
    "    R3TAPS = 0x700080  # bits 22,21,20,7\n",
    "\n",
    "    R1OUT = 0x040000  # bit 18 (the high bit)\n",
    "    R2OUT = 0x200000  # bit 21 (the high bit)\n",
    "    R3OUT = 0x400000  # bit 22 (the high bit)\n",
    "\n",
    "    def __init__(self):\n",
    "        self.R1 = 0\n",
    "        self.R2 = 0\n",
    "        self.R3 = 0\n",
    "\n",
    "    def parity(self, x):\n",
    "        x ^= x >> 16\n",
    "        x ^= x >> 8\n",
    "        x ^= x >> 4\n",
    "        x ^= x >> 2\n",
    "        x ^= x >> 1\n",
    "        return x & 1\n",
    "\n",
    "    def clockone(self, reg, mask, taps):\n",
    "        t = reg & taps\n",
    "        reg = (reg << 1) & mask\n",
    "        reg |= self.parity(t)\n",
    "        return reg\n",
    "\n",
    "    def majority(self):\n",
    "        sum = self.parity(self.R1 & self.R1MID) + self.parity(self.R2 & self.R2MID) + self.parity(self.R3 & self.R3MID)\n",
    "        return 1 if sum >= 2 else 0\n",
    "\n",
    "    def clock(self):\n",
    "        maj = self.majority()\n",
    "        if ((self.R1 & self.R1MID) != 0) == maj:\n",
    "            self.R1 = self.clockone(self.R1, self.R1MASK, self.R1TAPS)\n",
    "        if ((self.R2 & self.R2MID) != 0) == maj:\n",
    "            self.R2 = self.clockone(self.R2, self.R2MASK, self.R2TAPS)\n",
    "        if ((self.R3 & self.R3MID) != 0) == maj:\n",
    "            self.R3 = self.clockone(self.R3, self.R3MASK, self.R3TAPS)\n",
    "\n",
    "    def clockallthree(self):\n",
    "        self.R1 = self.clockone(self.R1, self.R1MASK, self.R1TAPS)\n",
    "        self.R2 = self.clockone(self.R2, self.R2MASK, self.R2TAPS)\n",
    "        self.R3 = self.clockone(self.R3, self.R3MASK, self.R3TAPS)\n",
    "\n",
    "    def getbit(self):\n",
    "        return self.parity(self.R1 & self.R1OUT) ^ self.parity(self.R2 & self.R2OUT) ^ self.parity(self.R3 & self.R3OUT)\n",
    "\n",
    "    def keysetup(self, key, frame):\n",
    "        self.R1 = self.R2 = self.R3 = 0\n",
    "\n",
    "        for i in range(64):\n",
    "            self.clockallthree()\n",
    "            keybit = (key[i // 8] >> (i & 7)) & 1\n",
    "            self.R1 ^= keybit\n",
    "            self.R2 ^= keybit\n",
    "            self.R3 ^= keybit\n",
    "\n",
    "        for i in range(22):\n",
    "            self.clockallthree()\n",
    "            framebit = (frame >> i) & 1\n",
    "            self.R1 ^= framebit\n",
    "            self.R2 ^= framebit\n",
    "            self.R3 ^= framebit\n",
    "\n",
    "        for _ in range(100):\n",
    "            self.clock()\n",
    "\n",
    "    def generate_keystream(self, length):\n",
    "        keystream = [0] * length\n",
    "\n",
    "        for i in range(length * 8):\n",
    "            self.clock()\n",
    "            keystream[i // 8] |= self.getbit() << (7 - (i & 7))\n",
    "\n",
    "        return keystream\n",
    "def generate_random_key():\n",
    "    return [random.randint(0, 255) for _ in range(8)]\n",
    "    \n",
    "def convert_key_to_bits(key):\n",
    "    key_bits = []\n",
    "    for byte in key:\n",
    "        for bit in range(8):\n",
    "            key_bits.append((byte >> bit) & 1)\n",
    "    return key_bits\n",
    "\n",
    "def generate_records(filename, num_records):\n",
    "    frame = 0x134  # Using a fixed frame number for simplicity\n",
    "\n",
    "    with open(filename, 'w', newline='') as csvfile:\n",
    "        csvwriter = csv.writer(csvfile)\n",
    "        headers = [f'key_bit_{i}' for i in range(64)] + [f'keystream_byte_{i}' for i in range(10)]\n",
    "        csvwriter.writerow(headers)\n",
    "\n",
    "        for _ in range(num_records):\n",
    "            key = generate_random_key()\n",
    "            key_bits = convert_key_to_bits(key)\n",
    "\n",
    "            # Setup the cipher\n",
    "            a5_1 = A5_1()\n",
    "            a5_1.keysetup(key, frame)\n",
    "            \n",
    "            # Generate 10 bytes of keystream\n",
    "            keystream = a5_1.generate_keystream(10)\n",
    "            \n",
    "            \n",
    "            # Create the record and write it to the CSV\n",
    "            record = key_bits + keystream\n",
    "            csvwriter.writerow(record)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    generate_records('keystream_records_10lakh.csv', 1500000)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Initial key is BYTE instead of bits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import random\n",
    "\n",
    "class A5_1:\n",
    "    R1MASK = 0x07FFFF  # 19 bits, numbered 0..18\n",
    "    R2MASK = 0x3FFFFF  # 22 bits, numbered 0..21\n",
    "    R3MASK = 0x7FFFFF  # 23 bits, numbered 0..22\n",
    "\n",
    "    R1MID = 0x000100  # bit 8\n",
    "    R2MID = 0x000400  # bit 10\n",
    "    R3MID = 0x000400  # bit 10\n",
    "\n",
    "    R1TAPS = 0x072000  # bits 18,17,16,13\n",
    "    R2TAPS = 0x300000  # bits 21,20\n",
    "    R3TAPS = 0x700080  # bits 22,21,20,7\n",
    "\n",
    "    R1OUT = 0x040000  # bit 18 (the high bit)\n",
    "    R2OUT = 0x200000  # bit 21 (the high bit)\n",
    "    R3OUT = 0x400000  # bit 22 (the high bit)\n",
    "\n",
    "    def __init__(self):\n",
    "        self.R1 = 0\n",
    "        self.R2 = 0\n",
    "        self.R3 = 0\n",
    "\n",
    "    def parity(self, x):\n",
    "        x ^= x >> 16\n",
    "        x ^= x >> 8\n",
    "        x ^= x >> 4\n",
    "        x ^= x >> 2\n",
    "        x ^= x >> 1\n",
    "        return x & 1\n",
    "\n",
    "    def clockone(self, reg, mask, taps):\n",
    "        t = reg & taps\n",
    "        reg = (reg << 1) & mask\n",
    "        reg |= self.parity(t)\n",
    "        return reg\n",
    "\n",
    "    def majority(self):\n",
    "        sum = self.parity(self.R1 & self.R1MID) + self.parity(self.R2 & self.R2MID) + self.parity(self.R3 & self.R3MID)\n",
    "        return 1 if sum >= 2 else 0\n",
    "\n",
    "    def clock(self):\n",
    "        maj = self.majority()\n",
    "        if ((self.R1 & self.R1MID) != 0) == maj:\n",
    "            self.R1 = self.clockone(self.R1, self.R1MASK, self.R1TAPS)\n",
    "        if ((self.R2 & self.R2MID) != 0) == maj:\n",
    "            self.R2 = self.clockone(self.R2, self.R2MASK, self.R2TAPS)\n",
    "        if ((self.R3 & self.R3MID) != 0) == maj:\n",
    "            self.R3 = self.clockone(self.R3, self.R3MASK, self.R3TAPS)\n",
    "\n",
    "    def clockallthree(self):\n",
    "        self.R1 = self.clockone(self.R1, self.R1MASK, self.R1TAPS)\n",
    "        self.R2 = self.clockone(self.R2, self.R2MASK, self.R2TAPS)\n",
    "        self.R3 = self.clockone(self.R3, self.R3MASK, self.R3TAPS)\n",
    "\n",
    "    def getbit(self):\n",
    "        return self.parity(self.R1 & self.R1OUT) ^ self.parity(self.R2 & self.R2OUT) ^ self.parity(self.R3 & self.R3OUT)\n",
    "\n",
    "    def keysetup(self, key, frame):\n",
    "        self.R1 = self.R2 = self.R3 = 0\n",
    "\n",
    "        for i in range(64):\n",
    "            self.clockallthree()\n",
    "            keybit = (key[i // 8] >> (i & 7)) & 1\n",
    "            self.R1 ^= keybit\n",
    "            self.R2 ^= keybit\n",
    "            self.R3 ^= keybit\n",
    "\n",
    "        for i in range(22):\n",
    "            self.clockallthree()\n",
    "            framebit = (frame >> i) & 1\n",
    "            self.R1 ^= framebit\n",
    "            self.R2 ^= framebit\n",
    "            self.R3 ^= framebit\n",
    "\n",
    "        for _ in range(100):\n",
    "            self.clock()\n",
    "\n",
    "    def generate_keystream(self, length):\n",
    "        keystream = [0] * length\n",
    "\n",
    "        for i in range(length * 8):\n",
    "            self.clock()\n",
    "            keystream[i // 8] |= self.getbit() << (7 - (i & 7))\n",
    "\n",
    "        return keystream\n",
    "def generate_random_key():\n",
    "    return [random.randint(0, 255) for _ in range(8)]\n",
    "    \n",
    "def convert_key_to_bits(key):\n",
    "    key_bits = []\n",
    "    for byte in key:\n",
    "        for bit in range(8):\n",
    "            key_bits.append((byte >> bit) & 1)\n",
    "    return key_bits\n",
    "\n",
    "def generate_records(filename, num_records):\n",
    "    frame = 0x134  # Using a fixed frame number for simplicity\n",
    "\n",
    "    with open(filename, 'w', newline='') as csvfile:\n",
    "        csvwriter = csv.writer(csvfile)\n",
    "        headers = [f'key_byte_{i}' for i in range(8)] + [f'keystream_byte_{i}' for i in range(10)]\n",
    "        csvwriter.writerow(headers)\n",
    "\n",
    "        for _ in range(num_records):\n",
    "            key = generate_random_key()\n",
    "\n",
    "            # Setup the cipher\n",
    "            a5_1 = A5_1()\n",
    "            a5_1.keysetup(key, frame)\n",
    "            \n",
    "            # Generate 10 bytes of keystream\n",
    "            keystream = a5_1.generate_keystream(10)\n",
    "            \n",
    "            # Create the record and write it to the CSV\n",
    "            record = key + keystream\n",
    "            csvwriter.writerow(record)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    generate_records('keystream_records_4lakh.csv',400000)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Testing a model on 0th byte of keystream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data from CSV\n",
    "data = pd.read_csv('keystream_records.csv')\n",
    "\n",
    "# Separate the input features (64-bit key) and the target (0th byte of keystream)\n",
    "X = data.iloc[:, :64].values  # First 64 columns are the 64-bit key\n",
    "y = data.iloc[:, 64].values   # 65th column is the 0th byte of the keystream\n",
    "\n",
    "# Convert the target to categorical (byte values range from 0 to 255)\n",
    "y = y.astype(np.uint8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets (80-20 split)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KeystreamClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(KeystreamClassifier, self).__init__()\n",
    "        self.fc1 = nn.Linear(64, 128)\n",
    "        self.fc2 = nn.Linear(128, 256)\n",
    "        self.fc3 = nn.Linear(256, 256)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "# Initialize the model, loss function, and optimizer\n",
    "model = KeystreamClassifier()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert data to PyTorch tensors\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.long)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.long)\n",
    "\n",
    "# Create data loaders\n",
    "train_dataset = torch.utils.data.TensorDataset(X_train_tensor, y_train_tensor)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20, Loss: 5.546680651473999\n",
      "Epoch 2/20, Loss: 5.5437264659881595\n",
      "Epoch 3/20, Loss: 5.536945764160156\n",
      "Epoch 4/20, Loss: 5.517007850265503\n",
      "Epoch 5/20, Loss: 5.479582009506226\n",
      "Epoch 6/20, Loss: 5.4277951171875\n",
      "Epoch 7/20, Loss: 5.365756849288941\n",
      "Epoch 8/20, Loss: 5.298566541671753\n",
      "Epoch 9/20, Loss: 5.23156375579834\n",
      "Epoch 10/20, Loss: 5.167142416763306\n",
      "Epoch 11/20, Loss: 5.10946356048584\n",
      "Epoch 12/20, Loss: 5.05725241394043\n",
      "Epoch 13/20, Loss: 5.010503924942016\n",
      "Epoch 14/20, Loss: 4.9690794734954835\n",
      "Epoch 15/20, Loss: 4.931884042358399\n",
      "Epoch 16/20, Loss: 4.8995677173614505\n",
      "Epoch 17/20, Loss: 4.870518451690674\n",
      "Epoch 18/20, Loss: 4.842836697006225\n",
      "Epoch 19/20, Loss: 4.819706113052368\n",
      "Epoch 20/20, Loss: 4.797079890060425\n"
     ]
    }
   ],
   "source": [
    "# Training the model\n",
    "num_epochs = 20\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for inputs, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    print(f'Epoch {epoch+1}/{num_epochs}, Loss: {running_loss/len(train_loader)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.43%\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    outputs = model(X_test_tensor)\n",
    "    _, predicted = torch.max(outputs, 1)\n",
    "    accuracy = accuracy_score(y_test, predicted.numpy())\n",
    "    print(f'Accuracy: {accuracy * 100:.2f}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n",
      "2.10.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "\n",
    "\n",
    "print(tf.__version__)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv1D, BatchNormalization, Flatten, Dense\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import tensorflow as tf\n",
    "\n",
    "# Load the data from CSV\n",
    "data = pd.read_csv('keystream_records_10lakh.csv')\n",
    "\n",
    "# Separate the input features (64-bit key) and the targets (10 bytes of keystream)\n",
    "X = data.iloc[:, :64].values  # First 64 columns are the 64-bit key\n",
    "y = data.iloc[:, 64:74].values  # Next 10 columns are the 10 bytes of the keystream\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Reshape X to be (num_samples, 64, 1) for Conv1D\n",
    "X_train_reshaped = X_train.reshape(-1, 64, 1)\n",
    "X_test_reshaped = X_test.reshape(-1, 64, 1)\n",
    "\n",
    "# Function to build the model\n",
    "def build_model():\n",
    "    input_layer = Input(shape=(64, 1))\n",
    "    x = Conv1D(32, 4, activation='relu', padding='same', strides=2)(input_layer)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Conv1D(64, 4, activation='relu', padding='same', strides=2)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Conv1D(128, 4, activation='relu', padding='same', strides=2)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Conv1D(256, 4, activation='relu', padding='same', strides=2)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Flatten()(x)\n",
    "    output_layer = Dense(256, activation='softmax')(x)  # 256 units for each byte\n",
    "    model = Model(inputs=input_layer, outputs=output_layer)\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Function to train and evaluate a model for a specific byte of the keystream\n",
    "def train_and_evaluate_byte_0(X_train, y_train, X_test, y_test):\n",
    "    byte_index = 0\n",
    "    model = build_model()\n",
    "    y_train_byte = to_categorical(y_train[:, byte_index], num_classes=256)\n",
    "    y_test_byte = to_categorical(y_test[:, byte_index], num_classes=256)\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "    X_train_gpu = tf.convert_to_tensor(X_train_reshaped)\n",
    "    y_train_gpu = tf.convert_to_tensor(y_train_byte)\n",
    "    X_test_gpu = tf.convert_to_tensor(X_test_reshaped)\n",
    "    y_test_gpu = tf.convert_to_tensor(y_test_byte)\n",
    "    model.fit(X_train_gpu, y_train_gpu, epochs=50, batch_size=32, validation_split=0.1, callbacks=[early_stopping], verbose=1)\n",
    "    loss, accuracy = model.evaluate(X_test_gpu, y_test_gpu, verbose=0)\n",
    "    return accuracy\n",
    "\n",
    "def train_and_evaluate_byte_1(X_train, y_train, X_test, y_test):\n",
    "    byte_index = 1\n",
    "    model = build_model()\n",
    "    y_train_byte = to_categorical(y_train[:, byte_index], num_classes=256)\n",
    "    y_test_byte = to_categorical(y_test[:, byte_index], num_classes=256)\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "    X_train_gpu = tf.convert_to_tensor(X_train_reshaped)\n",
    "    y_train_gpu = tf.convert_to_tensor(y_train_byte)\n",
    "    X_test_gpu = tf.convert_to_tensor(X_test_reshaped)\n",
    "    y_test_gpu = tf.convert_to_tensor(y_test_byte)\n",
    "    model.fit(X_train_gpu, y_train_gpu, epochs=50, batch_size=32, validation_split=0.1, callbacks=[early_stopping], verbose=1)\n",
    "    loss, accuracy = model.evaluate(X_test_gpu, y_test_gpu, verbose=0)\n",
    "    return accuracy\n",
    "\n",
    "# Repeat similar function definitions for bytes 2 through 9\n",
    "\n",
    "def train_and_evaluate_byte_2(X_train, y_train, X_test, y_test):\n",
    "    byte_index = 2\n",
    "    model = build_model()\n",
    "    y_train_byte = to_categorical(y_train[:, byte_index], num_classes=256)\n",
    "    y_test_byte = to_categorical(y_test[:, byte_index], num_classes=256)\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "    X_train_gpu = tf.convert_to_tensor(X_train_reshaped)\n",
    "    y_train_gpu = tf.convert_to_tensor(y_train_byte)\n",
    "    X_test_gpu = tf.convert_to_tensor(X_test_reshaped)\n",
    "    y_test_gpu = tf.convert_to_tensor(y_test_byte)\n",
    "    model.fit(X_train_gpu, y_train_gpu, epochs=50, batch_size=32, validation_split=0.1, callbacks=[early_stopping], verbose=1)\n",
    "    loss, accuracy = model.evaluate(X_test_gpu, y_test_gpu, verbose=0)\n",
    "    return accuracy\n",
    "\n",
    "def train_and_evaluate_byte_3(X_train, y_train, X_test, y_test):\n",
    "    byte_index = 3\n",
    "    model = build_model()\n",
    "    y_train_byte = to_categorical(y_train[:, byte_index], num_classes=256)\n",
    "    y_test_byte = to_categorical(y_test[:, byte_index], num_classes=256)\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "    X_train_gpu = tf.convert_to_tensor(X_train_reshaped)\n",
    "    y_train_gpu = tf.convert_to_tensor(y_train_byte)\n",
    "    X_test_gpu = tf.convert_to_tensor(X_test_reshaped)\n",
    "    y_test_gpu = tf.convert_to_tensor(y_test_byte)\n",
    "    model.fit(X_train_gpu, y_train_gpu, epochs=50, batch_size=32, validation_split=0.1, callbacks=[early_stopping], verbose=1)\n",
    "    loss, accuracy = model.evaluate(X_test_gpu, y_test_gpu, verbose=0)\n",
    "    return accuracy\n",
    "\n",
    "def train_and_evaluate_byte_4(X_train, y_train, X_test, y_test):\n",
    "    byte_index = 4\n",
    "    model = build_model()\n",
    "    y_train_byte = to_categorical(y_train[:, byte_index], num_classes=256)\n",
    "    y_test_byte = to_categorical(y_test[:, byte_index], num_classes=256)\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "    X_train_gpu = tf.convert_to_tensor(X_train_reshaped)\n",
    "    y_train_gpu = tf.convert_to_tensor(y_train_byte)\n",
    "    X_test_gpu = tf.convert_to_tensor(X_test_reshaped)\n",
    "    y_test_gpu = tf.convert_to_tensor(y_test_byte)\n",
    "    model.fit(X_train_gpu, y_train_gpu, epochs=50, batch_size=32, validation_split=0.1, callbacks=[early_stopping], verbose=1)\n",
    "    loss, accuracy = model.evaluate(X_test_gpu, y_test_gpu, verbose=0)\n",
    "    return accuracy\n",
    "\n",
    "def train_and_evaluate_byte_5(X_train, y_train, X_test, y_test):\n",
    "    byte_index = 5\n",
    "    model = build_model()\n",
    "    y_train_byte = to_categorical(y_train[:, byte_index], num_classes=256)\n",
    "    y_test_byte = to_categorical(y_test[:, byte_index], num_classes=256)\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "    X_train_gpu = tf.convert_to_tensor(X_train_reshaped)\n",
    "    y_train_gpu = tf.convert_to_tensor(y_train_byte)\n",
    "    X_test_gpu = tf.convert_to_tensor(X_test_reshaped)\n",
    "    y_test_gpu = tf.convert_to_tensor(y_test_byte)\n",
    "    model.fit(X_train_gpu, y_train_gpu, epochs=50, batch_size=32, validation_split=0.1, callbacks=[early_stopping], verbose=1)\n",
    "    loss, accuracy = model.evaluate(X_test_gpu, y_test_gpu, verbose=0)\n",
    "    return accuracy\n",
    "\n",
    "def train_and_evaluate_byte_6(X_train, y_train, X_test, y_test):\n",
    "    byte_index = 6\n",
    "    model = build_model()\n",
    "    y_train_byte = to_categorical(y_train[:, byte_index], num_classes=256)\n",
    "    y_test_byte = to_categorical(y_test[:, byte_index], num_classes=256)\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "    X_train_gpu = tf.convert_to_tensor(X_train_reshaped)\n",
    "    y_train_gpu = tf.convert_to_tensor(y_train_byte)\n",
    "    X_test_gpu = tf.convert_to_tensor(X_test_reshaped)\n",
    "    y_test_gpu = tf.convert_to_tensor(y_test_byte)\n",
    "    model.fit(X_train_gpu, y_train_gpu, epochs=50, batch_size=32, validation_split=0.1, callbacks=[early_stopping], verbose=1)\n",
    "    loss, accuracy = model.evaluate(X_test_gpu, y_test_gpu, verbose=0)\n",
    "    return accuracy\n",
    "\n",
    "def train_and_evaluate_byte_7(X_train, y_train, X_test, y_test):\n",
    "    byte_index = 7\n",
    "    model = build_model()\n",
    "    y_train_byte = to_categorical(y_train[:, byte_index], num_classes=256)\n",
    "    y_test_byte = to_categorical(y_test[:, byte_index], num_classes=256)\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "    X_train_gpu = tf.convert_to_tensor(X_train_reshaped)\n",
    "    y_train_gpu = tf.convert_to_tensor(y_train_byte)\n",
    "    X_test_gpu = tf.convert_to_tensor(X_test_reshaped)\n",
    "    y_test_gpu = tf.convert_to_tensor(y_test_byte)\n",
    "    model.fit(X_train_gpu, y_train_gpu, epochs=50, batch_size=32, validation_split=0.1, callbacks=[early_stopping], verbose=1)\n",
    "    loss, accuracy = model.evaluate(X_test_gpu, y_test_gpu, verbose=0)\n",
    "    return accuracy\n",
    "\n",
    "def train_and_evaluate_byte_8(X_train, y_train, X_test, y_test):\n",
    "    byte_index = 8\n",
    "    model = build_model()\n",
    "    y_train_byte = to_categorical(y_train[:, byte_index], num_classes=256)\n",
    "    y_test_byte = to_categorical(y_test[:, byte_index], num_classes=256)\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "    X_train_gpu = tf.convert_to_tensor(X_train_reshaped)\n",
    "    y_train_gpu = tf.convert_to_tensor(y_train_byte)\n",
    "    X_test_gpu = tf.convert_to_tensor(X_test_reshaped)\n",
    "    y_test_gpu = tf.convert_to_tensor(y_test_byte)\n",
    "    model.fit(X_train_gpu, y_train_gpu, epochs=50, batch_size=32, validation_split=0.1, callbacks=[early_stopping], verbose=1)\n",
    "    loss, accuracy = model.evaluate(X_test_gpu, y_test_gpu, verbose=0)\n",
    "    return accuracy\n",
    "\n",
    "def train_and_evaluate_byte_9(X_train, y_train, X_test, y_test):\n",
    "    byte_index = 9\n",
    "    model = build_model()\n",
    "    y_train_byte = to_categorical(y_train[:, byte_index], num_classes=256)\n",
    "    y_test_byte = to_categorical(y_test[:, byte_index], num_classes=256)\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "    X_train_gpu = tf.convert_to_tensor(X_train_reshaped)\n",
    "    y_train_gpu = tf.convert_to_tensor(y_train_byte)\n",
    "    X_test_gpu = tf.convert_to_tensor(X_test_reshaped)\n",
    "    y_test_gpu = tf.convert_to_tensor(y_test_byte)\n",
    "    model.fit(X_train_gpu, y_train_gpu, epochs=50, batch_size=32, validation_split=0.1, callbacks=[early_stopping], verbose=1)\n",
    "    loss, accuracy = model.evaluate(X_test_gpu, y_test_gpu, verbose=0)\n",
    "    return accuracy\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training for byte 9...\n"
     ]
    }
   ],
   "source": [
    "print('\\nTraining for byte 9...')\n",
    "accuracy = train_and_evaluate_byte_9(X_train, y_train, X_test, y_test)\n",
    "#accuracies.append(accuracy)\n",
    "print(f'Accuracy for byte 9: {accuracy * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
